Procedia Computer Science
Volume 29, 2014, Pages 1446‚Äì1457
ICCS 2014. 14th International Conference on Computational Science

A High Performance Computing Course Guided by the LU
Factorization
Gregorio Bernab¬¥e1 , Javier Cuenca1 , Luis-Pedro Garc¬¥ƒ±a2 , Domingo Gim¬¥enez1 ,
and Sergio Rivas-Gomez1
1

University of Murcia, Spain
{gbernabe,jcuenca,domingo,sergio.rivas}@um.es
2
Technical University of Cartagena, Murcia, Spain
luis.garcia@sait.upct.es

Abstract
This paper presents an experience of Problem-based learning in a High Performance Computing
course. The course is part of the specialization in High Performance Architectures and Supercomputing on a Master in New Technologies in Computer Science. It is supposed the students
have a basic knowledge of Parallel Programming, but previous studies and the place where they
were taken mean the group is heterogeneous. The Problem-based learning approach therefore
has to facilitate the individual development and supervision of the students. The course focuses
on HPC, matrix computation, parallel libraries, heterogeneous computing and scientiÔ¨Åc applications of parallelism. The students work on the diÔ¨Äerent aspects of the course using the LU
factorization, developing their own implementations, using diÔ¨Äerent libraries, combining diÔ¨Äerent levels of parallelism and conducting experiments in a small heterogeneous cluster composed
of multicores of diÔ¨Äerent characteristics and with GPU of diÔ¨Äerent types.
Keywords: Problem-based learning, High Performance Computing, multicore, GPU, Master‚Äôs studies

1

Introduction

This paper presents a problem-based learning [25] experience in which the LU factorization is
used to guide a course on High Performance Computing [26]. The basics of matrix computation
and the LU factorization are presented to the students at the beginning of the course [15], and
when the diÔ¨Äerent topics of the course are studied, the LU factorization is used to guide the
course, with the students working to develop diÔ¨Äerent versions of the factorization to solve
larger problems with lower execution times.
Problem-based learning is an especially interesting approach for computer science courses,
which can be centered on the practical work of students. There are some experiences in scientiÔ¨Åc
computing courses and in particular in parallelism courses [4, 24, 27]. The experience presented
is the continuation of a similar one [5] in which a problem-based learning approach was used
1446

Selection and peer-review under responsibility of the ScientiÔ¨Åc Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.131

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

in a course of Introduction to Parallel Programming, working on the development of parallel
metaheuristics for the solution of a tasks-to-processors assignation problem. The experience
was conducted on a course in a Degree of Computer Science, and is now extended to a higher
level course in a Master on New Technologies in Computer Science. It is supposed that students
have previous knowledge in the basics of Parallel Architectures and Parallel Programming. The
course is part of the specialization of High Performance Architectures and Supercomputing
and focuses on matrix computation, parallel libraries, heterogeneous computing and scientiÔ¨Åc
applications of parallelism. Other courses of the specialization complement the training of the
students in Parallel Architectures, Distributed Systems and Multi-device Programming. The
problem-based learning approach used in our course facilitates the individual development and
supervision of the students, who come from diÔ¨Äerent universities and hold diÔ¨Äerent degrees or
specializations and may follow the course at a diÔ¨Äerent pace, depending on their knowledge of
the basic concepts of parallelism.
The paper is organized as follows. Section 2 explains the organization of the Master and the
specialization of which the course is part, and it comments on the heterogeneity of the students.
In section 3 the organization of the course is explained in detail. A test is given to the students
to see how the teaching objectives have been fulÔ¨Ålled, and the results of the test are commented
in section 4. Section 5 summarizes the conclusions.

2

The Context

The course is part of the specialization of High Performance Architectures and Supercomputing
in a Master on New Technologies in Computer Science at the University of Murcia, Spain.
In recent years, mainly propitiated by the appearance of multicores and by general purpose
computing on graphic accelerators, parallel computing has become omnipresent, and it is being
progressively introduced in university studies [21, 22]. The IEEE Technical Committee on
Parallel Processing presented in 2012 its Curriculum on Parallel and Distributed Computing
[17], which includes a list of core topics on parallelism for undergraduate studies. At the same
time, the IEEE-TCPP launched the Early Adopter Program in 2011.
The Degree in Computer Engineering in the University of Murcia is organized into four years,
with the fourth year for specialization. There are Ô¨Åve specializations: Computer Engineering,
Software Engineering, Computation, Information Technology and Information Systems. There
is a core course on Concurrent and Distributed Programming in the second year of the degree,
and some topics of parallel architectures are covered in the third year in a course on Architecture and Organization of Computers. A course on Methodology of Parallel Programming is
oÔ¨Äered in the fourth year as compulsory for the students of Software Engineering and optional
for those in Computer Engineering. This course is devoted to shared-memory and messagepassing programming, analysis and design of parallel algorithms and methodology of parallel
programming. There is another optional course on Multicore Programming in the Computer
Engineering specialization. Most of the students on the Degree Ô¨Ånish their studies with a basic
knowledge of concurrency, parallelism and parallel architectures, and only those who follow
the specializations of Computer Engineering or Software Engineering study additional parallel computing topics. We think this situation is far from desirable given the omnipresence of
parallelism in today‚Äôs computational systems.
The Master is organized in seven specializations: Intelligent and Knowledge Technologies
with Applications in Medicine, Networks and Telematics, Engineering Ubiquitous Computing
Environments, Software Technologies, Mathematics Applied to Information and Communications Technology, Industrial Informatics and High Performance Architectures and Supercomput1447

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

ing. There are two common courses on Methodology and Technology for research in Computer
Science, and each specialization has some compulsory courses, a number of optional credits
which can be obtained following courses in the other specializations, and each student works in
the Master‚Äôs Thesis on a topic related to the specialization he/she is in. Table 1 shows the organization of the specialization on High Performance Architectures and Supercomputing. The
course this paper deals with is in the Ô¨Årst semester and comprises 6 credits. It is compulsory
for students in this specialization, and an option for students in other specializations.
The number of students following the course is normally small, which facilitates the organization of teaching with a problem-based learning approach, personal advice and guidance
of students. This year six students are enrolled on the course. As mentioned, they form a
heterogeneous group:
‚Ä¢ Most students came from a Degree in Computer Engineering, but the course is followed
occasionally by students from other degrees. This year one student comes from Telecommunications Engineering.
‚Ä¢ Among the students from Computer Engineering some have followed some course on
Parallel Computing at undergraduate level. This year three of the six students had
followed this type of courses, so only 50% of the students are in the ideal situation to
follow the HPC course. Additional activities are organized for the students without the
desired previous knowledge.
‚Ä¢ Students have studied at diÔ¨Äerent universities, which means in this case their previous
approach to parallelism diÔ¨Äers greatly. This year three students are from the University
of Murcia, two from a nearby university (UCAM), and one from a university in Colombia.
‚Ä¢ Five of the students are following the High Performance Architectures and Supercomputing specialization of the Master, and one the Industrial informatics specialization.
‚Ä¢ The utility of the concepts to work with in the HPC course in their future work or
research and in their Master‚Äôs Thesis is non uniform. The themes they are working on are
molecule simulation, in diÔ¨Äerent parallel systems, and with the use of basic linear algebra
libraries; drug design, by minimizing some scoring measure between molecules, and with
parallel programming to accelerate the computation; image treatment, with GPU; cache
coherency; control problems, with the use of GPU; signal treatment problems with GPU.

3

Course Organization

The course is guided by the LU factorization, and the students work on diÔ¨Äerent versions of
this factorization to accelerate its computation with the use of algorithms by blocks, optimized
libraries, parallel programming environments and parallel computational systems.
The students are encouraged to install the libraries and programming environments to use
in the course in their own systems. They can develop and test the implementations they are
asked to do in their systems. They then conduct experiments in the laboratory of the ScientiÔ¨Åc
Computing and Parallel Programming research group of the University of Murcia, where they
study experimentally, and for bigger problems, the speed-up and scalability of the programs,
and also combine diÔ¨Äerent nodes for heterogeneous computing. The laboratory has a cluster
with Ô¨Åve multicore nodes, each with GPU cards. The cluster has a total of 52 cores and 10
GPUs: the biggest node is a NUMA system (saturno) with 24 cores and a GPU device Tesla
K20c (based on Kepler Architecture) with 2496 CUDA cores; there are two hexa-core nodes,
1448

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

Table 1: Organization of the High Performance Architectures and Supercomputing specialization in the Master on New Technologies in Computer Science, University of Murcia.
course
Research Methodology in Computer Engineering
Technology for Research in Computer
Science
Parallel
Programming
and
High Performance
Computing

type
credits
compulsory
3

semester
Ô¨Årst

compulsory

3

Ô¨Årst

compulsory
specialization

6

Ô¨Årst

Architecture of Multicore Processors

compulsory
specialization

6

Ô¨Årst

Advanced Programming of Multicore
Architectures

compulsory
specialization

6

second

Operating Systems
for High Performance Environments

compulsory
specialization

6

second

Master‚Äôs Thesis

compulsory

18

Courses in other specializations

optional

12

content
Introduction to methodology in
research and the topics of the specialization
Introduction to tools for the different specializations
Parallel programming, supercomputing, high performance computing, shared-memory programming, message-passing programming, matrix computation, hybrid parallelism, hierarchical systems, scientiÔ¨Åc applications of
parallelism
Multicore
processors,
highperformance, energy-eÔ¨Éciency,
cache coherence protocols, cache
organization,
synchronization
mechanisms, hardware transactional memory, reliability and
fault-tolerance
Multicore programming, Cell Be,
GPGPU, heterogeneous computing, high performance computing,
synchronization mechanisms
System monitoring, resource
optimization, high availability,
workload balancing, parallel Ô¨Åle
systems, logical volume management, backup, batch job systems,
administration
Initiation to research in a topic of
the specialization

each with a GPU GeForce GTX 590 with 512 CUDA cores; another comprises two hexa-cores
and six GPU cards, two Nvidia Fermi Tesla C2050 with 448 cores, and the other four in two
devices, each device with two Nvidia GeForce GTX 590 with 512 CUDA cores each. Finally,
access to the cluster is through a quadcore luna with an Nvidia GeForce 9800 GT, with 112
cores. The total primary memory in the Ô¨Åve nodes is 100Gb. The nodes are interconnected with
Gigabit Ethernet technology at 1 Gbit/s speed and run Ubuntu 12.04.2 LTS with Linux Kernel
1449

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

3.5 x86 64 as operating system. Each node contains a local disk for the operating system,
temporary Ô¨Åle systems and swap. Additionally the system supports a shared NFSv4 managed
by luna for the storage of the home directories of user accounts.
The course is organized in three parts: parallel programming environments, OpenMP,
MPI and CUDA; matrix computation, sequential algorithms, algorithms by blocks, out-of-core
algorithms, and parallel algorithms; numerical libraries BLAS, LAPACK, MKL, PLASMA,
MAGMA and ScaLAPACK. However, the temporal organization does not follow this order.
Some of the students have knowledge of some of the programming environments, and so some
of the sessions are attended by part of the students. Below, we comment on the main objectives,
the methodology, the work proposed and some results in each of the sessions:
‚Ä¢ Presentation: This session presents the course, its general organization, the problem
to work with and the tasks to be done by the students. The previous knowledge of the
student on the diÔ¨Äerent topics of the course is determined; three of the six students have
some experience with OpenMP and MPI, and two have experience with CUDA. So, the
sessions on parallel programming environments will be organized for part of the students.
The computational system to work with is presented, and students are given access to it,
along with a brief description of the queue system and how to work interactively.
‚Ä¢ OpenMP and MPI: Two sessions are organized outside the general course timetable;
one on OpenMP and another on MPI. The students can attend these sessions or the
corresponding sessions in a course on Methodology of Parallel Programming in the fourth
year of the Degree on Computer Engineering.
‚Ä¢ Matrix algoritmhs: The second session in the normal organization of the course is
devoted to matrix algorithms. The basic concepts of sparse and dense basic linear algebra
routines are presented, with the column and row major storage schemes and the concept
of leading dimension. Algorithms by blocks and their use in the development of dense
linear algebra libraries are introduced, and the LU factorization is studied in detail, in
versions without and with blocks. Precision issues are commented on.
‚Ä¢ Numerical libraries: Some of the numerous available libraries are commented on [23],
and the session centers on linear algebra libraries [13]. The standard libraries BLAS [12]
and LAPACK [3] are presented, together with some eÔ¨Écient, multithread implementations
(MKL [18], GotoBLAS [29] and ATLAS [30]), with some alternative approaches (FLAME
[16] and PLAPACK [14]) and recent eÔ¨Äorts of optimization for multicore (PLASMA [28]).
The concept of autotuning is introduced, and some articles on autotuning of the ScientiÔ¨Åc Computing and Parallel Programming Group are provided. The articles are on
techniques based on experiments [7] or empirical models of the execution time [6], and
also on application of autotuned routines in higher level scientiÔ¨Åc software [2].
The Ô¨Årst practical to be done by the students is proposed. They will compare the execution time of diÔ¨Äerent versions of the LU: sequential without and with blocks, a version
by blocks calling to diÔ¨Äerent libraries (MKL, GotoBLAS and ATLAS) for the matrix
multiplications inside the factorization, and direct calls to LU in MKL and PLASMA.
The inÔ¨Çuence of the block size and of the number of threads on the execution time when
multithread libraries are used is analyzed. The students can install the libraries and conduct experiments in their own systems, but conclusions must be obtained in the larger
multicore in the cluster (saturno).
1450

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez










"# $%&#






       	 
 


 !"!



Figure 1: Speed-up of diÔ¨Äerent versions of the LU factorization with respect to the sequential
implementation. In Saturno.
‚Ä¢ CUDA: A session is devoted to introducing the basic concepts of GPU programming with
CUDA. The students will not be asked to develop CUDA programs in this course; there is
a course on Advanced Programming of Multicore Architectures in the second semester. In
one of the practicals they are asked to use GPU libraries, and they can decide to combine
it with CUDA programming if they think it is interesting for their Master‚Äôs Thesis.
‚Ä¢ Control session: The work performed by the students in the Ô¨Årst practical is discussed,
together with the problems they have when doing the practical and drawing the main
conclusions. Most of the students decided to install the libraries in their own system. This
supposed a lot of work in some cases, but contributed to learning how to work with these
libraries and the diÔ¨Äerences they have, the libraries hierarchy, the possibility of using C
and Fortran APIs, etc. After learning the use of the routines by experimenting locally, they
used the cluster in the laboratory for further experiments, including scalability analysis.
Figure 1 shows the comparison made by one of the students of diÔ¨Äerent versions of the LU
by blocks. The speed-up with respect to the sequential-simple version provided is shown.
We can point out some peculiarities of the use of linear algebra libraries:
‚Äì A large increment of the performance is achieved with the use of optimized libraries,
and generally the advantage is more apparent for larger problems. A speed-up close
to 300 was achieved in a system with 24 cores, so there are advantages of using
parallelism, but also other alternative optimizations, such as algorithms by blocks
or vectorization.
‚Äì To achieve high performance it is necessary to use the library appropriately, selecting
correctly the value of some parameters. This can be observed in the Ô¨Ågure when
using ATLAS, which has not been tuned well.
‚Äì The use of a library optimized for a particular system does not always give the
best performance. In the Ô¨Ågure the Intel MKL versions (those labeled BLAS and
LAPACK) are surpassed by non vendor versions.
‚Äì The versions by blocks without pivoting surpass the direct use of the routine, but
in this case pivoting is used, so the inÔ¨Çuence of the use of pivoting in the execution
time should be analyzed.
1451

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

In the same session, the utilization of OpenMP in the development of dense linear algebra
routines is discussed. The ideas of algorithms by blocks are reused for the development of
OpenMP versions. The possibility of using multilevel parallelism is commented on, as are
diÔ¨Äerent sources of two-level parallelism: two-level OpenMP routines, OpenMP combined
with multithread libraries, diÔ¨Äerent number of general threads and BLAS threads in
MKL routines, etc. The general problematic for the solution of very large problems is
commented on, and the basic ideas of out-of-core algorithms are introduced.
The second practical is proposed. It consists of the development of OpenMP and
out-of-core versions. In the OpenMP versions the combination of OpenMP and library
parallelism must be analyzed, with determination of the preferred number of threads at
each level. For the out-of-core version a non pivoting version of the LU is proposed, and
the size of the problem to be solved must be determined depending on the amount of
secondary memory.
‚Ä¢ Out-of-core algorithms: This session was given by a researcher from another university,
and the presentation centered on parallel and out-of-core implementations of the LU
factorization, with discussion of precision problems and of In/Out and linear algebra
out-of-core libraries.
‚Ä¢ Research lines: Some of the research lines of the ScientiÔ¨Åc Computing and Parallel
Programming Group are presented. The objective of the session is to present some Ô¨Åelds
where parallel computing and matrix computation are used in research and in scientiÔ¨Åc
applications so that the students can identify some directions in which they can be applied
in their Master‚Äôs Thesis. The themes treated in the session are:
‚Äì Parallel parameterized metaheuristics and hyperheuristics and their use in scientiÔ¨Åc problems [10, 11]. A uniÔ¨Åed view of metaheuristics and hyperheuristics over a
parameterized scheme is presented, with shared-memory and message-passing implementations and some autotuning techniques.
‚Äì Parallel numerical and optimization methods for Simultaneous Equation Models
[19, 20]. Parallel QR factorizations are used to solve Simultaneous Equation Models,
and for a set of data satisfactory models are generated with parallel metaheuristics.
To accelerate the computation when applying QR factorizations, an optimization
problem is stated, and the optimum solution is approached through metaheuristics.
So, numerical and non-numerical parallel routines are considered, and the application of metaheuristics to a numerical problem is presented.
‚Äì Experimental study of linear algebra libraries in multicore, GPU and Many Integrated Core. Experimental results of the matrix multiplication and the LU, QR
and Cholesky factorizations in NUMA systems are presented, together with some
techniques for autotuning basic linear algebra routines. The performance of linear
algebra routines in GPU and the Intel Xeon Phi is compared.
‚Ä¢ Control session: This discusses the OpenMP and out-of-core versions of the LU factorization. The advantages of using multilevel parallelism to increase the performance of
linear algebra routines in large NUMA systems was reported to the students. Experiments
with OpenMP+MKL parallelism with the three blocks-to-threads distributions in Figure
2 give the execution times shown in Figure 3. Two level parallelism does not improve the
1452

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

Figure 2: Blocks-to-threads distributions in the three OpenMP+MKL experimented with.




 !


	


























	


 

 

Figure 3: Comparison of the execution time of diÔ¨Äerent OpenMP+MKL versions.

result obtained with MKL, and the best two-level routine is that with distribution of the
submatrix L by consecutive blocks. The assignation on a mesh of threads gives slightly
worse results, which may be due to a worse use of the memory in the multiplications.
For the practical on out-of-core algorithms, the block limit is initially determined. In
saturno, with 32 GB of RAM, the maximum matrix size for the three square matrices is
approximately 35000. Figure 4 compares the execution time of three implementations.
The initial version (OoC) is improved with simultaneous in-out operations (OoC I/O
Multi-Th), with which an important reduction of the execution time is obtained for large
matrices. A version with storage and reading-writing the data in text format gives similar
results when operations are carried out concurrently (OoC text I/O Multi-Th).
Some basic ideas for the development of CPU+GPU and message-passing versions of the
LU factorization are discussed. A third practical, on LU on CPU+CPU, and a fourth
practical, on message-passing LU, are proposed. The students can work on the practical
they decide (or both), depending on the direction they are more interested in.
For the CPU+GPU version they should decide where to store the matrix initially (the
1453

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez





! "# $






	




       	 




 



Figure 4: Comparison of the execution time of diÔ¨Äerent out-of-core versions.
GPU or the CPU), and the basic routines to be applied in each computing component.
Basic functions of some linear algebra library for GPU (CULA [9], CUBLAS [8] and
MAGMA [1]) can be used, and the implementations must be compared with the best
version of the LU factorization obtained in the previous practicals. Versions for several
GPUs could also be evaluated.
The message-passing version to work with will be a simple version without pivoting. The
best versions obtained in the previous practicals can be used for local computation, so
combining OpenMP, multithread libraries, GPU routines and libraries and out-of-core
implementations. Furthermore, the students can practice with heterogeneous computing
by combining diÔ¨Äerent implementations in diÔ¨Äerent nodes and GPUs in the cluster.
‚Ä¢ Final session: One month after the previous session the results obtained in the three
or four practicals the students have worked in are analyzed. It is not expected that all
the students work on all the practicals, but the work on the Ô¨Årst and second practical
is compulsory, and some eÔ¨Äort must be devoted to the third or fourth practical, maybe
without an experimental study, but at least with some discussion on how to develop some
version for GPU and message-passing.
The course is evaluated in this session. The students are interviewed about the interest
of the themes treated in the course, the suitability of guiding the course with the LU
factorization, the general organization of the course, and the usefulness of what they have
learned for their Master‚Äôs Thesis and their future research or work.

4

Evaluating Teaching

A test has been prepared to evaluate if the teaching objectives have been fulÔ¨Ålled. The test
comprises fourteen statements. Each item can be valued from 1 to 5, with 1 meaning total
disagreement and 5 total agreement. The statements are:
1. Problem-based learning is an interesting approach for a course on HPC.
2. An evaluation with small guided practicals would have been preferable.
3. Evaluation through practicals is better than through exams.
1454

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

Table 2: Mean score for each item in the test.
1
4.2

2
3.2

3
4.8

4
4

5
3.8

6
4.8

7
4.4

8
4

9
2.8

10
2.8

11
2.8

12
2.4

13
5

14
4.8

4. The part on matrix algorithms has been interesting.
5. The part on matrix algorithms will be useful for my Master‚Äôs Thesis.
6. The part on matrix libraries has been interesting.
7. The part on matrix libraries will be useful for my Master‚Äôs Thesis.
8. The part on out-of-core algorithms has been interesting.
9. The part on out-of-core algorithms will be useful for my Master‚Äôs Thesis.
10. Shared-memory programming and OpenMP should be studied in more depth.
11. Message-passing parallelism and MPI should be studied in more depth.
12. GPU parallelism should be studied in more depth.
13. In general, I Ô¨Ånd parallel programming interesting.
14. Parallel computing will be useful for my Master‚Äôs Thesis.
Additionally, the students were asked which knowledge from the course they are using or plan
to use in their Master‚Äôs Thesis.
Table 2 summarizes the answers. The mean score for each item is shown. The number of
students on the course is low. So, no signiÔ¨Åcant conclusions can be drawn from the answers,
but some indicators can be observed:
‚Ä¢ About the organization of the course (items 1 to 3). The problem-based approach is
valued positively, and the students prefer an evaluation by practicals to an evaluation
based on exams, but smaller practicals may be preferable.
‚Ä¢ The diÔ¨Äerent issues tackled in the course are interesting, especially the part of matrix
libraries, and those on matrix algorithms and libraries are useful for their work in the
Master‚Äôs Thesis. This was asserted in the answers to the open question about the Master‚Äôs
Thesis.
‚Ä¢ The students do not perceive any special need to dedicate more time to any of the three
parallel programming paradigms worked with on the course. In any case, in the second
semester they have a course on multicore and manycore programming.
‚Ä¢ In general, they Ô¨Ånd parallel programming interesting and useful for their research (items
13 and 14 and the open question), which is not surprising if we consider they have enrolled
on the High Performance Architectures and Supercomputing specialization.
1455

A HPC Course Guided by the LU

5

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

Conclusions and Future Works

In this paper a practical experience of a Problem-based learning for a High Performance Computing course is described. This course is part of the Master on New Technologies in Computer
Science at University of Murcia, Spain. The course has been oriented towards a heterogeneous
group of students with basic knowledge of Parallel Programming, but with diÔ¨Äerent previous
degree studies at various universities. Thus, the Problem-based learning approach has allowed
individual development and supervision of the students. The students have worked on the diÔ¨Äerent aspects of the course, focusing on a speciÔ¨Åc routine: LU factorization. They have developed
their own implementations, using diÔ¨Äerent libraries, combining diÔ¨Äerent levels of parallelism
and conducting experiments in a small heterogeneous cluster composed of multicore CPUs of
diÔ¨Äerent characteristics and with manycores GPGPU of diÔ¨Äerent types and performances.
The success of the course organization has been evaluated through a test for the students.
Due to the small number of students, we can not draw signiÔ¨Åcant conclusions, but they Ô¨Ånd the
approach is appropriate for a postgraduate course and in a class with few students and with
diÔ¨Äerent levels of knowledge and diÔ¨Äerent interests. The organization of the course has allowed
them to work with the basic concepts of High Performance Computing practically and to direct
their learning according to the themes they are working on in their Master‚Äôs Thesis. Given
the success of this learning methodology, we plan to continue with it in following courses, but
modifying it at some points. For example, students could work on diÔ¨Äerent problems closely
related with their research Ô¨Åelds.

5.1

Acknowledgments

This work was supported by the Spanish MINECO, as well as European Commission FEDER
funds, under grant TIN2012-38341-C04-03.

References
[1] E. Agullo, J. Demmel, J. Dongarra, B. Hadri, J. Kurzak, J. Langou, H. Ltaief, P. Luszczek, and
S. Tomov. Numerical linear algebra on emerging architectures: The PLASMA and MAGMA
projects. Journal of Physics: Conference Series, 180(1), 2009.
¬¥
[2] A. Alvarez-Melc¬¥
on, F. D. Quesada-Pereira, D. Gim¬¥enez, C. P¬¥erez-Alcaraz, T. Ram¬¥ƒ±rez, and J.G. Pic¬¥
on. On the development and optimization of hybrid parallel codes for Integral Equation
formulations. In 7th European Conference on Antennas and Propagation, 2013.
[3] E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. J. Dongarra, J. Du Croz, A. Grenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, and D. Sorensen. LAPACK User‚Äôs Guide. Society for
Industrial and Applied Mathematics, 1995.
[4] M. H. Bidokht and A. Assareh. Life-long learners through problem-based and self directed learning.
Procedia CS, 3:1446‚Äì1453, 2011.
[5] A. L. Calvo, A. Cort¬¥es, D. Gim¬¥enez, and C. Pozuelo. Using metaheuristics in a parallel computing
course. In M. Bubak, G. D. van Albada, J. Dongarra, and P. M. A. Sloot, editors, ICCS (2),
volume 5102 of Lecture Notes in Computer Science, pages 659‚Äì668. Springer, 2008.
[6] J. C¬¥
amara, J. Cuenca, L.-P. Garc¬¥ƒ±a, and D. Gim¬¥enez. Empirical modelling of linear algebra
shared-memory routines. In ICCS, 2013.
[7] J. C¬¥
amara, J. Cuenca, D. Gim¬¥enez, L.-P. Garc¬¥ƒ±a, and A. M. Vidal. Empirical installation of linear
algebra shared-memory subroutines for auto-tuning. International Journal of Parallel Programming, 42(3):408‚Äì434, 2014.
[8] CUBLAS. http://docs.nvidia.com/cuda/cublas/.

1456

A HPC Course Guided by the LU

Bernab¬¥e, Cuenca, Garc¬¥ƒ±a, Gim¬¥enez, Rivas-Gomez

[9] CULA GPU Accelerated Linear Algebra. http://www.culatools.com/dense/performance/.
[10] J.-M. Cutillas-Lozano and D. Gim¬¥enez. Determination of the kinetic constants of a chemical
reaction in heterogeneous phase using parameterized metaheuristics. In ICCS, 2013.
[11] L.-G. Cutillas-Lozano, J.-M. Cutillas-Lozano, and D. Gim¬¥enez. Modeling shared-memory metaheuristic schemes for electricity consumption. In Distributed Computing and ArtiÔ¨Åcial Intelligence
- 9th International Conference, pages 33‚Äì40, 2012.
[12] J. J. Dongarra, J. Du Croz, S. Hammarling, and R. J. Hanson. An extended set of fortran basic
linear algebra subroutines. ACM Transactions on Mathematical Software, 14:1‚Äì17, 1988.
[13] Freely Available Software for Linear Algebra. http://www.netlib.org/utk/people/JackDongarra
/la-sw.html.
[14] R. A. Van de Geijn. Using PLAPACK. The MIT Press, 1997.
[15] G. Golub and C. F. Van Loan. Matrix Computations. The John Hopkins University Press, fourth
edition, 2013.
[16] J. A. Gunnels, F. G. Gustavson, G. Henry, and R. A. van de Geijn. Flame: Formal linear algebra
methods environment. ACM Trans. Math. Softw., 27(4):422‚Äì455, 2001.
[17] IEEE Technical Committee on Parallel Processing. Curriculum on Parallel and Distributed Computing, http://www.cs.gsu.edu/~tcpp/curriculum/index.php.
[18] Intel MKL web page. http://software.intel.com/en-us/intel-mkl/.
[19] J.-J. L¬¥
opez-Esp¬¥ƒ±n, A. M. Vidal, and D. Gim¬¥enez. Two-stage least squares and indirect least
squares algorithms for simultaneous equations models. J. Computational Applied Mathematics,
236(15):3676‚Äì3684, 2012.
[20] J. J. L¬¥
opez-Esp¬¥ƒ±n, A. M. Vidal, and D. Gim¬¥enez. Heuristics and metaheuristics for accelerating the
computation of simultaneous equations models through a steiner tree. Journal of Computational
and Applied Mathematics, 255(0):605 ‚Äì 615, 2014.
[21] D. J. Meder, V. Pankratius, and W. F. Tichy. http://www.multicore-systems.org/separs/
downloads/GI-WG-SurveyParallelismCurricula.pdf, 2008.
[22] R. Muresano, D. Rexachs, and E. Luque. Learning parallel programming: a challenge for university
students. In ICCS, number 1, pages 875‚Äì883, 2010.
[23] National HPCC Software Exchange. http://www.nhse.org/rib/repositories/nhse/catalog
/#Numerical Programs and Routines.
[24] E. Nuutila, S. T¬®
orm¬®
a, and L. Malmi. PBL and Computer Programming - The Seven Steps Method
with Adaptations. Computer Science Education, 15(2):123‚Äì142, 2005.
[25] M. J. O‚ÄôGrady. Practical problem-based learning in computing education. Trans. Comput. Educ.,
12(3):10:1‚Äì10:16, July 2012.
[26] Parallel Programming and High Performance Computing course at the University of Murcia,
http://dis.um.es/~domingo/cap.html.
[27] R. S. Pinto, P. N. Nobile, E. L. C. Mamani, L. P. J¬¥
unior, H. J. F. Luz, and F. J. Monaco. Operating
System from the Scratch: a Problem-Based Learning Approach for the Emerging Demands on OS
Development. In ICCS, pages 2472‚Äì2481, 2013.
[28] PLASMA. http://icl.cs.utk.edu/plasma/.
[29] Texas Advanced Computing Center. http://www.tacc.utexas.edu/resources/software/#blas.
[30] R. Clinton Whaley, A. Petitet, and J. Dongarra. Automated empirical optimizations of software
and the ATLAS project. Parallel Computing, 27(1-2):3‚Äì35, 2001.

1457

