Available online at www.sciencedirect.com

ScienceDirect
Procedia Computer Science 108C (2017) 1050â€“1059

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Efficient Hybrid Algorithms for Computing Clusters
Overlap
Efficient Hybrid Algorithms
for Computing Clusters
Overlap
Pradeep Javangula, Kourosh Modarresi, Paresh Shenoy1,2*
2â€ 
Yi Liu
and Aran
NayebiParesh
1,2*
Pradeep Javangula,
Kourosh
Modarresi,
Shenoy1,2*
1
Adobe Inc, U.S.
2â€ 
2â€ 
Yi Liu2Adobe
and Aran
Nayebi
Inc, U.S.

1Adobe Inc, U.S.
javangul@adobe.com, modarres@adobe.com,
pshenoy@adobe.com, yiliu15@stanford.edu,
2
2Adobe Inc, U.S.
anayebi@stanford.edu
javangul@adobe.com, modarres@adobe.com, pshenoy@adobe.com, yiliu15@stanford.edu,
anayebi@stanford.edu
1

Abstract
Every year, marketers target different segments of the population with multitudes of advertisements.
Abstract
However, millions of dollars are wasted targeting similar segments with different advertisements.
Every
year, marketers
target expensive
different segments
of the
the similarity
populationbetween
with multitudes
of advertisements.
Furthermore,
it is extremely
to compute
the segments
because these
However,
millions
of
dollars
are
wasted
targeting
similar
segments
with
different
advertisements.
segments can be very large, on the order of millions and billions. In this project, we come
up with a fast
Furthermore,
it is extremely
expensive
to compute
thedetermine
similarity the
between
the segments
because
these
probabilistic algorithm,
described
in Section
3, that can
similarity
between large
segments
segments
can degree
be veryoflarge,
on thethan
order
of millions
and billions. In this project, we come up with a fast
with a higher
accuracy
other
known methods.
probabilistic algorithm, described in Section 3, that can determine the similarity between large segments
Â© 2017
TheClustering,
Authors.
by Elsevier
B.V.known methods.
with
a higher
degreePublished
of accuracy
than Inclusion-Exclusion
other
Keywords:
Jaccard
similarity,
algorithm, MinHash, HyperLogLog

Peer-review under responsibility of the scientific committee of the International Conference on Computational Science

Keywords:
Keywords: Clustering,
Clustering, Jaccard
Jaccard similarity,
similarity, Inclusion-Exclusion
Inclusion-Exclusion algorithm,
algorithm, MinHash,
MinHash, HyperLogLog
HyperLogLog

1 Introduction
clusters or segments are some of the major functionality in data analysis and digital
1 Building
Introduction

marketing. These segments are built for creation of a group of similar users. The interests would be to
Buildingthe
clusters
segments
are insome
of specific
the major
functionality
analysis
and digital
understand
users, or
their
inclination
taking
actions
and also in
in data
targeting
the users
in the
marketing.
segments
are built for creation of a group of similar users. The interests would be to
segment forThese
specific
campaign.
understand
the users,
theirofinclination
in taking
specific
actions
and also in
targeting
the sense
users of
in that
the
One prominent
feature
these segments
is that
they have
considerable
overlaps
in the
segment
forusers
specific
many same
are campaign.
members of the different segments. Campaigns aim in avoiding targeting the same
Onesoprominent
feature
of these
segments
that they
have considerable
overlaps
in the
of that
users,
finding these
overlaps
is critical
to is
prevent
redundancy
and loss of
resources.
Bysense
computing
many
same
users
are
members
of
the
different
segments.
Campaigns
aim
in
avoiding
targeting
the
same
the amount of overlaps the segments may have, one could also make a better estimate about the value
users,
so
finding
these
overlaps
is
critical
to
prevent
redundancy
and
loss
of
resources.
By
computing
of each segment.
the amount of overlaps the segments may have, one could also make a better estimate about the value
of each segment.
VP of Digital Marketing, Sr AI- Machine Learning scientist, Team Lead at Media & Advertising Solutions (All at Adobe)
Interns at Adobe Inc
**
****
The
authors
names areSrsorted
in alphabetical
order
(Adobe
FT and
VP of
of
Digital
Marketing,
AI- Machine
Machine
Learning
scientist,
Team
LeadInterns).
at Media
Media &
& Advertising
Advertising Solutions
Solutions (All
(All at
at Adobe)
Adobe)
VP
Digital
Marketing,
Sr AILearning
scientist,
Team
Lead
at
â€ â€ 
Interns
at
Adobe
Inc
Interns at Adobe Inc
****
**** The
The authors
authors names
names are
are sorted
sorted in
in alphabetical
alphabetical order
order (Adobe
(Adobe FT
FT and
and Interns).
Interns).
*
â€ 

1877-0509 Â© 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.212

	

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

The objective of this work is to find efficient and accurate model for the computation of the overlaps
of segments.

2 The Current Models
Before giving our full algorithm in Section 3, we first give an overview of two initial
probabilistic approaches that we will pursue, and then will combine these two methods in Section 3 in
a novel way.

2.1 Inclusion-Exclusion Method
B:

The inclusion-exclusion method makes use of the basic property that for two segments A and
|ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ| = |ğ´ğ´ğ´ğ´| + |ğµğµğµğµ| âˆ’ |ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ|.

Thus, if we can quickly compute |ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ|, then we can derive the size of the overlap given by
|ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ|. Currently, the HyperLogLog (HLL) algorithm (Flajolet, 2007) can generate the values of
|ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ| very efficiently and with high accuracy (as it is a probabilistic algorithm, so the results will
not be guaranteed to be exact). Therefore, this approach is a viable alternative to the brute force
approach.

2.2 MinHash + HLL
Another observation for computing |ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ|, is the following identity:
The quantity

|ğ´ğ´ğ´ğ´âˆ©ğµğµğµğµ|

|ğ´ğ´ğ´ğ´âˆªğµğµğµğµ|

|ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ| =

|ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ|
âˆ— |ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ|.
|ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ|

is known as the Jaccard similarity between A and B, and can be computed

efficiently and with high accuracy using a technique known as MinHash (Broder, 1997). Moreover,
|ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ| can be computing efficiently using HyperLogLog, as in the Inclusion-Exclusion method.

For the sake of completeness, we describe MinHash and provide its pseudocode; our
description is based on the explanation provided in (Vassilvitskii, 2011). Let ğ‘”ğ‘”ğ‘”ğ‘”1 , â€¦ , ğ‘”ğ‘”ğ‘”ğ‘”ğ‘˜ğ‘˜ğ‘˜ğ‘˜ be ğ‘˜ğ‘˜ğ‘˜ğ‘˜
independent random hash functions. We then construct ğ‘˜ğ‘˜ğ‘˜ğ‘˜ new hash functions ğ»ğ»ğ»ğ»1 , â€¦ , ğ»ğ»ğ»ğ»ğ‘˜ğ‘˜ğ‘˜ğ‘˜ where for any
segment ğ‘Šğ‘Šğ‘Šğ‘Š,
ğ»ğ»ğ»ğ»ğ‘–ğ‘–ğ‘–ğ‘– (ğ‘Šğ‘Šğ‘Šğ‘Š) = min ğ‘”ğ‘”ğ‘”ğ‘”ğ‘–ğ‘–ğ‘–ğ‘– (ğ‘¤ğ‘¤ğ‘¤ğ‘¤).
ğ‘¤ğ‘¤ğ‘¤ğ‘¤âˆˆğ‘Šğ‘Šğ‘Šğ‘Š

In other words, each hash function ğ»ğ»ğ»ğ»ğ‘–ğ‘–ğ‘–ğ‘– is the minimum value of the hash function ğ‘”ğ‘”ğ‘”ğ‘”ğ‘–ğ‘–ğ‘–ğ‘– on the segment ğ‘Šğ‘Šğ‘Šğ‘Š.
Thus, for the two segments ğ´ğ´ğ´ğ´ and ğµğµğµğµ, we first compute their summary vectors, ğ‘†ğ‘†ğ‘†ğ‘†(ğ´ğ´ğ´ğ´) and ğ‘†ğ‘†ğ‘†ğ‘†(ğµğµğµğµ), defined
as such:
ğ‘†ğ‘†ğ‘†ğ‘†(ğ´ğ´ğ´ğ´) = < ğ»ğ»ğ»ğ»1 (ğ´ğ´ğ´ğ´), â€¦ , ğ»ğ»ğ»ğ»ğ‘˜ğ‘˜ğ‘˜ğ‘˜ (ğ´ğ´ğ´ğ´) >

ğ‘†ğ‘†ğ‘†ğ‘†(ğµğµğµğµ) = < ğ»ğ»ğ»ğ»1 (ğµğµğµğµ), â€¦ , ğ»ğ»ğ»ğ»ğ‘˜ğ‘˜ğ‘˜ğ‘˜ (ğµğµğµğµ) >.

1051

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

1052	

Now, define ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘– = 1 if ğ»ğ»ğ»ğ»ğ‘–ğ‘–ğ‘–ğ‘– (ğ´ğ´ğ´ğ´) = ğ»ğ»ğ»ğ»ğ‘–ğ‘–ğ‘–ğ‘– (ğµğµğµğµ) and ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘– = 0 if otherwise. Then the MinHash estimate of the
Jaccard similarity is given by

âˆ‘ğ‘˜ğ‘˜ğ‘˜ğ‘˜ğ‘–ğ‘–ğ‘–ğ‘–=1 ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–
.
ğ‘˜ğ‘˜ğ‘˜ğ‘˜

We provide the pseudocode for MinHash below (based on the above explanation):
MinHash Pseudocode
Input: Segments A and B
1.
2.

Construct ğ’Œğ’Œğ’Œğ’Œ random hash functions ğ’ˆğ’ˆğ’ˆğ’ˆğŸğŸğŸğŸ , â€¦ , ğ’ˆğ’ˆğ’ˆğ’ˆğ’Œğ’Œğ’Œğ’Œ
Compute the summary vectors for A and B:
ğ‘ºğ‘ºğ‘ºğ‘º(ğ‘¨ğ‘¨ğ‘¨ğ‘¨) = < ğ‘¯ğ‘¯ğ‘¯ğ‘¯ğŸğŸğŸğŸ (ğ‘¨ğ‘¨ğ‘¨ğ‘¨), â€¦ , ğ‘¯ğ‘¯ğ‘¯ğ‘¯ğ’Œğ’Œğ’Œğ’Œ (ğ‘¨ğ‘¨ğ‘¨ğ‘¨) >
ğ‘ºğ‘ºğ‘ºğ‘º(ğ‘©ğ‘©ğ‘©ğ‘©) = < ğ‘¯ğ‘¯ğ‘¯ğ‘¯ğŸğŸğŸğŸ (ğ‘©ğ‘©ğ‘©ğ‘©), â€¦ , ğ‘¯ğ‘¯ğ‘¯ğ‘¯ğ’Œğ’Œğ’Œğ’Œ (ğ‘©ğ‘©ğ‘©ğ‘©) >,
where for any segment W,
ğ‘¯ğ‘¯ğ‘¯ğ‘¯ğ’Šğ’Šğ’Šğ’Š (ğ‘¾ğ‘¾ğ‘¾ğ‘¾) = ğ¦ğ¦ğ¦ğ¦ğ¦ğ¦ğ¦ğ¦ğ¦ğ¦ğ¦ğ¦ ğ’ˆğ’ˆğ’ˆğ’ˆğ’Šğ’Šğ’Šğ’Š (ğ’˜ğ’˜ğ’˜ğ’˜).
ğ’˜ğ’˜ğ’˜ğ’˜âˆˆğ‘¾ğ‘¾ğ‘¾ğ‘¾

3. Let Y denote the number of indices i where S(A) and S(B) match. (So, ğ’€ğ’€ğ’€ğ’€ = âˆ‘ğ’Œğ’Œğ’Œğ’Œğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ ğ’€ğ’€ğ’€ğ’€ğ’Šğ’Šğ’Šğ’Š , in
our above explanation).
Return:
ğ’€ğ’€ğ’€ğ’€
.
ğ’Œğ’Œğ’Œğ’Œ

For further reference, our complete Python implementation of the MinHash algorithm is
given in Appendix A.2 (note that it has not been parallelized for efficiency). For our simulations
presented in Section 5, we used a parallelized implementation of MinHash found online (Zhu, 2016).

3 Our Mathematical Model
In our simulations (detailed in Section 5) of the Inclusion-Exclusion and MinHash + HLL methods,
we found that the error rate of Inclusion-Exclusion was sometimes comparable to that of MinHash +
HLL (though MinHash + HLL generally attained lower error than Inclusion-Exclusion), and overall
Inclusion-Exclusion ran faster than MinHash + HLL. Therefore, it would be advantageous to know when
we should use one method over the other, rather than simply sticking to a single method. Both
theoretically and empirically, which we will detail in Sections 4 and 5, we have found that the error
strongly depends on the Jaccard similarity between the two segments. The basic idea behind our
approach is when the error of Inclusion-Exclusion is comparable (according to an empirically defined
threshold on the Jaccard similarity of the segments) to that of MinHash + HLL, then we use InclusionExclusion; otherwise, we use MinHash + HLL, thereby optimizing between speed and performance.

3.1 Pseudocode

	

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

The pseudocode for our algorithm is given below:
Pseudocode
Input: N segments ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ , â€¦ , ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ‘µğ‘µğ‘µğ‘µ

0.

1.

By default, set the threshold ğœ¶ğœ¶ğœ¶ğœ¶ = ğŸğŸğŸğŸ. ğŸ“ğŸ“ğŸ“ğŸ“. (This threshold can be set manually to a
different value if you wish).
If ğ‘µğ‘µğ‘µğ‘µ â‰¥ ğŸ‘ğŸ‘ğŸ‘ğŸ‘, use MinHash + HLL to compute the overlap | â‹‚ğ‘µğ‘µğ‘µğ‘µ
ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š |, since
ğ‘µğ‘µğ‘µğ‘µ

| â‹‚ğ‘µğ‘µğ‘µğ‘µ
ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š |
ï¿½ï¿½ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š ï¿½ =
âˆ— ï¿½ï¿½ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š ï¿½,
ğ‘µğ‘µğ‘µğ‘µ
|
â‹ƒ
ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ
ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š |
ğ‘µğ‘µğ‘µğ‘µ

| â‹‚ğ‘µğ‘µğ‘µğ‘µ
ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š |

, can be computed by MinHash,

where the generalized Jaccard similarity,
and the generalized union,
2.

ï¿½â‹ƒğ‘µğ‘µğ‘µğ‘µ
ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š ï¿½,

ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ

| â‹ƒğ‘µğ‘µğ‘µğ‘µ
ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š |

can be computed using HLL.

Else if ğ‘µğ‘µğ‘µğ‘µ = ğŸğŸğŸğŸ, first compute |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ | and |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ | either exactly or approximately using
HLL. Now, suppose |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ | â‰¥ |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ |, namely suppose ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ is the larger of the two sets.
i)

If

|ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ |

|ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ |

â‰¥ ğœ¶ğœ¶ğœ¶ğœ¶, then estimate |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ âˆª ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ | using HLL, and use the Inclusion-

Exclusion method to compute |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ âˆ© ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ |. If the estimated Jaccard similarity
|ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ âˆ©ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ |
â‰¥ ğœ¶ğœ¶ğœ¶ğœ¶, then return |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ âˆ© ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ |, which we already computed with the
|ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ âˆªğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ |

Inclusion-Exclusion method. Otherwise, compute |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ âˆ© ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ | using MinHash
+ HLL.
ii)
Else, compute |ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ âˆ© ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğŸğŸğŸğŸ | using MinHash + HLL.
Return: Computed estimate of the segment overlap:
ğ‘µğ‘µğ‘µğ‘µ

ï¿½ï¿½

ğ‘¨ğ‘¨ğ‘¨ğ‘¨ğ’Šğ’Šğ’Šğ’Š ï¿½.

ğ’Šğ’Šğ’Šğ’Š=ğŸğŸğŸğŸ

We recommend using at least 22000 hash functions for MinHash and at least 10,000
streams for HLL.

3.2 Explanation and Justification

For more than two segments, we use MinHash + HLL, as it is the most direct approach for
computing intersection between multiple segments since the Inclusion-Exclusion formula becomes
rather unruly and impractical for more than two segments, not to mention that the generalized Jaccard
similarity can be computed by MinHash and the generalized union can be computed by HLL.
Now, in the case of two segments, we try to attain a reasonable tradeoff between the speed of
the Inclusion-Exclusion method and the accuracy of MinHash + HLL. Both empirically and
theoretically, we have found that the Inclusion-Exclusion method attains a comparable error rate to
MinHash + HLL for extreme values of the Jaccard similarity, namely, when the Jaccard similarity is
high. The reason why we first estimate the ratio

|ğ´ğ´ğ´ğ´2 |

|ğ´ğ´ğ´ğ´1 |

because it is a surrogate for the Jaccard similarity

1053

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

1054	

and can be more reliably estimated (or computed exactly) than the Jaccard similarity. This is simply
because
|ğ´ğ´ğ´ğ´1 âˆ© ğ´ğ´ğ´ğ´2 | â‰¤ |ğ´ğ´ğ´ğ´2 | â‰¤ |ğ´ğ´ğ´ğ´1 | â‰¤ |ğ´ğ´ğ´ğ´1 âˆª ğ´ğ´ğ´ğ´2 |,

which implies that

As a result, if

|ğ´ğ´ğ´ğ´2 |
|ğ´ğ´ğ´ğ´1 |

< ğ›¼ğ›¼ğ›¼ğ›¼, then

|ğ´ğ´ğ´ğ´1 âˆ©ğ´ğ´ğ´ğ´2 |

|ğ´ğ´ğ´ğ´1 âˆªğ´ğ´ğ´ğ´2 |

|ğ´ğ´ğ´ğ´2 | |ğ´ğ´ğ´ğ´1 âˆ© ğ´ğ´ğ´ğ´2 |
â‰¥
.
|ğ´ğ´ğ´ğ´1 | |ğ´ğ´ğ´ğ´1 âˆª ğ´ğ´ğ´ğ´2 |

< ğ›¼ğ›¼ğ›¼ğ›¼, which means that the Jaccard similarity is below the

threshold ğ›¼ğ›¼ğ›¼ğ›¼, in which case we use MinHash + HLL, as in Step 2.ii. Otherwise, if

|ğ´ğ´ğ´ğ´2 |
|ğ´ğ´ğ´ğ´1 |

â‰¥ ğ›¼ğ›¼ğ›¼ğ›¼, then this

does not imply anything on the Jaccard similarity, so in that case, we need to still estimate the Jaccard
similarity to see whether it is above or below the threshold ğ›¼ğ›¼ğ›¼ğ›¼, which we do in Step 2.i.

In what follows, we further justify the above algorithm to explain how we determined the
threshold ğ›¼ğ›¼ğ›¼ğ›¼ = 0.5. Particularly, in Section 4, we provide a theoretical justification for our approach as
well as support it empirically in Section 5.

4 Theoretical Error Analysis
Before delving into the empirical results in Section 5, we will first heuristically derive error
bounds on the probabilistic approaches outlined in Sections 2.1 and 2.2 of the Inclusion-Exclusion
Method and MinHash + HLL in Sections 4.1 and 4.2. Finally, in Section 4.3, we will use our
derivations for the error rates of the two methods to justify our algorithm proposed in Section 3.
As these error bounds are intended to be a heuristic, we will assume for convenience that the estimate
of Jaccard similarity,

|ğ´ğ´ğ´ğ´âˆ©ğµğµğµğµ|

, using MinHash, and the estimate of the union |ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ| using HLL are

|ğ´ğ´ğ´ğ´âˆªğµğµğµğµ|

statistically independent.

Let ğ‘‹ğ‘‹ğ‘‹ğ‘‹ = |ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ| denote the true overlap between A and B. Then, for any estimator ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ of ğ‘‹ğ‘‹ğ‘‹ğ‘‹, the error
of the estimator ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ can be quantified via mean squared error and decomposed into the following biasvariance tradeoff:
2
2
2
2
ğ¸ğ¸ğ¸ğ¸ ï¿½ï¿½ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ï¿½ ï¿½ = ï¿½ğ¸ğ¸ğ¸ğ¸ï¿½ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ï¿½ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ + ğ¸ğ¸ğ¸ğ¸ ï¿½ï¿½ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ âˆ’ ğ¸ğ¸ğ¸ğ¸ï¿½ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ï¿½ï¿½ ï¿½ = ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµï¿½ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ï¿½ + ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ï¿½ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ï¿½ï¿½,

where E denotes expected value.

Now, let ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ and let ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» denote the estimates of ğ‘‹ğ‘‹ğ‘‹ğ‘‹ using the Inclusion-Exclusion and MinHash +
HLL methods, respectively. Thus, the errors of the two methods are given by ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ )2 ] and
ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» )2 ], respectively, and can be decomposed as above:
ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ )2 ] = ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ( ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ )2 + ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ )

ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» )2 ] = ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ( ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» )2 + ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» ).

For notational convenience, define

	

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

|ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ|
|ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ|
ğ‘‰ğ‘‰ğ‘‰ğ‘‰ = |ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ|.

ğ‘šğ‘šğ‘šğ‘š =

4.1 Inclusion-Exclusion Method Error

We proceed to derive the error of the Inclusion-Exclusion Method, namely, we derive an
expression for the quantity, ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ )2 ]. From the above discussion, it suffices to find an
expression for ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ ) and ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ ). Observe that since we know the sizes of ğ´ğ´ğ´ğ´ and ğµğµğµğµ and
are only computing |ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ| using HLL, then we have that
ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ ) = ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»)

ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ ) = ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»).

Now, the expectation of HLL as ğ‘‰ğ‘‰ğ‘‰ğ‘‰ â†’ âˆ in estimating n is ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ğ‘‰ğ‘‰ğ‘‰ğ‘‰, as reported in [2, Theorem 1],
where |ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)| â‰¤ 5Ã—10âˆ’5 if we have ğ‘‰ğ‘‰ğ‘‰ğ‘‰ â‰¥ 16 streams. Hence, ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ») = ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ğ‘‰ğ‘‰ğ‘‰ğ‘‰. Furthermore, the
variance of HLL as ğ‘‰ğ‘‰ğ‘‰ğ‘‰ â†’ âˆ in estimating n is ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ») = ï¿½

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘Ÿğ‘Ÿğ‘Ÿğ‘Ÿ

2

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 , where ğ›½ğ›½ğ›½ğ›½ â‰ˆ 1.04

and |ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)| â‰¤ 5Ã—10âˆ’4 if we have ğ‘‰ğ‘‰ğ‘‰ğ‘‰ â‰¥ 16 streams, as reported in in [2, Theorem 1]. As a result,
ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ ) = ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ğ‘‰ğ‘‰ğ‘‰ğ‘‰

ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ ) = ï¿½

from which it follows that as ğ‘‰ğ‘‰ğ‘‰ğ‘‰ â†’ âˆ,

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 ,

ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ )2 ] = ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)2 ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 + ï¿½

4.2 MinHash + HLL Error

2

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

2

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 .

For this error estimate, as mentioned before, we will be assuming that the estimate of Jaccard
similarity m using MinHash, and the estimate of the union n using HLL are statistically independent.
1

The estimate of m using MinHash with ğ‘˜ğ‘˜ğ‘˜ğ‘˜ = ğ‘‚ğ‘‚ğ‘‚ğ‘‚ ï¿½ğ‘™ğ‘™ğ‘™ğ‘™ğ‘™ğ‘™ğ‘™ğ‘™ğ‘”ğ‘”ğ‘”ğ‘” ï¿½ hash functions is (1 + ğ›¿ğ›¿ğ›¿ğ›¿)ğ‘šğ‘šğ‘šğ‘š, as can be derived
ğ›¿ğ›¿ğ›¿ğ›¿

in [3, Theorem 1] using a standard Chernoff bound argument. Note that MinHash is an unbiased
estimator, so in the limit, it does not have any bias. As a result, the bias in estimating |ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ| with
MinHash + HLL is the product of the biases of MinHash and HLL (due to our independence
assumption),
ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» ) = ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ğ‘šğ‘šğ‘šğ‘šğ‘‰ğ‘‰ğ‘‰ğ‘‰.

Furthermore, the variance of MinHash + HLL can be computed again using the formula for the
variance of the product of independent random variables (by our independence assumption),
ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» ) = ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘€ğ‘€ğ‘€ğ‘€ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµâ„ âˆ— ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»)

1055

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

1056	

= ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘€ğ‘€ğ‘€ğ‘€ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµâ„) âˆ— ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ») + ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘€ğ‘€ğ‘€ğ‘€ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµâ„) âˆ— (ğ¸ğ¸ğ¸ğ¸[ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»])2
+ ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ») âˆ— (ğ¸ğ¸ğ¸ğ¸[ğ‘€ğ‘€ğ‘€ğ‘€ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµâ„])2 .

Now, to finish the computation of ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» ), all that is left is to compute
ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘€ğ‘€ğ‘€ğ‘€ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµâ„), which is the variance of MinHash. Observe that for each hash function ğµğµğµğµ =
1, â€¦ , ğ‘˜ğ‘˜ğ‘˜ğ‘˜, let ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘– be the Bernoulli random variable which denotes whether there is a hash collision, where
Pr[ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘– = 1] = ğ‘šğ‘šğ‘šğ‘š, so the MinHash estimate is
ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘€ğ‘€ğ‘€ğ‘€ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµâ„) = ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ ï¿½

âˆ‘ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘–ğ‘–ğ‘–ğ‘–=1 ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–
ğ‘˜ğ‘˜ğ‘˜ğ‘˜

. Therefore,

âˆ‘ğ‘˜ğ‘˜ğ‘˜ğ‘˜ğ‘–ğ‘–ğ‘–ğ‘–=1 ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘– ) ğ‘˜ğ‘˜ğ‘˜ğ‘˜ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š)
âˆ‘ğ‘˜ğ‘˜ğ‘˜ğ‘˜ğ‘–ğ‘–ğ‘–ğ‘–=1 ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘–
ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š)
ï¿½=
=
=
,
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘˜ğ‘˜ğ‘˜ğ‘˜ 2
ğ‘˜ğ‘˜ğ‘˜ğ‘˜ 2
ğ‘˜ğ‘˜ğ‘˜ğ‘˜

since ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘Œğ‘Œğ‘Œğ‘Œğ‘–ğ‘–ğ‘–ğ‘– ) = ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š), as it is a Bernoulli random variable with mean m. Thus, as a
reminder of what we already know, we have that
ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ(ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ») = ï¿½

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

2

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2

ğ¸ğ¸ğ¸ğ¸[ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»ğ»] = ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ğ‘‰ğ‘‰ğ‘‰ğ‘‰
ğ¸ğ¸ğ¸ğ¸[ğ‘€ğ‘€ğ‘€ğ‘€ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµâ„] = ğ‘šğ‘šğ‘šğ‘š.

Therefore, it follows that
ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğµğµğµğµğµğµğµğµğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» )
=

2

2

ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š) ğ›½ğ›½ğ›½ğ›½
ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š)
ğ›½ğ›½ğ›½ğ›½
ï¿½ + ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 +
ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ 2 ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 + ï¿½ + ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 ğ‘šğ‘šğ‘šğ‘š2 .
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘‰ğ‘‰ğ‘‰ğ‘‰
âˆš
âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

Hence, using the bias-variance tradeoff, the error of MinHash + HLL becomes,
ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» )2 ]

2

ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š) ğ›½ğ›½ğ›½ğ›½
ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š)
= ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰) ğ‘šğ‘šğ‘šğ‘š ğ‘‰ğ‘‰ğ‘‰ğ‘‰ +
ï¿½ + ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 +
ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ 2 ğ‘‰ğ‘‰ğ‘‰ğ‘‰2
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰
2

2 2

+ï¿½

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

2

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 ğ‘šğ‘šğ‘šğ‘š2 .

4.3 Theoretical Justification for our Proposed Algorithm in Section 3

Now that we have derived expressions for the errors of both the Inclusion-Exclusion Method
and MinHash + HLL, we proceed to understand the conditions under which we may expect one
algorithm to achieve lower error than the other, as this understanding underlies our proposed algorithm
in Section 3. Therefore, we aim to understand when

or equivalently, when

ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ‘€ğ‘€ğ‘€ğ‘€ğ»ğ»ğ»ğ» )2 ] < ğ¸ğ¸ğ¸ğ¸[(ğ‘‹ğ‘‹ğ‘‹ğ‘‹ âˆ’ ğ‘‹ğ‘‹ğ‘‹ğ‘‹ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼ )2 ],

	

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)2 ğ‘šğ‘šğ‘šğ‘š2 ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 +

2

2

ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š) ğ›½ğ›½ğ›½ğ›½
ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š)
ğ›½ğ›½ğ›½ğ›½
ï¿½ + ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 +
ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ 2 ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 + ï¿½ + ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 ğ‘šğ‘šğ‘šğ‘š2
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘‰ğ‘‰ğ‘‰ğ‘‰
âˆš
âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰
2 2

< ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰) ğ‘‰ğ‘‰ğ‘‰ğ‘‰ + ï¿½

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

Observe that we can cancel out ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 from both sides to simplify the inequality to become
2

2

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘‰ğ‘‰ğ‘‰ğ‘‰2 .

2

ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š) ğ›½ğ›½ğ›½ğ›½
ğ‘šğ‘šğ‘šğ‘š(1 âˆ’ ğ‘šğ‘šğ‘šğ‘š)
ğ›½ğ›½ğ›½ğ›½
ï¿½ + ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ +
ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ 2 + ï¿½ + ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ ğ‘šğ‘šğ‘šğ‘š2
ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰) ğ‘šğ‘šğ‘šğ‘š +
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰
âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰
2

1057

2

2

Now, to simplify the above expression, we define the following quantities
ğ´ğ´ğ´ğ´ = ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)2

ğµğµğµğµ = ï¿½
ğ¶ğ¶ğ¶ğ¶ =

Therefore, the inequality above becomes
ğ´ğ´ğ´ğ´ğ‘šğ‘šğ‘šğ‘š2 +

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

< ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰) + ï¿½

ğ›½ğ›½ğ›½ğ›½

âˆšğ‘‰ğ‘‰ğ‘‰ğ‘‰

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ .

2

+ ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½

2

ğµğµğµğµ + ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½
.
ğ‘˜ğ‘˜ğ‘˜ğ‘˜

ï¿½1 + ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰)ï¿½ 2 2
ğµğµğµğµ 2
(ğ‘šğ‘šğ‘šğ‘š âˆ’ ğ‘šğ‘šğ‘šğ‘š) +
(ğ‘šğ‘šğ‘šğ‘š âˆ’ ğ‘šğ‘šğ‘šğ‘š) + ğµğµğµğµğ‘šğ‘šğ‘šğ‘š2 < ğ´ğ´ğ´ğ´ + ğµğµğµğµ,
ğ‘˜ğ‘˜ğ‘˜ğ‘˜
ğ‘˜ğ‘˜ğ‘˜ğ‘˜

which can be further simplified to

(ğ´ğ´ğ´ğ´ + ğµğµğµğµ + ğ¶ğ¶ğ¶ğ¶)ğ‘šğ‘šğ‘šğ‘š2 âˆ’ ğ¶ğ¶ğ¶ğ¶ğ‘šğ‘šğ‘šğ‘š < ğ´ğ´ğ´ğ´ + ğµğµğµğµ.

To make the above inequality concrete, we will try reasonable values of the variables, which we
actually used in our simulations in Section 4. Specifically, we used ğ‘˜ğ‘˜ğ‘˜ğ‘˜ = 22000 hash functions, ğ‘‰ğ‘‰ğ‘‰ğ‘‰ =
10816 streams, and we suppose for worst-case analysis that ğœ–ğœ–ğœ–ğœ–(ğ‘‰ğ‘‰ğ‘‰ğ‘‰) and ğœ–ğœ–ğœ–ğœ–1 (ğ‘‰ğ‘‰ğ‘‰ğ‘‰) achieve their maximum
values of 5Ã—10âˆ’5 and 5Ã—10âˆ’4 , respectively. Therefore,
ğ´ğ´ğ´ğ´ = 2.5Ã—10âˆ’9

ğµğµğµğµ = 0.00011025

ğ¶ğ¶ğ¶ğ¶ â‰ˆ 0.000045464.

Hence, the quadratic inequality we are supposed to solve becomes
(0.00015572)ğ‘šğ‘šğ‘šğ‘š2 âˆ’ (0.000045464)ğ‘šğ‘šğ‘šğ‘š < 0.00011025,

from which it follows that for this inequality is satisfied only if

âˆ’0.708018 < ğ‘šğ‘šğ‘šğ‘š < 0.999977.

2

1058	

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

Since the Jaccard similarity 0 â‰¤ ğ‘šğ‘šğ‘šğ‘š â‰¤ 1, then this means that for almost all values of the Jaccard
similarity (unless the two sets are identical whereby ğ‘šğ‘šğ‘šğ‘š = 1), MinHash + HLL should attain a lower
error than the Inclusion-Exclusion method. In other words, we should expect MinHash + HLL to
generally always have a lower error than the Inclusion-Exclusion Method.
But, we also have seen that Inclusion-Exclusion can be much faster than MinHash + HLL, so
if we slightly weaken this inequality such that the error of Inclusion-Exclusion is similar to that of
MinHash + HLL, for what values of the Jaccard similarity ğ‘šğ‘šğ‘šğ‘š would we prefer to therefore use
Inclusion-Exclusion instead? In other words, for what values of ğ‘šğ‘šğ‘šğ‘š and some given tolerance 0 < ğ›¾ğ›¾ğ›¾ğ›¾ <
1, when should we expect that
(1 + ğ›¾ğ›¾ğ›¾ğ›¾)ï¿½(0.00015572)ğ‘šğ‘šğ‘šğ‘š2 âˆ’ (0.000045464)ğ‘šğ‘šğ‘šğ‘šï¿½ > 0.00011025.

It appears that answer is that for extreme values of of Jaccard similarity, then we should use the
Inclusion-Exclusion method over MinHash + HLL, as it will achieve a comparable error to MinHash +
HLL but is faster than MinHash + HLL. For instance, for ğ›¾ğ›¾ğ›¾ğ›¾ = 0.25, the solution is that
ğ‘šğ‘šğ‘šğ‘š > 0.912436.

Empirically, as we will show in Section 5, it appears that we can further loosen this threshold to ğ‘šğ‘šğ‘šğ‘š â‰¥
0.5 as we discuss next, to use in our proposed algorithm in Section 3, which is a hybrid combination
of MinHash + HLL and the Inclusion-Exclusion method.

5 Empirical Results and Conclusion
For our simulations, we constructed two sets A and B of random numbers with predetermined
intersection ratio and where the size of each set can also be specified. Here, we define intersection ratio
to mean the proportion of B that is in A, where |ğ´ğ´ğ´ğ´| â‰¥ |ğµğµğµğµ|, without loss of generality. More formally, the
intersection ratio (in some literature is called the overlap) is defined to be:
|ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ|
.
ğ¼ğ¼ğ¼ğ¼ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ¼ğ¼ğ¼ğ¼ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ‘‰ğ¼ğ¼ğ¼ğ¼ğµğµğµğµğµğµğµğµğµğµğµğµ ğ‘…ğ‘…ğ‘…ğ‘…ğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµğµ =
|ğµğµğµğµ|

	

Pradeep Javangula et al. / Procedia Computer Science 108C (2017) 1050â€“1059

We varied the size of the two sets on a log scale from 3 to 6 (i.e. from 1000 to 1000000) as
well as the intersection ratio of the two sets in the range [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99] and
observed how the error rate of the two methods, Inclusion-Exclusion and MinHash + HLL, compared.
We used k=22000 hash functions for all of our simulations.
The empirical results confirm the theory in section 4 and 5 and justify our criteria on |B|/|A|.
The results also display the accuracy of our hybrid model (figure above).
In the implementation of the algorithm, the Jaccard Similarity is just an estimator of the
actual Jaccard Similarity, therefore as a caution, we recommend a higher level of ğ›¼ğ›¼ğ›¼ğ›¼ (i.e. ğ›¼ğ›¼ğ›¼ğ›¼ = 0.5) to
compensate for the possible error in the estimates.

In conclusion, we should say that although the problem of computing the union |ğ´ğ´ğ´ğ´ âˆª ğµğµğµğµ| of two large
segments A and B has been well-studied and there are many viable probabilistic approaches, computing
the overlap (or intersection) |ğ´ğ´ğ´ğ´ âˆ© ğµğµğµğµ| is not as well-studied, as well as the overlap for more than two
segments. Here, we explored two probabilistic approaches as an alternative to the impractical brute force
approach, and found that a novel combination of MinHash + HLL and Inclusion-Exclusion based on a
Jaccard similarity threshold seems to be the most viable approach as it consistently achieves a lower
error percentage and has a very reasonable running time for large segments. Our results are supported
both by theory and experiment, making it a practical and reliable for computing market segment
overlaps.

References
Broder, Andrei Z. (1997). On the resemblance and containment of documents. Compression
and Complexity of Sequences: Proceedings. Positano, Amalfitan Coast, Salerno, Italy,
June 11-13, 1997: pp. 21-29
Flajolet, P.; Fusy, E.; Gandouet, O.; Meunier, F. (2007). HyperLogLog: the analysis of
a near-optimal cardinality estimation algorithm. AOFA â€˜07: Proceedings of the 2007
International Conference on the Analysis of Algorithms
McCormick, Chris (2015). Example Python code for comparing documents using MinHash.
GitHub Repository. https://github.com/chrisjmccormick/MinHash
Vassilvitskii, Sergei (2011). COMS 6998-12: Lecture 1 Notes
http://www.cs.columbia.edu/~coms699812/lecture1.pdf.
Zhu, Eric (2016). Probabilistic data structures for processing very large datasets, Github
Repository https://github.com/ekzhu/datasketch

1059

