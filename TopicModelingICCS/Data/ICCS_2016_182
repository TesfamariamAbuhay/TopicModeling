Procedia Computer Science
Volume 80, 2016, Pages 1507‚Äì1518
ICCS 2016. The International Conference on Computational
Science

WOWMON: A Machine Learning-based ProÔ¨Åler for
Self-adaptive Instrumentation of ScientiÔ¨Åc WorkÔ¨Çows
Xuechen Zhang1 , Hasan Abbasi2 , Kevin Huck3 , and Allen D. Malony3
1

Washington State University Vancouver, Vancouver, Washington, U.S.A
xuechen.zhang@wsu.edu
2
Oak Ridge National Laboratory, Oak Ridge, Tennessee, U.S.A.
habbasi@ornl.gov
3
University of Oregon, Eugene, Oregon, U.S.A
khuck@cs.uoregon.edu, malony@cs.uoregon.edu

Abstract
Performance debugging using program proÔ¨Åling and tracing for scientiÔ¨Åc workÔ¨Çows can be
extremely diÔ¨Écult for two reasons. 1) Existing performance tools lack the ability to automatically produce global performance data based on local information from coupled scientiÔ¨Åc
applications of workÔ¨Çows, particularly at runtime. 2) ProÔ¨Åling/tracing with static instrumentation may incur high overhead and signiÔ¨Åcantly slow down science-critical tasks. To gain more
insights on workÔ¨Çows we introduce a lightweight workÔ¨Çow monitoring infrastructure, WOWMON (WOrkÔ¨ÇoW MONitor), which enables user‚Äôs access not only to cross-application performance data such as end-to-end latency and execution time of individual workÔ¨Çow components
at runtime, but also to customized performance events. To reduce proÔ¨Åling overhead, WOWMON uses adaptive selection of performance metrics based on machine learning algorithms
to guide proÔ¨Ålers collecting only metrics that have most impact on performance of workÔ¨Çows.
Through the study of real scientiÔ¨Åc workÔ¨Çows (e.g., LAMMPS) with the help of WOWMON,
we found that the performance of the workÔ¨Çows can be signiÔ¨Åcantly aÔ¨Äected by both software
and hardware factors, such as the policy of process mapping and in-situ buÔ¨Äer size. Moreover,
we experimentally show that WOWMON can reduce data movement for proÔ¨Åling by up to 54%
without missing the key metrics for performance debugging.
Keywords: TAU, ScientiÔ¨Åc workÔ¨Çows, Performance monitoring

1

Introduction

Data-intensive knowledge discovery requires scientiÔ¨Åc applications to run concurrently with
analytics and visualization codes as workÔ¨Çows. These coupled applications can be executed
in situ for timely output inspection and knowledge extraction. Performance debugging for
scientiÔ¨Åc workÔ¨Çows can be more diÔ¨Écult than that for stand-alone applications using existing
Selection and peer-review under responsibility of the ScientiÔ¨Åc Programme Committee of ICCS 2016
c The Authors. Published by Elsevier B.V.

doi:10.1016/j.procs.2016.05.474

1507

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

high-performance computing (HPC) performance tools [20, 2] for two reasons. First, they
lack the ability to produce global performance data based on local data from multiple coupled
applications at runtime. Without the global data, for example, it is diÔ¨Écult to observe the total
amount of time that a scientiÔ¨Åc workÔ¨Çow used to process data produced by an application at a
particular execution step. We refer to this time as end-to-end latency of a workÔ¨Çow. Second,
proÔ¨Åling/tracing of multiple applications with static instrumentation can incur high storage
overhead and slow down the execution of mission-critical scientiÔ¨Åc tasks.
In this paper we describe a novel monitoring infrastructure called WOWMON to gain deeper
understanding of where and when performance bottleneck happen in scientiÔ¨Åc workÔ¨Çows. It
provides three unique features: 1) online feedback for timely workÔ¨Çow tuning and adaptation
by accessing in-memory performance data; 2) global monitoring which produces global performance data, speciÔ¨Åcally used for performance debugging of workÔ¨Çows; 3) self-adaptive proÔ¨Åling
which can guide proÔ¨Ålers collecting only the metrics that have most impact on performance of
workÔ¨Çows using machine learning algorithms. More speciÔ¨Åcally, we made the following contributions in this work:
‚Ä¢ We designed simple interface for users to access in-memory performance data across multiple applications/components of workÔ¨Çows, and implemented a Ô¨Çexible and lightweight
runtime system, supporting data sampling, multiple network topologies, metric selection
for customized coverage of performance metrics, and self-adaptive proÔ¨Åling.
‚Ä¢ We implemented WOWMON based on TAU [20] and EVpath [4] libraries. With the help
of WOWMON our experiments using realistic scientiÔ¨Åc workÔ¨Çows (e.g., LAMMPS ) show
that the end-to-end latency of workÔ¨Çows can be aÔ¨Äected by the memory buÔ¨Äer size for
in-situ operations and the policy of mapping processes of applications to nodes.
‚Ä¢ We demonstrated that WOWMON can evaluate performance metrics at runtime using
feature selection algorithms, and then use its output to further reduce the volume of performance data by 54% for the LAMMPS workÔ¨Çow, while still providing in-depth insights
for end-users.
The rest of this paper is organized as follows. Section 2 discusses the existing tools related
to performance research of scientiÔ¨Åc applications. Section 3 describes the design and implementation of WOWMON. Section 4 describes and analyzes experimental results. Finally, we
conclude the paper in Section 5.

2

Related Work

Most of the previous work focused on the performance measurement and monitoring of standalone applications. For example, TAU [20] has been very popular as an HPC toolkit for performance instrumentation, measurement, analysis, storage, and visualization. By leveraging
PAPI [2] and source instrumentation, it can access both hardware counters and application
performance data in standard ways. However, TAU‚Äôs performance data analysis is typically
performed after data has been written to disk-resident logs, or in a central location. This
restricts the scalability of online monitoring and analysis tasks.
An online monitoring infrastructure is needed to capture transient eÔ¨Äects of data-driven behaviors. Although many works have been proposed for this purpose, none of them was designed
for capturing performance of workÔ¨Çows. With respect to instrumentation, a salient feature of
1508

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

the performance measurement tool Paradyn [13] is Ô¨Çexible selection of metric subsets for binary instrumentation at runtime, which might take seconds to Ô¨Ånish. In contrast, WOWMON
creates initial instrumentation points based on a priori knowledge using the simple WOWMON
API. WOWMON‚Äôs runtime library supports online reconstruction of metric sets in networking
layers for reducing monitoring overhead. With respect to online data access, TAUg [10] was
designed to collect performance data of MPI processes for stand-alone applications. Roth et
al. [19] presented an online performance diagnosis system, focusing on optimization of problem
search strategies for Ô¨Ånding bottlenecks of large-scale stand-alone applications. The Ganglia
distributed monitoring system [12] is widely used in both enterprise and HPC domains. However, it only targets on system metrics such as CPU idle time. WOWMON needs to collect
source-level data (e.g., function execution time) as well as track system-level events because
both are critical for the analysis of the workÔ¨Çow performance as shown in Section 4.
Other application-steering software may have built-in monitoring modules. An example is
Peridot [6], which allows programmers to guide analysis process with query and then interacts
with runtime systems. WOWMON can also provide feedback for optimization of the metric
sets. Moreover, it provides key services for performance diagnosis of a workÔ¨Çow not a standalone application. For the latter, performance steering has been well studied. Autopilot [18]
used classiÔ¨Åcation algorithms to produce the hints of making resource management decision
based on collected performance data. WOWMON can also leverage learning algorithms [9]
in order to evaluate importance of metrics. Eisenhauer et al. [3] proposed a steering system
working with multiple collaborated users. Falcon [7] supports online interaction with end users
of complex scientiÔ¨Åc simulations. Tapus et al. [21] proposed a steering approach, which takes
into account the performance characteristics of linked libraries of binaries.
In summary, WOWMON is the only system, which is designed for performance diagnosis
and steering of the scientiÔ¨Åc workÔ¨Çows composed of in-situ analytics.

3

The Design of WOWMON

We have three objectives in the design of WOWMON: 1) accessing in-memory data structures
for collecting online performance data; 2) tracking global performance data using the local data
collected from individual workÔ¨Çow components; 3) providing a Ô¨Çexible and lightweight networking layer which can support self-adaptive proÔ¨Åling/tracing using machine learning algorithms.
In addition, WOWMON provides simple APIs for end users to create and track timers, specify
system and application events of interests, and customize communication patterns. We will
discuss them in detail in the following sections.

3.1

Architecture Overview

The WOWMON infrastructure includes three major components, user interface (APIs), a runtime library, and a workÔ¨Çow manager. Programmers need to instrument source code using the
APIs, as discussed in Section 3.2. At runtime, WOWMON creates relay networks connecting
the processes of applications and the workÔ¨Çow manager using a network topology speciÔ¨Åed in
the parameter (WOWMON TOPO COMM ) by users (star topology is set by default). Then
software and hardware events can be added to an initial metric set (M etricSetinit ), whose
members might be dynamically selected at runtime to control the size of the set, which correlates to monitoring overhead. SpeciÔ¨Åcally, the software events can track program‚Äôs performance
such as function execution time, call depth, and memory heap size when entering and exiting
a function. And the hardware events are used to track hardware performance such as cache
1509

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

 



!

"









Zhang et al.





WOWMON Runtime



	


Data
Message




Control
Message



Figure 1: WOWMON architecture

misses, Ô¨Çoating point operations, and so on. WOWMON reads the values of the metrics from
a in-memory data structure of a proÔ¨Åler, such as TAU [20]. The data structure tracks all the
current value of the metrics in M etricSetinit . For those not strongly correlated to the endto-end latency of workÔ¨Çows, as indicated by the outputs of machine learning algorithms, the
workÔ¨Çow manager can at runtime specify another set of metrics M etricSetinterest to replace
M etricSetinit . M etricSetinterest needs to be a subset of M etricSetinit . And only performance
data for the metrics in M etricSetinterest are transferred to the workÔ¨Çow manager. Because
the size of M etricSetinterest may be signiÔ¨Åcantly smaller than M etricSetinit , the monitoring
overhead of WOWMON can be reduced as shown in Section 4.4.
Function
WOWMON REGISTER VIEW()
WOWMON ADD EVENTS()
WOWMON GET GLOBAL DATA()
WOWMON DEREGISTER VIEW()
WOWMON INIT TIMER()
WOWMON TRACK TIMER()

Description
Establish connection to runtime
Track hardware/software events
Notify the networking layer to send data
Disconnect from the runtime
Create a user timer
Track a user timer

Table 1: A description of WOWMON APIs

3.2

User Interface

The user interface (APIs) of WOWMON is designed to be easy to use, and callable from C,
C++, and FORTRAN. The functions listed in Table 1 work synergistically with WOWMON
runtime to fulÔ¨Åll user‚Äôs needs on performance monitoring. The APIs include six functions.
WOWMON REGISTER VIEW() creates data buÔ¨Äers and connections to the runtime system.
With this function users can specify a network topology and name a communicator. WOWMON ADD EVENTS() adds events to M etricSetinit . For example, a software event can be
added to track memory heap size when entering a particular function having the signature string
1510

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

‚Äùvoid compute and send(bond record ptr) [bonds.c 398,1-469,1]‚Äù 1 . Function signatures can be
obtained using the existing proÔ¨Åling tools, such as TAU. WOWMON GET GLOBAL DATA()
is called to send performance data to the workÔ¨Çow manager. For data sampling users can
specify a subset of processes as the samples of proÔ¨Åling data using WOWMON PATTERN,
which should be in the range of 0 to nprocs, which is the total number of processes of an
application. When it is set to i, only data from the process of rank 0 to i ‚àí 1 are collected
and sent to the workÔ¨Çow manager. By default it is set to nprocs. This feature is very useful
for reducing communication overhead when workÔ¨Çows are executed at scale with thousands of
processes. Data collection can be disabled by setting WOWMON PATTERN to 0 when users
are not interested in the metrics from a particular component or the latency between directly
connected components. When a program is Ô¨Ånalized, WOWMON DEREGISTER VIEW() is
needed to disconnect from runtime and clean up state buÔ¨Äers. WOWMON INIT TIMER() and
WOWMON TRACK TIMER() are called to create and track a user timer placed at a speciÔ¨Åc
location in source code.

3.3

The Runtime Library

In the design of WOWMON runtime, we optimize its proÔ¨Åling operations, buÔ¨Äer management,
and communication considering both portability and scalability. Three components, including
a proÔ¨Åler, a buÔ¨Äer manager, and a relay network, interact with the workÔ¨Çow manager to achieve
lightweight monitoring, as shown in Figure 1.
The proÔ¨Åler maintains in-memory data structures to keep tracking of the values of timers
and events instrumented by programmers. WOWMON uses the existing proÔ¨Åling software such
as TAU and PAPI for this purpose, although other tools can be supported easily because only
‚àº50 lines of code are proÔ¨Åler-dependent. When TAU is used as the proÔ¨Åler, WOWMON calls
two key functions TAU GET EVENT NAMES() and TAU GET FUNC VALS() [22] to read
the values of the metrics in M etricSetinterest and stores them in data buÔ¨Äers.
The buÔ¨Äer manager tracks M etricSetinterest and M etricSetinit for each application of a
workÔ¨Çow. Based on M etricSetinterest it reads in-memory proÔ¨Åles, creates buÔ¨Äers for data
messages, and then sends those messages to the workÔ¨Çow manager. As a receiver, it also updates
M etricSetinterest when control messages for adaptive proÔ¨Åling are received. The format of the
data messages is composed of both data Ô¨Åelds, each corresponds to a metric in M etricSetinterest ,
and meta-data Ô¨Åelds such as application ID, process ID, and communicator ID, which are then
used by the workÔ¨Çow manager to identify the messages from various running instances and
produce global performance data (e.g., end-to-end latency of workÔ¨Çows) based on proÔ¨Åled local
information.
The relay network is a thin communication layer between the runtime of applications
(sources) and workÔ¨Çow managers (sinks). The messages sent from the source to sink nodes may
be processed through multi-level relay nodes in order to remove a networking bottleneck caused
by a centralized workÔ¨Çow manager and improve the scalability of the network. EVpath [5] is
selected for relay network management for its proven performance on high-end machines and
support of multiple networking drivers (e.g., TCP/IP, InÔ¨Åniband [14], and ENET [17] etc). If
WOWMON TOPO COMM is set to star, all the sources are directly connected to the workÔ¨Çow
manager. This topology should only be used for small scale runs. If WOWMON TOPO COMM
is set to tree, a network having a spanning tree topology is created for the applications having
more than 128 processes. In this scenario, only a limited number of relay nodes are directly
1 compute and send() is an expensive function in the Bonds code of the LAMMPS workÔ¨Çow. More details
of the workÔ¨Çow are presented in Section 4.1.

1511

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

WOWMON Runtime
MCoordinator
Data
e
Message

Control
Message




	

			
	

Figure 2: An example of a workÔ¨Çow manager using machine learning algorithms provided by
Weka to select correlated metrics.
connected to the workÔ¨Çow manager. The relay nodes periodically send the summarized performance data received in a period to the workÔ¨Çow manager for reduced overhead of data transfer
and a more balanced load distribution.

3.4

Self-adaptive ProÔ¨Åling

A workÔ¨Çow manager, named M Coordinator, is designed to help select metrics according to their
impact on end-to-end latency, rather than acting only as a dummy manager just collecting local
data. As shown in Figure 2, M Coordinator collects data from workÔ¨Çow components and then
converts them to software-compatible formats, such as attribute-relation Ô¨Åle format (ARFF)
required by the Weka [8] software. In the next step, attributes selection algorithms are executed
to rank the metrics in M etricSetinit or M etricSetinterest . SpeciÔ¨Åcally, we use an algorithm
called CfsSubsetEval in Weka to evaluate the worth of a subset of metrics by considering the
individual predictive ability of each metric along with the degree of redundancy between them.
Subsets of metrics that are highly correlated with the latency while having low inter-correlation
are preferred [9]. Breadth-Ô¨Årst search algorithm [11] is used for metric subsets creation during
the search. In the end, the metrics in the selected subset are sent back to WOWMON runtime
via a control channel. M Coordinator can trigger the metric selection procedure both oÔ¨Ñine
and online. In addition, it needs to decide when to trigger the procedure to minimize its learning
overhead. A hybrid approach is used in the design of M Coordinator, whose metric selection
procedure can be triggered by both timers and special events, such as a moving average of the
end-to-end latency of workÔ¨Çows is 50% higher/lower than the one measured in the previous
steps.

4

Evaluation

In this section we study the impact of hardware and software factors on the performance
of realistic scientiÔ¨Åc workÔ¨Çows using WOWMON. In addition, we illustrate how its adaptive
proÔ¨Åling technique helps reduce the volume of performance data at runtime. For evaluation
we used an on-site cluster ACISS hosted at University of Oregon. The cluster includes 128 12core Intel Xeon CPU X5650 2.67 GHz nodes running RedHat Enterprise release 6.6. All nodes
are interconnected with a Voltaire Vantage 8500 10GigE network switch. The WOWMON
library and related tools were compiled with the latest release of TAU [22], EVpath [5], and
1512

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

ADIOS [1]. With respect to software conÔ¨Ågurations, QueueDepth for ADIOS is set to 20. We
run one LAMMPS process per core unless speciÔ¨Åed otherwise.

4.1

Driving ScientiÔ¨Åc WorkÔ¨Çows

We instrumented LAMMPS (Large Scale Atomic/Molecular Massively Parallel Simulator) [15]
and its analytics Bonds and Csym, which are executed concurrently as the driving scientiÔ¨Åc
workÔ¨Çow in the experiments. LAMMPS has been widely used for material science study.
Bonds reads input from LAMMPS and performs all-nearest neighbor calculation to determine
which atoms are bonds together. Csym then uses the output of Bonds to further determine
whether there are deformation zones in the material. If they are detected, Csym continues
to calculate the conditions under which a crack occurred. Therefore, its execution time and
resource utilization may change over the whole period of simulation.
We manually select 12 metrics related to key functions of the LAMMPS workÔ¨Çow for tracing.
As shown in Table 2, the metrics, such as bonds read input and csym output results, are related
to I/Os for moving data from upstream applications to downstream analytics or to disks.
And the metrics such as bonds compute send and csym compute send are related to computing
kernels of Bonds and Csym, respectively. The other metrics are used to measure memory usage
of a function. For example, csym compute send mem measures the heap size of the function
csym compute send.

4.2

The End-to-end Latency of the LAMMPS WorkÔ¨Çow

The end-to-end latency of the LAMMPS workÔ¨Çow determines the time spent on analyzing
physics of atoms using data generated by LAMMPS. We added 90 lines of code for source instrumentation of the metrics listed in Table 2. WOWMON can help capture transient behavior
of workÔ¨Çows. To demonstrate this we show a breakdown of the end-to-end latency after completion of each simulation step during the execution of the LAMMPS workÔ¨Çow. The number
of processes of LAMMPS, Bonds, and Csym are set to 128, 1, and 1, respectively.
From Figure 3, we observed that the end-to-end latency reached the maximum at the 42th
step. According to its execution time breakdown, we found that during the execution of the
workÔ¨Çow compute times of all the components did not change. In contrast, data transfer time
is increased by 110% on average for both LAMMPS and Csym. With a careful study of this
performance issues oÔ¨Ñine, we found the reason is that the ADIOS library uses in-memory
queues to buÔ¨Äer output data of upstream applications for asynchronous execution. When the
buÔ¨Äers became full after the 42th step, queuing time was dominant in the data transfer time
as well as in the end-to-end latency.

4.3

Impact of a WorkÔ¨Çow Mapping Policy

Given the same number of compute nodes, the policies of mapping processes of workÔ¨Çow components to nodes may signiÔ¨Åcantly impact the end-to-end latency of scientiÔ¨Åc workÔ¨Çows. Using
LAMMPS as an example, we demonstrate the performance diÔ¨Äerence between two mapping
policies given 11 compute nodes. More speciÔ¨Åcally, P olicyCB has Csym and Bonds placed on
a dedicated node, while LAMMPS is executed on the other 10 nodes. There is no resource
contention between LAMMPS and Csym or LAMMPS and Bonds. P olicyCL has Csym and
LAMMPS placed on the same nodes sharing memory and CPU resources. The above policies
are diÔ¨Äerent from the mapping policy used in the previous experiments in which processes use
dedicated cores. In the experiment, LAMMPS, Bonds and Csym are conÔ¨Ågured with 128, 1,
1513

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Metric name
bonds read input
bonds list output
bonds compute send

bonds read input mem
bonds compute send mem
csym read input
csym compute send
csym output results

csym read input mem
csym compute send mem
lammps start timer
csym stop timer

Zhang et al.

Description
Gives us a handle on throughput for reading data in
Bonds.
Gives us a handle on throughput for moving data out
of Bonds.
Monitors the main computation function in Bonds.
Most of its time is spent on building the adjacentformat output.
The memory usage for executing bonds read input()
The
memory
usage
for
executing
bonds compute send()
Gives us a handle on throughput for reading data in
Csym.
Monitors the main computation function in Csym.
Most of its time is spent on converting input data.
The corresponding function,
which follows
csym output results(), denotes the end of the
workÔ¨Çow and where we end the latency measurement.
The
memory
usage
for
executing
csym read input mem()
The
memory
usage
for
executing
csym compute send mem()
The timer is triggered when the generated data is
placed in buÔ¨Äers on LAMMPS end.
The timer is triggered when the last analytic Ô¨Ånishes.

Table 2: The selected metrics for the LAMMPS workÔ¨Çow

Figure 3: An execution time breakdown. X-(Tran) and X-(Comp) denote data transfer time
and compute time of application X (Csym, Bonds, and LAMMPS), respectively.

and 1 processes, respectively. The end-to-end latency of each step with both P olicyCB and
P olicyCL are shown in Figure 4. The average end-to-end latencies are 35.6s and 40.0s for
1514

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

Figure 4: The end-to-end latency of the LAMMPS workÔ¨Çow with diÔ¨Äerent policies of mapping
processes of in-situ analytics to the compute nodes.

P olicyCB and P olicyCL , respectively. One observation is that from the 1st to 14th step the
end-to-end latency with P olicyCB is higher. When the buÔ¨Äers for storing data for in-situ analysis are full after the 20th step, P olicyCB has smaller latency than P olicyCL since LAMMPS
is more compute-intensive than Bonds. And extra interference between LAMMPS and Csym
with P olicyCL caused the higher latency.

4.4

EÔ¨Äectiveness of Self-adaptive ProÔ¨Åling

In this section, we study the correlation between selected proÔ¨Åling metrics and the performance
of the LAMMPS workÔ¨Çow. In the experiment, the workÔ¨Çow is executed with 64 processes
for LAMMPS, 2 processes for Bonds, and 1 process for Csym. Using the performance data
collected from 1000 simulation steps as training data, the machine learning algorithm found
one best metric subset including bonds read input, csym read input, and csym compute send.
This result is consistent with our understanding that Csym is the bottleneck of the workÔ¨Çow
for lack of parallelism in its design. We further measured the execution times of the functions
corresponding to the selected metrics and found that they together account for about 46% of
the average end-to-end latency. Figure 5 shows the results. This explains why they can be
representative of the overall latency.
In addition, we evaluate the predictability of the models created based on either the selected
metrics or the original metric set using a regression tree algorithm [23]. In detail, we created two
machine learning models, M odel interest based on the three selected metrics and two timers,
and M odel init based on the metrics in M etricSet init as presented in Section 3.4. Both
models use the selected metrics to predict the end-to-end latency of the workÔ¨Çow. 80% and
20% of the training set are used for creating a model and model validation, respectively. The
validation results show that M odelinterest and M odelinit have relative absolute errors of 9.4%
and 13.6%, respectively. This means M etricSetinterest has better predictability than M odelinit
because the accuracy of M odel interest is improved for less noises from the low-impact metrics
in M etricSetinterest . Therefore, using M etricSetinterest for monitoring can reduce the total
amount of data transferred by 54% for the LAMMPS workÔ¨Çow without losing key metrics for
performance debugging.
1515

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

Figure 5: Execution times of the key functions of the LAMMPS workÔ¨Çow over 100 simulation
time steps.

Figure 6: Total execution time of the LAMMPS workÔ¨Çow. TAU: applications run with the
TAU proÔ¨Åler; WOWMON: applications run with WOWMON.

4.5

Overhead Analysis

There are three major sources of overhead in WOWMON. The Ô¨Årst is proÔ¨Åling overhead, which
has been well studied in many existing tools. WOWMON relies on these tools to provide
scalable proÔ¨Åling services on various machines [16]. The second overhead is networking latency.
We experimentally study the networking overhead of WOWMON compared to TAU, which
is the default proÔ¨Åler in WOWMON. In the experiment, LAMMPS workÔ¨Çow is executed on
ACISS with increased parallelism of LAMMPS from 32, 64, to 128 and one process for Bonds.
As shown in Figure 6, the execution time with WOWMON is on average 7% more than that
running with TAU alone. Its overhead grows sublinearly as the number of processes is increased.
Third, WOWMON causes the memory overhead for maintaining performance data buÔ¨Äer at
runtime. The size of the buÔ¨Äer is determined by the number of metrics in M etricSetinterest .
For the LAMMPS workÔ¨Çow its buÔ¨Äer size is less than 20 KB with 128 processes.
1516

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

5

Zhang et al.

Conclusion and Future Work

In the paper we present the design and implementation of WOWMON, a lightweight and powerful monitoring infrastructure, speciÔ¨Åcally designed for scientiÔ¨Åc workÔ¨Çows with in-situ analytics
targeting large-scale computing platforms. It enables the online observation of adaptive workÔ¨Çow behavior. Evaluation with real scientiÔ¨Åc workÔ¨Çows shows that workÔ¨Çow performance can
be aÔ¨Äected by both software and hardware factors, such as the policy of process mapping and
the size of memory buÔ¨Äer for in-situ processing. In addition, we show that WOWMON can
automatically rank the correlation of each metric relative to the end-to-end latency of workÔ¨Çows
using machine learning algorithms and reduce monitoring overhead with self-adaptive proÔ¨Åling/tracing. The overhead of WOWMON is 7% on average compared to the legacy proÔ¨Åling
tools, making it well suit for online performance monitoring and analysis.
Future work for WOWMON will focus on the study of the eÔ¨Äect of performance metrics
across diÔ¨Äerent runs with various input parameters to analytics (e.g., R 1 which determines
how close atoms are for Bonds). In addition, with the help of WOWMON, we need to further understand the changes of data-driven behaviors of scientiÔ¨Åc workÔ¨Çows in emerging HPC
platforms with deep memory hierarchies for caching in-situ output data.

6

Acknowledgements

We are grateful to the anonymous reviewers. We thank Jai Dayal and Matthew Wolf for
their support on the LAMMPS workÔ¨Çow instrumentation. We also thank Wyatt Spear for
many discussions during this work. This research was partially supported by DOE grant DESC0012381 funded by the ScientiÔ¨Åc Data Management, Analysis and Visualization (SDMAV)
program and WSU Seed Grant.

References
[1] Adaptable IO System (ADIOS).
https://www.olcf.ornl.gov/center-projects/adios/.
[2] S. Browne, J. Dongarra, N. Garner, G. Ho, and P. Mucci. A Portable Programming Interface
for Performance Evaluation on Modern Processors. International Journal of High Performance
Computing Applications, 14(3):189‚Äì204, 2000.
[3] Greg Eisenhauer and Karsten Schwan. An object-based infrastructure for program monitoring and
steering. In 2nd SIGMETRICS Symposium on Parallel and Distributed Tools (SPDT‚Äô98), pages
10‚Äì20, 1998.
[4] Greg Eisenhauer, Matthew Wolf, Hasan Abbasi, and Karsten Schwan. Event-based systems:
Opportunities and challenges at exascale. DEBS ‚Äô09, pages 2:1‚Äì2:10. ACM, 2009.
[5] EVpath Library.
http://svn.cc.gatech.edu/kaos/evpath/.
[6] Michael Gerndt, Andreas Schmidt, Martin Schulz, and R Wismuller. Performance analysis for
teraÔ¨Çop computers: a distributed automatic approach. In 10th Euromicro Workshop on Parallel,
Distributed and Network-based Processing, pages 23‚Äì30. IEEE, 2002.
[7] Weiming Gu, Greg Eisenhauer, Eileen Kraemer, Karsten Schwan, John Stasko, and Je rey Vetter.
Falcon: On-line monitoring and steering of large-scale parallel programs. In Proceedings of the 5th
Symposium of the Frontiers of Massively Parallel Computing, pages 422‚Äì429, 1995.
[8] Mark Hall, Eibe Frank, GeoÔ¨Ärey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H.
Witten. The weka data mining software: An update. SIGKDD Explor. Newsl., 11(1):10‚Äì18, 2009.

1517

A Machine Learning-based ProÔ¨Åler for Self-adaptive Instrumentation

Zhang et al.

[9] Mark A. Hall. Correlation-based feature selection for machine learning. Technical report, 1999.
[10] Kevin A. Huck, Allen D. Malony Sameer Shende, and Alan Morris. TAUg: Runtime Global
Performance Data Access Using MPI. In EuroPVM/MPI 2006, 2006.
[11] Richard E. Korf. Depth-Ô¨Årst iterative-deepening. ArtiÔ¨Åcial Intelligence, 27(1):97 ‚Äì 109, 1985.
[12] Matthew L. Massie, Brent N. Chun, and David E. Culler. The ganglia distributed monitoring
system: Design, implementation and experience. Parallel Computing, 30:2004, 2003.
[13] Barton P. Miller, Jonathan M. Cargille, R. Bruce Irvin, Krishna Kunchithapadam Mark D.
Callaghan, JeÔ¨Ärey K. Hollingsworth, Karen L. Karavanic, and Tia Newhall. The Paradyn Parallel
Performance Measurement Tools. Computer, 28:37‚Äì46, 1995.
[14] White Paper. Interconnect Analysis:10GigE and InÔ¨ÅniBand in High Performance Computing.
HPC Advisory Council Network of Expertise.
[15] S. Plimpton, R. Pollock, and M. Stevens. Particle-Mesh Ewald and rRESPA for Parallel Molecular
Dynamics Simulations. In Proc of the Eighth SIAM Conference on Parallel Processing for ScientiÔ¨Åc
Computing, 2007.
[16] R.Bell, A.D. Malony, and S. Shende. A Portable, Extensible, and Scalable Tool for Parallel
Performance ProÔ¨Åle Analysis. In EUROPAR‚Äô 03.
[17] Reliable UDP networking library.
http://enet.bespin.org/.
[18] Randy L. Ribler, Huseyin Simitci, and Daniel A. Reed. The autopilot performance-directed adaptive control system. In Future Generation Computer Systems, pages 175‚Äì187, 1997.
[19] Philip C. Roth and Barton P. Miller. On-line automated performance diagnosis on thousands of
processes. PPoPP ‚Äô06.
[20] S. Shende and A. D. Malony. TAU: The TAU Parallel Performance System. International Journal
of High Performance Computing Applications, pages 287‚Äì311, 2006.
[21] Cristian Tapus, I-Hsin Chung, and JeÔ¨Ärey K. Hollingsworth. Active Harmony: Towards Automated Performance Tuning. In Supercomputing 2002, 2002.
[22] TAU Software.
https://www.cs.uoregon.edu/research/tau/downloads.php.
[23] Mengzhi Wang, Kinman Au, Anastassia Ailamaki, Anthony Brockwell, Christos Faloutsos, and
Gregory R. Ganger. Storage device performance prediction with cart models. pages 588‚Äì595, 2004.

1518

