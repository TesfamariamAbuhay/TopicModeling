Available online at www.sciencedirect.com

Procedia Computer Science 9 (2012) 479 – 488

International Conference on Computational Science, ICCS 2012

Agent Based Priority Heuristic for Job Scheduling on
Computational Grids
Syed Nasir Mehmood Shah*, M Nordin B Zakaria, Ahmad Kamil Bin Mahmood,
Anindya Jyoti Pal, Nazleeni Haron
Department of Computer and Information Sciences
Universiti Teknologi PETRONAS, Bandar Seri Iskandar, 31750 Tronoh, Perak, Malaysia

Abstract
A grid is an infrastructure for resource sharing. At present, many scientific applications require high computing power in
processing, which can only be achieved by using the computational grid. For the selection and allocation of grid resources to
current and future applications, grid job scheduling is playing a very vital role for computational grids. They constitute the
building blocks for making grids available to the society. The efficient and effective scheduling policies, when assigning different
jobs to specific resources, are very important for a grid to process high computing intensive applications.
This paper presents an agent based job scheduling algorithm for efficient and effective execution of user jobs. This paper also
includes the comparative performance analysis of our proposed job scheduling algorithm along with other well known job
scheduling algorithms considering the quality of service parameters like waiting time, turnaround time, response time, total
completion time, bounded slowdown time and stretch time. We also conducted the QoS based evaluation of the scheduling
algorithms on an experimental computational grid using real workload traces.
Experimental evaluation confirmed that the proposed grid scheduling algorithms posses a high degree of optimality in
performance, efficiency and scalability. This paper also includes a statistical analysis of real workload traces to present the nature
and behavior of jobs.

Keywords: Distributed systems; Cluster; Grid computing; Software agent, Grid scheduling; Workload modeling; Performance evaluation;
Simulation; Load balancing; Task synchronization; Parallel processing.

1. Introduction
A grid is a computational system consisting of large number of geographically distributed and heterogeneous
resources that provides dependable, pervasive, consistent, and inexpensive access to high-end computational

* Corresponding author. Tel.: +60-125936195
E-mail address: nasirsyed.utp@gmail.com

1877-0509 © 2012 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
doi:10.1016/j.procs.2012.04.051

480

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

powers, beyond the capacity of even the largest parallel computer system. Job scheduling is one of the key
components of grid, which plays an important role in the efficient and effective execution of various kinds of
scientific and engineering applications [1, 2].
A number of interesting challenges have been introduced to scheduling by grid computing in which the
scheduling policies not only can manage the various resources needed in computing, but also can make the decisions
regarding the dynamic execution of jobs. Optimization of the grid performance is dependent on the scheduling
policies [1, 3, 4, 5, 11]. In order to obtain a grid environment, which works with high performance, the effective and
efficient resource management is a must. Due to the high dynamicity, scalability and heterogeneity of a grid, some
challenges then arise in the development of algorithms for scheduling to be used along with grid computing [6].
In this paper, job scheduling algorithms have been studied extensively and a new agent based hybrid priority
job scheduling algorithm (AHS) has been proposed. The proposed scheduling algorithm has shown its optimal
performance compared to the existing ones on an experimental computational grid using real workload traces. Apart
from the development of these algorithms, software has been developed to facilitate the study with a greater ease
and more user friendly manner.
This paper presents the comparative performance analysis of our proposed job scheduling algorithm with other
well known scheduling approaches; e.g.; First Come First Served (FCFS), Round Robin (RR), Proportional Local
Round Robin (PLRR), Shortest Process Next (SPN), Priority (P) and Longest Job First (LJF). We evaluated the
efficiency, performance and scalability of each scheduling algorithm on a computational grid using six key
performance parameters, i.e., average waiting time, average turnaround time, average response time, average
bounded slowdown times, total completion time and maximum job stretch times.
The structure of the paper will now be described. Section 2 is a literature review of grid scheduling
methodologies. Section 3 presents the proposed grid scheduling algorithm and section 4 is about the statistical
analysis of real workload traces. Section 5 shows the homogenous implementation of scheduling algorithms. In
section 6, the scheduling simulator’s design and development are discussed. Section 7 shows the experimental setup
and section 8 describes the performance analysis of the grid scheduling algorithms. Section 9 concludes the paper.
2. Related Research
Job scheduling plays a vital role in an efficient grid resource management. Most of the parallel jobs demand a
fixed number of processors, which are unchangeable during execution [1]. Good job scheduling policies are very
essential to manage grid systems more efficiently and productively [2].
Grid job scheduling policies can generally be divided into space-sharing and time-sharing approaches. In timesharing policies, processors are temporally shared by jobs. In space-sharing policies, conversely, processors are
exclusively allocated to a single job until its completion. The well known space-sharing policies are FCFS,
Backfilling, Job Rotate Scheduling Policy (JR), Multilevel Opportunistic Feedback (MOF), Shortest Job First (SJF),
Shortest Remaining Time First (SRTF), Longest Job First (LJF) and Priority (P) approaches. The famous timesharing scheduling policies on the other hand are Round Robin (RR) and Proportional Local Round Robin
Scheduling (PLRR) [7, 8, 9].
The FCFS is the simplest and non preemptive job scheduling algorithm. For this algorithm the ready queue is
maintained as a FIFO queue. Each new job/process is added to the tail of the ready queue and then the algorithm
dispatches processes from the head of the ready queue for execution by the CPU. A process terminates and is
deleted from the system after completing its task. The next process is then selected from the head of the ready queue
[10, 11].
The SJF algorithm takes the processes using the shortest CPU time first. For this algorithm the ready queue is
maintained in order of CPU burst length with the shortest CPU demand at the head of the queue [11]. While the LJF
algorithm takes the processes that use the longest CPU time first. For this algorithm the ready queue is maintained in
order of CPU demands (runtime) in descending order [11, 12].
Round-robin scheduling [11, 13] is a simple way of scheduling in which all processes form a circular array and
the scheduler gives control to each process at a time. The ready queue for this algorithm is maintained as a FIFO
queue. A process submitted to the system is linked to the tail of the queue. The algorithm dispatches processes from
the head of the ready queue for execution by the CPU. Processes being executed are preempted on expiry of a time
quantum, which is a system-defined variable. A preempted process is linked to the tail of the ready queue. When a
process has completed its task, i.e., before the expiry of the time quantum, it terminates and is deleted from the

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

481

system. The next process is then dispatched from the head of the ready queue. This algorithm produces a good
response time as compared to other scheduling algorithms.
In the priority (P) scheduling algorithm; the processes are prioritized in accordance with their operational
significance. For this algorithm, the ready queue is maintained in the order of the system-defined priorities. Every
process is assigned a priority and a new process submitted to the system is linked to the process in the ready queue
having the same or a higher priority. The algorithm dispatches processes from the head of the ready queue for
execution by the CPU. When a process has completed its task, it terminates and is deleted from the system. The next
process afterward is dispatched from the head of the ready queue. If the priority criterion for execution is the order
of arrival of the jobs into the system, then the priority scheduling behaves like FCFS scheduling. Alternatively, if
the priority criterion is such that the jobs with shorter CPU demands are assigned higher priorities, then this makes
the priority scheduling behave like SJF scheduling [11].
Several scheduling policies have been implemented in computational grids for high performance computing. The
first come first serve (FCFS) with backfilling [14, 15] is the most commonly used; as on average, a good utilization
of the system and good response times of the jobs are achieved. However, with certain job characteristics, other
scheduling policies might be superior to FCFS. For example, for mostly long running jobs, the longest job first
(LJF) is beneficial, while the shortest job first (SJF) is used with mostly short jobs [16].
In [7], the author has performed an experimental performance analysis of three space-sharing policies (FCFS, JR
and MOF) and two time-sharing policies (Global Round Robin and Proportional Local Round Robin Scheduling)
that have been developed for grid computing. It is concluded that time-sharing scheduling policies perform better
than space-sharing scheduling policies. The RR scheduling policy is extensively used for job scheduling in grid
computing [7, 17]. In [18], the authors have performed an analysis of the processor scheduling algorithms using a
simulation of a grid computing environment. Three space-sharing scheduling algorithms (FCFS, SJF and P) have
been considered for simulation.
Two fundamental issues that have to be considered for the performance evaluation and comparison of grid
scheduling algorithms are firstly, representative workload traces are required to produce dependable results [19], and
secondly, a good testing environment should be set up, most commonly through simulations. A standard workload
should be used as a benchmark for evaluating scheduling algorithms [20, 21].
3. Proposed Agent Based Hybrid Priority Scheduling Algorithm
Grid scheduling is an NP complete problem, i.e., no such deterministic algorithm exists which can generate an
optimum solution in polynomial time. To predict the demand of grid jobs in a dynamic scheduling environment
however is not simple. The dynamic scheduling means jobs that are arriving in the system with different processing
demands and have different priorities. The priorities are assigned to the jobs on the basis of user classifications.
Agent based Hybrid Priority Scheduling (AHS) uses task agent for job distribution in such a way to achieve the
optimum solution. Task agent receives the jobs/processes from the users, and distributes them among different
prioritize global queues based on user levels. Number of global queues can be customized in the grid system
according to defined priority classifications at global level. Block diagram of AHS is shown in Figure 1.

Fig. 1. Block Diagram of AHS

482

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

AHS uses agent based job distribution strategy at global level for optimal job distribution based on user levels
and job priorities. AHS uses its Hybrid priority job scheduling strategy at local level for efficient and effective
execution of jobs. Algorithms for each proposed strategy at global and local levels are as follows:
3.1. Agent based Job Distribution Strategy
Step 1.

Set the number of global queues for the computational grid

Step 2.

Prioritization of global queues on the basis of job priorities and user levels

Step 3.

Define the value of priority threshold for each global queue based on priority classification; e.g. Threshold1

Priority (global queue1)>> Priority (global queue2)>> Priority (global queue3)
for global queue1, Threshold2 for global queue2 and Threshold3 for global queue3
Step 4.

Task agent receives the user jobs/processes and distributes them among the global queues while considering
their priorities

Step 5.

If a process priority <= Threshold1 then
Assign the process to the global queue1
else If a process priority <= Threshold2 then
Assign the process to the global queue2
else
Assign the process to the global queue3
end if

Step 6.

if global queue1 is not empty then
Distribute the processes from global queue1 among the compute nodes of a grid
else if global queue2 is not empty then
Distribute the processes from global queue2 among the compute nodes of a grid
else Distribute the processes from global queue3 among the compute nodes of a grid
end if

3.2. Hybrid Priority Job Scheduling Strategy
Step 1.

Sort the processes in the local queue on the basis of process priorities

Step 2.

Allocate the CPU to a process that has the highest priority

Step 3.

If two or more processes have same priorities then
Sort the processes on the basis of process demands
Allocate the CPU to the process that has shortest runtime (i.e., minimum CPU demand)
end if

Step 4.

if two or more processes have equal priorities and equal runtime demands then
Allocate the CPU to processes according to the First Come First Served policy
end if

4. Statistical Analysis of Real Workload Traces
In [12, 22], a comprehensive statistical analysis has been carried out for a variety of workload traces on clusters
and grids. We reproduced the graphs of [22, 23] to study the behaviour of the dynamic nature of workload ‘LCG1’
using our developed SyedWSim [24]. The total numbers of jobs in ‘LCG1’ are ‘188041’. We looked at the number
of jobs arriving in each 64 second period. The number of jobs arriving in a particular period is its ‘job count’. The
left hand graph of Figure 2 shows the distribution of job counts for the whole trace. Next we performed an
autocorrelation of the job counts at different lags. The middle graph of Figure 2 shows the autocorrelation plot at
different lags. Then we performed a Fourier analysis by applying the FFT on the values of the autocorrelation
output. This is shown in the right hand graph of Figure 2.

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

483

Fig. 2. The sequence plot, autocorrelation function(ACF) and Fast Fourier transformation(FFT) for the count process of LCG1

Figure 2 depicts that, job arrivals show a diversity of correlation structures, including short range dependencies,
pseudo periodicity, and long range dependence. Long range dependencies can results in big performance
degradation, which effects should be taken into consideration for evaluation of scheduling algorithms. Real grid
workload ‘LCG1’ has shown rich correlation and scaling behaviour, which are different from conventional parallel
workload [22, 23]. ‘LCG1’ has been used in this work for performance evaluation of scheduling algorithms on an
experimental computational grid.
5. Homogeneous Implementation of Proposed Scheduling Algorithms
We used a master/slave architecture for implementation of job scheduling algorithms, as shown in Figure 3. One
processor is dedicated as the master processor among the cluster nodes. The master processor is responsible for
distribution of the workload among the slave processors using round robin allocation strategy (i.e. 1, 2, 3…. n, 1) for
parallel computation.

Fig. 3. Block diagram of master/slave architecture

The same algorithm, either FCFS or AHS, is used on each slave processor. Once computation is complete, the
results are sent to the master processor.
6. Scheduling Simulator Design and Development
The MPJ-express is widely used Java message passing library that allows writing and executing parallel
applications for distributed and multicore systems. We developed a Java based simulator using MPJ-express API to
evaluate the efficiency of our proposed scheduling algorithms. The metadata for each process includes its ID, its

484

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

arrival time, its CPU time and the number of slaves that the job is to be divided between. The simulation software
encounters the arrival time for each process and then submits processes to the system. The software has two main
programs. One program runs on the master node (SimM). The other program runs on each slave processor (SimS).
SimM accepts a workload and distributes among slave processors using RR. SimM receives notification from each
slave processor for each job (or part of a job) that has finished. Each slave runs SimS and computes the average
waiting time, the average turnaround time and the average response times. SimS processes the metadata for the list
of processes that have been assigned to it. Upon completion of a process, SimM is informed. SimS keeps a detailed
record of the processes being run on the slave - process ID; submit time; CPU time; time quantum.
All slaves use the same scheduling algorithm, which is input by the user of SimM. The user can select one of a
range of algorithms including the newly developed one, AHS, as well as established ones, PLRR, FCFS, SJF, SPN,
RR and P. The purpose of the simulator is to produce a comparative performance analysis of scheduling algorithms.
7. Experimental Setup
The experiments made use of a HPC facility in the High Performance Computing Centre at Universiti Teknologi
PETRONAS. We ran our experiment using a cluster of 128 processors. The ‘hpc.local’ was used as the default
execution site for job submission. A detailed experimental setup is shown in Table 1.
Table 1. Experimental Setup
Name

Type

Location

Configuration

gillani

Shell terminal

Lab
Workstation

Intel Core 2 Duo CPU 2.0GHZ
2 GB Memory

hpc.local

Execution site

HPC facility

128 Core Intel(R) Itanium2(R)
Processor 9030
arch
: IA-64
CPU MHz : 1.6 GHz

8. Performance Analysis of Grid Scheduling Algorithms
Experiments have been performed on an experimental computational grid using ‘LCG1’. Experimentation
includes the efficiency, performance and scalability test of scheduling algorithms under an increased real workload
and increased processors availability. Two data sets have been formed, first by using ‘10%’, and second by using
‘20%’ of the LCG1 workload (i.e. 18804, and 37608 processes), respectively. The ‘runtime’ attribute is given for
each process in ‘LCG1’. The ‘runtime’ is taken as CPU time in this experiment. A series of experiments have
carried on experimental grid by varying the number of CPUs successively from ‘16’ to ‘128’. This experimentation
had used ‘50’ units as the fixed time quantum.

Fig. 4. Average waiting times of scheduling algorithms for 10% and 20% workload of LCG1

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

Fig. 5. Average turnaround times of scheduling algorithms for 10% and 20% workload of LCG1

Fig. 6. Average response times of scheduling algorithms for 10% and 20% workload of LCG1

Fig. 7. Average slowdown times of scheduling algorithms for 10% and 20% workload of LCG1

485

486

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

Fig. 8. Total completion times of scheduling algorithms for 10% and 20% workload of LCG1

Fig. 9. Maximum job stretch time of scheduling algorithms for 10% and 20% workload of LCG1

8.1. Average Waiting Time Analysis
The Waiting Time is the time for which a process waits from its submission to completion in the local and global
queues [11], [25]. Figure 4 illustrates the average waiting times for scheduling algorithm using LCG1 workload
trace of ‘18804’ and ‘37608’ processes. It has been found that AHS and SPN scheduling algorithms have shown the
best performance while producing the shortest average waiting times as compared to other scheduling algorithms. It
also presents that RR has shown the average performance but result in higher average waiting time measures as
compared to those for AHS and SPN. Moreover, the RR, PLRR, P, FCFS and LJF have shown the worst
performance w. r. t. the average waiting time measures. The LJF has shown to have the longest average waiting
times. All scheduling algorithms have shown the improvement w. r. t. average waiting times by varying number of
CPUs successively from ‘16’ to ‘128’. As a result, AHS has shown the optimal average waiting times for ‘10%’ and
‘20%’ workload of LCG1.
8.2. Average Turnaround Time Analysis
The Turnaround time of the job is defined as the time difference between the completion time and release time
[11], [25]. Figure 5 shows the average turnaround times computed for each scheduling algorithm using ‘10%’ and
‘20%’ workload of LCG1. The values for average turnaround times computed by AHS are found shorter than those
for the other grid scheduling algorithms. This figure also shows that SPN has shown better performance w. r. t. the
average turnaround times. Furthermore, it is found that RR, P, PLRR, FCFS and LJF scheduling algorithms have
shown the longer average turnaround time measures.

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

487

8.3. Average Response Time Analysis
It is the amount of time taken from when a process is submitted until the first response is produced [11], [25]. In
interactive grid applications, response time is a very important parameter. Average response times computed for the
scheduling algorithms using ‘10%’ and ‘20%’ workload of LCG1, are shown in Figure 6. It is found that that
average response times computed by the RR are shorter than other scheduling algorithms. Average response times
for each algorithm have decreased by increasing the number of CPUs. It also shows that AHS and SPN algorithms
produces better average response time compared to other algorithms. However, P, PLRR, FCFS and LJF have
shown the worst performance w. r. t. average response time measures, out of which LJF results in the longest
average response times. All scheduling algorithms have shown the improvement w. r. t. average response time
measures by increasing the number of CPUs successively from ‘16’ to ‘128’.
8.4. Average Slowdown Time Analysis
Figure 7 shows the average slowdown times computed for each scheduling algorithm using ‘10%’ and ‘20%’
workload of LCG1. Figure 7 shows that RR and AHS have produced the shortest average slowdown times compared
to other scheduling algorithms. Figure 7 also presents that SPN has also shown average performance w. r. t. the
average slowdown times. It has also shown that PLRR, P, FCFS and LJF have shown the worst performance while
resulting in longer average slowdown times. LJF has shown the longest average slowdown times. As a result, RR
and AHS have shown the best average slowdown times compared to other scheduling algorithms and presented
improvement w. r. t. average slowdown times under the increasing number of CPUs successively from ‘16’ to ‘128’.
8.5. Total Completion Time Analysis
Machine Completion time is defined as the time for which a machine ‘m’ will finalize the processing of the
previously assigned tasks as well as of those already planned tasks for the machine [6]. Figure 8 shows the total
completion times computed for each scheduling algorithm using ‘10%’ workload of LCG1. Figure 8 shows that
AHS has produced the shortest total completion times compared to the other scheduling algorithms. Figure 8 also
presents that SPN and RR have shown slightly higher total completion times than those for AHS. This figure also
depicts that P, FCFS and LJF have shown the worst performance, resulting in longer completion times.
Moreover, all scheduling algorithms have shown improvement in total completion times by increasing the
number of CPUs for ‘10%’ to ‘20%’ workload of LCG1. As a result, MH and MHR have shown best total
completion times.
8.6. Maximum Job Stretch Time Analysis
Stretch time is defined as the flow of a job over the processing time. In order to avoid the starvation situation
from the grid system, it is also required to minimize the stretch of each job [26], [27]. This motivates us to compute
another performance parameter, i.e. Maximum Stretch time of job.
The maximum job stretch times for each scheduling algorithm using ‘10%’ and ‘20%’ workload of LCCG1 are
shown in Figure 9. It can be depicted that RR have shown the shorter maximum job stretch times compared to the
other scheduling algorithms. In addition, AHS and SPN have shown the average measures of maximum job stretch
times. Figure 9 also shows that P, PLRR, FCFS and LJF have produced the longest maximum job stretch times.
Finally, RR, AHS and SPN have shown the better maximum job stretch times.
9. Conclusion
In this paper we present agent based hybrid priority job scheduling algorithm, namely AHS. We compared the
efficiency, performance and scalability of proposed job scheduling algorithm with other grid scheduling algorithms
on a computational grid using real workload traces. In this paper we also performed a statistical analysis of the
LCG1 workload trace to study the dynamic nature of grid jobs.
Experimental results show that AHS has shown the optimal performance w. r. t. average waiting times, average
turnaround times, average slowdown times and total completion times using real workload traces of LCG1.
Experimental results also exhibit that RR has shown the best average response times and maximum job stretch times
compared to other job scheduling approaches. It has been demonstrated and concluded that AHS is better scheduling
policy from system perspective while RR is better choice from user perspective.

488

Syed Nasir Mehmood Shah et al. / Procedia Computer Science 9 (2012) 479 – 488

References
1.
2.

3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.

E. Shmueli and D. G. Feitelson, "Backfilling with lookahead to optimize the packing of parallel jobs," J. Parallel Distrib. Comput.,
vol. 65, pp. 1090-1107, 2005.
Y. Zhang, H. Franke, J. E. Moreira, and A. Sivasubramaniam, "Improving parallel job scheduling by combining gang scheduling and
backfilling techniques," in Parallel and Distributed Processing Symposium, 2000. IPDPS 2000. Proceedings. 14th International, 2000,
pp. 133-142.
J. Chin, M. Harvey, S. Jha, and P. Coveney, "Scientific Grid Computing: The First Generation," Computing in Science and
Engineering, vol. 7, pp. 24-32, 2005.
K. Krauter, Buyya, R., Maheswaran, M., "A taxonomy and survey of grid resource management systems for distributed computing,"
Softw. Pract. Exper., vol. 32, pp. 135-164, 2002.
L. Chunlin, Z. J. Xiu, and L. Layuan, "Resource scheduling with conflicting objectives in grid environments: Model and evaluation,"
Journal of Network and Computer Applications, vol. 32, pp. 760-769, 2009.
F. Xhafa and A. Abraham, "Computational models and heuristic methods for Grid scheduling problems," Future Gener. Comput.
Syst., vol. 26, pp. 608-621, 2010.
J. Abawajy, "Job Scheduling Policy for High Throughput Grid Computing," in Distributed and Parallel Computing. vol. 3719, M.
Hobbs, et al., Eds., ed: Springer Berlin / Heidelberg, 2005, pp. 184-192.
B. G. Lawson, E. Smirni, and D. Puiu, "Self-Adapting Backfilling Scheduling for Parallel Systems," presented at the Proceedings of
the 2002 International Conference on Parallel Processing, 2002.
D. Tsafrir, Y. Etsion, and D. G. Feitelson, "Backfilling Using System-Generated Predictions Rather than User Runtime Estimates,"
Parallel and Distributed Systems, IEEE Transactions on, vol. 18, pp. 789-803, 2007.
K. Li, "Job scheduling and processor allocation for grid computing on metacomputers," Journal of Parallel and Distributed
Computing, vol. 65, pp. 1406-1418, 2005.
W. Stallings, Operating Systems Internals and Design Principles: Prentice Hall, 2004.
H. Li and R. Buyya, "Model-Driven Simulation of Grid Scheduling Strategies," presented at the Proceedings of the Third IEEE
International Conference on e-Science and Grid Computing, 2007.
S. Jang and J. Lee, "Predictive Grid Process Scheduling Model in Computational Grid," in Advanced Web and Network Technologies,
and Applications. vol. 3842, H. Shen, et al., Eds., ed: Springer Berlin / Heidelberg, 2006, pp. 525-533.
D. Lifka, "The ANL/IBM SP scheduling system," in Job Scheduling Strategies for Parallel Processing. vol. 949, D. Feitelson and L.
Rudolph, Eds., ed: Springer Berlin / Heidelberg, 1995, pp. 295-303.
J. Skovira, W. Chan, H. Zhou, and D. Lifka, "The EASY — LoadLeveler API project," in Job Scheduling Strategies for Parallel
Processing. vol. 1162, D. Feitelson and L. Rudolph, Eds., ed: Springer Berlin / Heidelberg, 1996, pp. 41-47.
D. G. Feitelson, "A Survey of Scheduling in Multiprogrammed Parallel Systems," IBM T.J.Watson Research Center, Yorktown
Heights, NY1995.
R. Sharma, V. K. Soni, and M. K. Mishra, "An improved resource scheduling approach using Job Grouping strategy in grid
computing," in Educational and Network Technology (ICENT), 2010 International Conference on, 2010, pp. 94-96.
S. S. Rawat and L. Rajamani, "Experiments with CPU Scheduling Algorithm on a Computational Grid," in Advance Computing
Conference, 2009. IACC 2009. IEEE International, 2009, pp. 71-75.
L. Hui and R. Buyya, "Model-Driven Simulation of Grid Scheduling Strategies," in e-Science and Grid Computing, IEEE
International Conference on, 2007, pp. 287-294.
D. Feitelson and L. Rudolph, "Metrics and benchmarking for parallel job scheduling," in Job Scheduling Strategies for Parallel
Processing. vol. 1459, D. Feitelson and L. Rudolph, Eds., ed: Springer Berlin / Heidelberg, 1998, pp. 1-24.
M. Calzarossa and G. Serazzi, "Workload characterization: a survey," Proceedings of the IEEE, vol. 81, pp. 1136-1150, 1993.
H. Li, "Workload dynamics on clusters and grids," The Journal of Supercomputing, vol. 47, pp. 1-20, 2009.
Iosup, H. Li, M. Jan, S. Anoep, C. Dumitrescu, L. Wolters, and D. Epema, "The Grid Workloads Archive," Future Generation
Computer Systems, vol. 24, pp. 672-686, 2008.
S. N. Mehmood Shah, A. K. Bin Mahmood, and A. Oxley, "SYEDWSIM: A Web Based Simulator for Grid Workload Analysis," in
Software Engineering and Computer Systems. vol. 181, J. M. Zain, et al., Eds., ed: Springer Berlin Heidelberg, 2011, pp. 677-692.
J. Blazewicz, Ecker, K.H., Pesch, E., Schmidt, G. und J. Weglarz, Scheduling Computer and Manufacturing Processes: Berlin
(Springer), 2001.
Rodero, F. Guim, and J. Corbalan, "Evaluation of Coordinated Grid Scheduling Strategies," in High Performance Computing and
Communications, 2009. HPCC '09. 11th IEEE International Conference on, 2009, pp. 1-10.
M. A. Bender, S. Chakrabarti, and S. Muthukrishnan, "Flow and stretch metrics for scheduling continuous job streams," presented at
the Proceedings of the ninth annual ACM-SIAM symposium on Discrete algorithms, San Francisco, California, United States, 1998.

