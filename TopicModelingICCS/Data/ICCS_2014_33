Procedia Computer Science
Volume 29, 2014, Pages 1299â€“1313
ICCS 2014. 14th International Conference on Computational Science

Static versus Dynamic Data Information Fusion
analysis using DDDAS for Cyber Security Trust
Erik Blasch1, Youssif Al-Nashif 2 , Salim Hariri

2

1

2

Air Force Research Lab, Information Directorate
NSF Center for Cloud and Autonomic Computing, The University of Arizona
erik.blasch.1@us.af.mil, alnashif@ece.arizona.edu, hariri@ece.arizona.edu

Abstract
Information fusion includes signals, features, and decision -level analysis over
various types of data including imagery, text, and cyber security detection. With the
maturity of data processing, the explosion of big data, and the need fo r user acceptance;
the Dynamic Data-Driven Application System (DDDAS) philosophy fosters insights
into the usability of information systems solutions. In this paper, we exp lore a notion of
an adaptive adjustment of secure communication trust analysis that seeks a balance
between standard static solutions versus dynamic -data driven updates. A use case is
provided in determin ing trust for a cyber security scenario exp loring comparisons of
Bayesian versus evidential reasoning for dynamic security detection updates. Using the
evidential reasoning proportional conflict redistribution (PCR) method, we demonstrate
improved trust for dynamically changing detections of denial of service attacks.

1 Introduction
Information fusion (Blasch, et al., 2012) has a well-documented following of different methods,
processes, and techniques emerging fro m control, probability, and commun ication theories.
Information fusion systems designs require methods for big data analysis, secure communications,
and support to end users. Current in formation fusion systems use probability, estimation, and signal
processing. Extending theses techniques to operational needs requires an assessment of some of the
fundamental assumptions such as secure communications over various data, applications, and
systems. Specifically, the key focus of this paper is based on the question of measuring trust in static
versus dynamic information fusion systems.
Static versus dynamic information fusion co mes fro m three perspectives such as data, models, and
processing. As related to information fusion techniques, many studies exist on centralized versus
distributed processing, single versus mult iple models, and stovepipe versus mult i-modal data. In each
case, static informat ion fusion rests in centralized processing from single model estimation over a

Selection and peer-review under responsibility of the Scientiï¬c Programme Committee of ICCS 2014
c The Authors. Published by Elsevier B.V.
doi:10.1016/j.procs.2014.05.117

1299

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

single source of data. On the other ext reme is d istributed processing, using mu ltiple -models over
mu lti-modal data; wh ich in reality is supposed to cover the entire gamut of big data solutions captured
in large-scale systems designs. In reality, with such an ambit ious goal, there are always fundamental
assumptions that tailor the system design to the user needs. For example, a system could be designed
to capture all image data being collected fro m surveillance sensors; however filtering collections over
a specific area, for a designated time internal, at a given frequency helps to refine answers to user
requests. Thus, as a user selects the details of importance, responses should be accessible, co mplete,
and trustworthy.
Dynamic information fusion is a key analysis of the paper of which we focus on trust. If a machine
is processing all the data, then time and usability constraints cannot be satisfied. Thus, either the user
or the machine must determine the appropriate set of data, models, and processing that is needed for a
specific applicat ion. Trust analysis is required to determine security and reliability constraints, and
DDDAS provides a fresh look at the balance between static and dynamic in formation fusion. In this
paper, we explore the notions of dynamic information fusion towards decision making as cyber
detections change.
In Section 2 we overview informat ion fusion and DDDAS. Section 3 d iscusses the notions of trust
as a means to balance between information fusion and dynamic data detections. Section 4 co mpares
Bayesian versus evidential reasoning. Sect ion 5 provides a use-case for analysis for cyber trust and
Section 6 provides conclusions..

2 Information Fusion and DDDAS
Information fusion and DDDAS overlap in many areas such as data measurements, statistical
reasoning, and software development for various applications. Recently, there is an interest in both
communit ies to address big data, software structures, and user ap plications. The intersection of these
areas includes methods of information management (Blasch, 2006) in assessing trust in data access,
dynamic processing, and distribution for applications-based end users.

2.1 Information Fusion
The Data Fusion Information Group (DFIG) model, shown in Figure 1, provides the various
attributes of an information fusion systems design. Informat ion fusion concepts are divided between
Low-level Informat ion Fusion (LLIF) and High-level Information Fusion (HLIF) (Blasch, et al.,
2012). LLIF (L0-1) co mposes data registration (Level 0 [L0]) and exp licit ob ject assessment (L1)
such as an aircraft location and identity (Yang, 2009). HLIF (L2-6) co mposes much of the open
discussions in the last decade. The levels, to denote processing, include situation (L2) and impact (L3)
assessment with resource (L4), user (L5) (Blasch, 2002), and mission (L6) refinement (Blasch, 2005).
Here we focus on Level 5 fusion by addressing cyber security trust in systems design.

1300

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

Figure 1. DFIG Information Fusion model (L = Information Fusion Level).
Data access for information fusion requires an information management (IM) model of the enterprise
architecture, as shown in Figure 2. The IM model illustrates the coordination and flow of data through
the enterprise with the various layers (Blasch, et al., 2012).
People or autonomous agents interact with the managed information enterprise environment by
producing and consuming informat ion. Various actors and their activit ies/services within an IM
enterprise surround the IM model that transforms data into informat ion. Within the IM model, there
are various services that are needed to process the managed information objects (MIOs). Security is
the first level of interaction between users and data.

Figure 2. Information Management (IM) Model.

A set of service layers are defined that use artifacts to perform specific services. An art ifact is a
piece of information that is acted upon by a service or that influences the behavior of the service (e.g.,
a policy). The service layers defined by the model are: Security, Workflow, Quality of Service (QoS),
Transformat ion, Bro kerage, and Maintenance. These services are intelligent agents that utilize the

1301

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

informat ion space within the architecture, such as cloud computing and machine analytics. Access to
the data requires secure communications which is dynamic, data-type driven, and application specific.

2.2 Dynamic Data Driven Application Systems (DDDAS)
DDDAS is focused on applications modeling (scenarios), mathematical and statistical algorithms
(theory), measurement systems, and systems software as shown in Figure 3. For a systems application,
user mission needs drive data access over the scenarios. The available data is processed from
measure ments to information using theoretical princip les. The data-driven results are presented to the
user through visualizat ions; however the trust in the data is compounded by data quality, the model
fidelity, and systems availability of which software is an integral part to a systems application.

Figure 3. DDDAS Aligned with Information Fusion.
Using a cyber examp le for DDDAS, the application is secure data commun ications to meet
mission needs (L6). While not a one-to-one mapping, it can be assumed that data management, driven
by scenarios, identifies cyber threat attacks (L3) such as denial of service attacks. The theory and
measurements come fro m the models of normal behavior (L1) which use co mputational methods to
support cyber situation awareness (L2) visualizat ion. The user (L5) interacts with the machine through
data management (L4), as new measurements arrive. Current research seeks distributed, faster, and
more reliable co mmunicat ion systems to enable such processing and coordination b etween the man
and their machines, however, measurement of trust is paramount.

3 Trust in Information Processing
Several theories and working models of trust in automation have been proposed. Informat ion
which is presented for decision-aid ing is not uniformly trusted and incorporated into situation
awareness. Three proposed increasing levels, o r â€˜stages of trustâ€™, for human -human interactions
include: Predictability, Dependability, and Faith (Rempel, et al., 1985). Participants progress through
these stages over time in a relationship. The same was anticipated in human -automat ion interactions,
either via training or experience. The main idea is that as trust develops, people will make decisions
based upon the trust that the system will continue to behave in new situations as it has demonstrated in
the past. Building upon Rempelâ€™s stages, (Muir & Moray, 1996) postulated that
Trust = Predictability + Dependability + Faith + Competence + Responsibility + Reliability
and further defined the construct of Distrust: which (1) can be caused by operator feeling that the
automation is undependable, unreliable, unpredictable, etc. and a (2) set of dimensions related to

1302

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

automation failures, which may cause distrust in automated systems (location of failure, causes of
failure or corruption, time patterns of failure).
Table 1, adapted below fro m (Mu ir & Moray, 1996), depicts the quadrant of trust and distrust
behaviors with respect to good or poor quality of the automation. Basically, the outcome of a wrong
decision to trust the automation is worse than the outcome of a wrong decision to not trust the
automation. Hence, security is enforced to not trust a poor decision.

Operatorâ€™s trust &
allocation of function
Trusts and uses the
automation
Distrusts and rejects the
automation

Quality of the automation
â€˜Goodâ€™
â€˜Poorâ€™
Appropriate Trust (optimize
False Trust (risk automated disaster)
system performance)
False Distrust (lose benefits of
Appropriate Distrust (optimize
automation, inc. workload)
system performance)

Table 1: Trust, Distrust, and Mistrust, (adapted from Muir and Moray, 1996)

Trust in the automation clearly impacts a user mental model of secure co mmunicat ions. Therefore,
dynamic models must be devised to account for different levels of attention, trust, and interactions in
Hu man in the Loop (HIL) and Hu man on the Loop (HOL) designs. A user must be given permission
to refine the assessment for final decision for valid ity and reliability of the informat ion presented.
User Trust issues then are confidence (correct detection), security (impacts), integrity (what you
know), dependability (timely), reliable (accurate), controllability, familiar (practice and train ing), and
consistent (reliable).
Trust in information processing involves many issues; however, here we focus on the development
of a cyber do main trust stack as shown in Figure 4. The trust stack co mposes policies, trust authority,
collecting raw met rics and behavior analysis, leading to authentication and authorization, and then
secure communications. Similar to the information management model, polices are important to
determine whether data access is available. Likewise, sensor management gets access to raw metrics
(Blasch, 2004) that need to be analy zed for situation awareness. The problem not being full addressed
is the impeding results for secure communications. In what follo ws, we discuss the main functions to
be provided by each layer in the trust stack shown in Figure 4.

Figure 4. Trust Stack.

3.1 Secure Communications, Authentication, and Authorization
Secure co mmunications is an important property to guarantee the confidentiality and integrity of
the messages used to evaluate trust in the system. Certificates are used to verify the identify of

1303

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

communicat ing end-devices (Kaliski, 1993). The co mmunicat ion channel is encrypted using DES
(Data Encryption Standard, 2010) in CFB64 (Cipher Feedback) mode. In this CFB mode, the first 8
bytes of the key generated used to encrypt the first block of data. Th is encrypted data is then used as a
key for the second block. This process is repeated until the last block is encrypted. The DES is still
used in legacy virtual private networks (VPNs) and could benefit fro m a DDDAS trust analysis even
used with multiple protocol authentication systems such as Kerberos.
Multiple protocols have been developed over the years for password -based authentication,
biometric authentication, and remote user authentication. In order to evaluate the trust of different
entities with many users, mult iple systems, and mult iple do mains, we assu me the use of remote user
authentication. Remote Authentication Dial-In User Serv ice (RA DIUS) (Willens, et al, 2000) is a
famous client/server protocol to allow remote entities to communicate with a server to authenticate
remote users. RADIUS gives organization ability to maintain user profiles in a specific database that
the remote servers share.
The Domain Trust Enforcement (DTE) agent performs the authorization process for the end -toend adaptive trust. Based on the results of the authentication process and the received trust level, the
DTE agent grants or denies authorizat ion to access the reso urces, i.e., allow o r deny the
communication between the different entities.

3.2 Collecting Raw Measurements
Much software, both commercial and open source, are available and provide important health and
security information, such as Nagios (Nass, 2009). This information can be used to extract metrics
that can be used to evaluate the trust of different entities. These metrics can be divided into mult iple
categories based on their source: User, Application, Mach ine, Connection, or Security Soft ware
Alerts. In order to evaluate the trust, the metrics need to be quantified and normalized (e.g., between 0
and 1) to a common scale. Table 2 shows a set of measured metrics and their quantification function
and Figure 5 shows these categories with some example metrics.
Category
User

P assword Strength

User

Days since last password change

User

Number of authentication
failures

User

Lock Outs

Application

Developer Reputation

Application

Who manages the software

Connection

Number of hops

Connection

Number of discarded P ackets

Machine

1304

Metric

Firmware version

Quantification
Í²Ç¡ÂƒÂ•Â•Â™ Â‘Â”Â†Â‡ÂÂ‰Â–ÂŠàµÍº   
ÂƒÂ•Â•Â™Â‘Â”Â†Â‡ÂÂ‰Â–ÂŠ
Ü³àµŒá‰
Ç¡Â–ÂŠÂ‡Â”Â™Â‹Â•Â‡
Í²Ç¤Í³ àµ… Í² Ç¤Í» Î®
ÂƒÂšÂ‹ÂÂ—ÂÂƒÂ•Â•Â™Â‘Â”Â†Â‡ÂÂ‰Â–ÂŠ
Í²Ç¡Í“Â†ÂƒÂ›Â•àµÂƒÂšÂ‹ÂÂ—ÂÂ—ÂÂ„Â‡Â”ÂˆÂƒÂ›Â• 
Í“Â†ÂƒÂ›Â•
Ü³àµŒá‰
Ç¡Â–ÂŠÂ‡Â”Â™Â‹Â•Â‡
Í³àµ†
ÂƒÂšÂ‹ÂÂ—ÂÂ—ÂÂ„ Â‡Â”Â‘ÂˆÂƒÂ›Â•
Í² Ç¡Í“ÂˆÂƒÂ‹ÂÂ—Â”Â‡Â•àµÂƒÂšÂ‹ÂÂ—Â Â—ÂÂ„Â‡Â”ÂˆÂÂÂ‘Â™Â‡Â†	ÂƒÂ‹ÂÂ—Â”Â‡Â• 
Í“ÂˆÂƒÂ‹ÂÂ—Â”Â‡Â•
Ü³àµŒàµ
Ç¡Â–ÂŠÂ‡Â”Â™Â‹Â•Â‡
Í³àµ†
ÂƒÂšÂ‹ÂÂ— ÂÂ—ÂÂ„Â‡Â”ÂˆÂÂÂ‘Â™Â‡Â†	ÂƒÂ‹ÂÂ—Â”Â‡Â•
Í² Ç¡Í“Â‘Â…ÂÂ—Â–Â•àµÂƒÂšÂ‹ÂÂ—ÂÂ—ÂÂ„Â‡Â”ÂˆÂÂÂ‘Â™Â‡Â† Â‘Â…ÂÂ—Â–Â•
Í“Â‘Â…ÂÂ—Â–Â•
Ü³àµŒàµ
Í³àµ†
Ç¡Â–ÂŠÂ‡Â”Â™Â‹Â•Â‡
ÂƒÂšÂ‹ÂÂ—ÂÂ—ÂÂ„Â‡Â”ÂˆÂÂÂ‘Â™Â‡Â† Â‘Â…ÂÂ—Â–Â•
Â‡Â’Â—Â–ÂƒÂ–Â‹Â‘Â
Ü³ àµŒ
ÂƒÂšÂ‹ÂÂ—ÂÂ‡Â’Â— Â–ÂƒÂ–Â‹Â‘Â
Í³ Ç¡
ÂÂ‘Â„ÂƒÂÂ†ÂÂ‹ÂÂ•Â–Â”ÂƒÂ–Â‘Â”
Ü³ àµŒ àµ Í²Ç¤Í·Ç¡Â‘Â…ÂƒÂÂ†ÂÂ‹ÂÂ‹Â•Â–Â”ÂƒÂ–Â‘Â”
Í²Ç¡Â‘Â†ÂÂ‹ÂÂ‹Â•Â–Â”ÂƒÂ–Â‘Â” 
Í²Ç¡Í“Â‘Â’Â•àµÂƒÂšÂ‹ÂÂ—ÂÂ—ÂÂ„Â‡Â”ÂˆÂ‘Â’Â•
Í“Â‘Â’Â•
Ü³àµŒá‰
Ç¡Â–ÂŠÂ‡Â”Â™Â‹Â•Â‡
Í³àµ†
ÂƒÂšÂ‹ÂÂ—ÂÂ—ÂÂ„Â‡Â”Â‘ÂˆÂ‘Â’Â•
Í² Ç¡Í“Â‹Â•Â…ÂƒÂ”Â†Â‡Â†ÂƒÂ… ÂÂ‡Â–àµÂƒÂšÂ‹ÂÂ—ÂÍ“Â‹Â•Â…ÂƒÂ”Â†Â‡Â† ÂƒÂ…ÂÂ‡Â–
Í“Â‹Â•Â…ÂƒÂ”Â†Â‡Â† ÂƒÂ…ÂÂ‡Â–
Ü³àµŒàµ
Ç¡Â–ÂŠÂ‡Â”Â™Â‹Â•Â‡ 
Í³àµ†
ÂƒÂšÂ‹ÂÂ—ÂÍ“Â‹Â•Â…ÂƒÂ”Â†Â‡Â† ÂƒÂ…ÂÂ‡Â–
Í³ Ç¡Â’Â–Â‘Â†ÂƒÂ–Â‡ 
Ü³ àµŒ àµ Í²Ç¤Í·Ç¡Í³Â‡Â”Â•Â‹Â‘ÂÂ‡ÂŠÂ‹ÂÂ†
Í²Ç¡Â–ÂŠÂ‡Â”Â™ Â‹Â•Â‡

Static versus Dynamic Data Information Fusion analysis using DDDAS...

Machine

Shared Folders

Analyzer

Integrity Check

Analyzer

Virus Alerts

E. Blasch et al.

Í³ Ç¡Â‘ÂŠÂƒÂ”Â‡Â†	Â‘ÂÂ† Â‡Â”Â• 
Ü³ àµŒ àµ Í²Ç¤Í·Ç¡ÂŠÂƒÂ”Â‡Â† Â•Â‡Â”	Â‘ÂÂ†Â‡Â”Â• 
Í²Ç¡ÂŠÂƒÂ”Â‡Â†Â›Â•Â–Â‡Â	Â‘ÂÂ† Â‡Â”Â• 
Í³Ç¡Â‘Â”Â‘Â„Â‡ÂÂ  
Ü³ àµŒ àµÍ² Ç¤Í·Ç¡Â”Â‘Â„ÂÂ‡ÂÂ‹ÂÂ—Â•Â‡Â”Â†ÂƒÂ–Âƒ 
Í² Ç¡Â”Â‘Â„ÂÂ‡ÂÂ‹ÂÂ•Â›Â•Â–Â‡ÂÂ‹ÂÂ–Â‡Â‰Â”Â‹Â–Â›
Í³Ç¡Â‘ÂÂ‡Â”Â–   
Í²Ç¤Í·Ç¡Â‹Â”Â—Â•	Â‘Â—ÂÂ†Â‹ÂÂƒÂ†Â‘Â…Â—ÂÂ‡Â Â–
Ü³àµŒàµ
Í²Ç¤Í´Í·Ç¡Â‹Â”Â—Â•	Â‘Â—ÂÂ†Â‹ÂÂƒÂ Â‡ÂšÂ‡Â…Â— Â–ÂƒÂ„ÂÂ‡
Í²Ç¡Â™Â‘Â”ÂÂˆÂ‘Â—ÂÂ†  

Table 2: Examples of metric quantification

3.3 Behavior Analysis
Behavior analysis techniques apply statistical and data min ing techniques to determine the current
operating zone of the execution environ ment (situation awareness) and also project its behavior in the
near future. The operating point (OP) of an environment can be defined as a point in an n-dimensional
space with respect to well-defined attributes. An acceptable operating zone can be defined by
combin ing the normal operating values for each attribute. A t runtime, the operating point moves fro m
one zone to another and that point might move to a zone where the environ ment does not meet its trust
and security requirements. We use these movements in the OP to adjust the trust value of the current
environment as will be discussed in further detail in the Do main Trust Authority section. By
continuously performing behavior analysis of the environ ment, we can then proactively predict and
detect the anomalous behaviors that might have been caused by malicious atta cks. Furthermore, once
it is determined that the environmentâ€™s operating point is moving outside the normal zone, it will
adopt its trust value and then determine the appropriate proactive management techniques that can
bring back the environment situation to a normal operating zone.

Figure 5. Trust M etrics.

1305

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

3.4 Domain Trust Authority
DTA evaluates the end-to-end trust over secure communicat ions. It defines a tuple (machine,
application, user, data) to be an entity and all co mmunications among entities has a certain context.
Thus authentication is conducted per entity. Every entity has a trust level associated with it. In order
to measure the trust, trustâ€™s metrics are introduced, and they take values between 0 and 1. Where 0
represents the distrust and 1 represent the blind or full trust. The trust measurements for all entities are
stored in an entity call Trust Authority. The NIST standard SP 800 -53 (NIST, 2010) is used and it
defines four levels of trust:
Level
Trust Value

Distrust
0.00

Low Trust
0.33

Moderate
0.66

High Trust
1.00

Initially, a risk and impact analysis is performed to quantify the impact of each component on the
overall operations of the network. Co mmon Vulnerab ilities and Exposures (CVE) and Co mmon
Vu lnerability Scoring System (CVSS) are used to evaluate the init ial impact for both software and the
environment, and reputations of the users are used to assign their init ial impacts. Based on the initial
impact analysis, the initial trust values for each entity is determined . The risk and impact analysis
performed is in consistence with the NIST â€œ Reco mmended Security Controls for Federal Informat ion
Systems and Organizations â€ report. According to the NIST report, risk measures the extent to which
entities are threatened by circumstances or events. The risk is a function of impact and its probability
of occurrence. Risks arise fro m the loss of confidentiality, integrity, and/or availab ility of informat ion
and resources. Thus the initial trust T can be viewed as an inverse function of the risk R:
T=1/R

(1)

Where the risk of an entity i is a function of the impact imp:
R i = imp i (confidentiality) â— Pr imp i (confidentiality) +
imp i (integrity) â— Pr imp i (integrity) + imp i (availability) â— Pr imp i (availability) (2)
When a new entity is added, it has to register with the Mutual Authentication (MA) module and
then its initial trust value can be quantified according to Equations 1 and 2.

Verify Trust
When an entity communicates with another entity, an Autonomic Trust Management (ATM) agent
obtains the trust level of the entity that needs to interact with fro m the Trust Authority (TA), see
Figure 6. If the trust level of the remote entity is below the minimu m required trust level set in the
policies, then the commun ication is dropped. By continuously checking with TA module, any
interacting entities will not be able to communicate if they do not meet the end -to-end trust policies.
Once the component trust level is verified, they can proceed and interact securely using the secure
communications.

1306

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

Figure 6. Adaptive End-to-End Trust

Adaptive Trust
The trust value assigned to each component is not static and is updated continuously. The Trust
Authority module is the one responsible for re-evaluating the trust at runtime. As mentioned in the
previous section, the trust is measured per entity and the trust levels are between 0 and 1.
T (E) Â [0, 1]

(3)

Each interaction between entities is governed by a context C. Thus, trust level for entities is
computed per context:

T (E, C) Â [0, 1]

(4)

A Forgiveness Factor, F, is assigned to provide an adaptive mechanis m for co mpro mised entities
to start gaining trust after all existing vulnerabilit ies have been fixed. Based on the impact of the entity
on the overall operations, we can control the time it takes for that entity to recover its trust level.
Monitoring, measuring, and quantifying trust metrics are required, and they are performed by the
ATM. Mi will denote the collected trust metric, where i is the metric identifier. The function m i () is a
quantifying function that returns a measurement between 0 and 1 for the metric Mi .
The overall trust for an entity is computed using two types of trust: 1) self-measured trust and 2)
reputation-measured trust. The self-measured trust Ts is the trust that is evaluated based on the
measurement perfo rmed by the ATM agent that manages the entity. While the reputation -measured
trust, Tp is based on the trust metrics collected fro m peers based on a previous recent interaction with
the entity for which the trust is being re-evaluated. The Ts and Tp are given by following equations:
L

T S (E , C) = T (ATM E , C) Â˜ Â¦

Ii (C) Â˜ mi (Mi )

i =1

T P (E , C) =

1
K

K

L

j =1

i=1

Â¦ T (ATM j , C ) Â˜ Â¦ Ii (C) Â˜ mi (Mi )

(5)

The values of the metric weight Ii for metric i is determined based on the feature selection
technique, where:
L

Â¦ Ii (C) = 1

(6)

i=1

1307

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

Based on the context and the type of operations, the end-to-end trust is evaluated using three trust
evaluation strategies: Optimistic, Pessimistic, and Average. The end -to-end trust for each strategy can
be evaluated as follows:
Trust Confidence
Optimistic
Average
Pessimistic

Trust Evaluation Strategy
T(E, C) = max {TS (E, C), TP (E, C)}
T(E, C) = ave {TS (E, C), TP (E, C)}
T(E, C) = min {TS (E, C), TP (E, C)}

Once T(E,C) is computed, then it is mapped to the nearest of trust level: (High, Moderate, Lo w,
and None).
The Trust Authority module continuously evaluates the trust for al l co mponents and their entities
whenever new metrics are obtained fro m the ATM agents that require an update to entity trust
evaluation above depending on the trust evaluation strategy. Various reasoning evaluation strategies
exist, such as that of Bayesian, Evidential Reasoning, and Belief Functions (Blasch, et al, 2013), that
can be used to evaluate trust.
In a DDDAS cyber environ ment, there are many levels of information fusion, but to build a
trustworthy DDDAS environ ment, we need to check the trust of each level o f informat ion fusion. The
Do main Trust Authority is the place to verify the trust of each entity passing information with in the
DDDAS environment. When the trust level drops below certain threshold; the incoming data can be
dropped to enable secure commun ications. What follows are the DDDAS theory, simu lations,
measurements, and software analysis for Information fusion levels of cyber data, situation/behavior
assessment, information management, and user refinement.

3.5 Bayes versus Evidential Reasoning
A fundamental technique for data fusion is Bayes Rule. Recently, (Dezert, et al., 2012) has shown
that Dempsterâ€™s rule is consistent with probability calculus and Bayesian reasoning if and only if the
prior P(X) is uniform. Ho wever, when the P(X) is not uniform, then Dempsterâ€™s rule gives a different
result. Both (Yen, 1986) and (Mahler, 1996) developed methods to account for non -uniform p riors.
Others have also tried to compare Bayes and evidential reasoning (ER) methods (Mahler, 2005,
Blasch, et al., 2013). Assuming that we have mult iple measurements Z = {Z1 , Z2 , â€¦, ZN } for cyber
detection D being monitored, Bayesian and ER methods are developed next.

3.6 Relating Bayes to Evidential Reasoning
Assuming conditional independence, one has the Bayes method:
P(X | Z1  Z2 ) =

P(X | Z1 ) P(X | Z2 ) / P(X)
N

(7)

Â¦ P(Xi | Z1 ) P(Xi | Z2 ) / P(X i )
i=1

With no information fro m Z1 or Z2 , then P(X | Z1 , Z2 ) = P(X). Without Z2 , then P(X | Z1 , Z2 ) = P(X |
Z1 ) and without Z1 , then P(X | Z1 , Z2 ) = P(X | Z2 ). Using Dezertâ€™s formu lation, then the denominator
can be expressed as a normalization coefficient:
m12 (Â‡) = 1 

Â¦ P(Xi | Z1 ) P(Xi | Z2 )
Xi ; Xj | X i  Xj

1308

(8)

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

Using this relation, then the total probability mass of the conflicting information is
P(X | Z1  Z2 ) =

1
x P(X | Z1 ) P(X | Z2 )
1  m12 (Â‡)

(9)

which corresponds to Dempsterâ€™s rule of co mbination using Bayesian belief masses with uniform
priors. When the priorâ€™s are not uniform, then Dempsterâ€™s rule is not consistent with Bayesâ€™ Rule. For
example, let m0 (X) = P(X), m1 (X) = P(X | Z1 ), and m2 (X) = P(X | Z2 ), then
m(X) =

m0 (X) m1 (X) m2 (X)
=
1  m012 (Â‡)

P(X) P(X | Z1 ) P(X | Z2 )
N

(10)

Â¦ P(X i ) P(Xi | Z1 ) P(Xi | Z2 )
i=1

Thus, methods are needed to deal with non-uniform prio rs and appropriately redistribute the
conflicting masses.

3.7 Proportional Conflict Redistribution
Recent advances in DS methods include Dezert-Smarandache Theory (DSmT). DSmT is an
extension to the Dempster-Shafer method of evidential reasoning which has been detailed in
numerous papers and texts: Advances and applications of DSmT for information fusion (Collected
works), Vo ls. 1-3 (Dezert, et al., 2009). In (Dezert, et al., 2002) introduced the methods for the
reasoning and in presented the hyper power-set notation for DSmT (Dezert, et al., 2003). Recent
applications include the DSmT Proportional Conflict Redistribution ru le 5 (PCR5) applied to target
tracking (Blasch, 2013).
The key contributions of DSmT are the redistributions of masses such that no refinement of the
frame 4 is possible unless a series of constraints are known. For examp le, Shaferâ€™s model (Shafer,
1976) is the most constrained DSm hybrid model in DSmT. Since Shaferâ€™s model, authors have
continued to refine the method to more p recisely address the combination of conflict ing beliefs
(Josang, et al., 2006) and generalizat ion of the co mbination ru les (Smaradache, et al., 2005, Daniel,
2006). An adaptive co mbination rule (Florea, et al., 2006) and rules for quantitative and qualitative
combinations (Martin, 2008) have been proposed. Recent examp les for sensor applications include
electronic support measures, (Djiknavorian, et al., 2010), physiological mon itoring sensors (Lee, et al.,
2010), and seismic-acoustic sensing (Blasch, et al., 2011).
Here we use the Proportional Conflict Redistribution rule no. 5 (PCR5) * . We replace Smetsâ€™ ru le
(Smets, 2005) by the more effective PCR5 to cyber detection probabilities. All details, justifications
with examples on PCRn fusion rules and DSm transformations can be found in the DSmT co mp iled
texts (Dezert, et al., 2009 Vols. 2 & 3). A comparison of the methods is shown in Figure 7.

*
Note: PCR used here is from information fusion technology and not the a Platform Configuration Register (PCR) of the
T rusted Platform Module (TPM) hardware technology.

1309

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

Figure 7. Comparison of Bayesian, Dempster-Shafer, and PCR5 Fusion Theories

In the DSmT framewo rk, the PCR5 is used generally to combine the basic belief assignment
(bba)â€™s. PCR5 transfers the conflicting mass only to the elements involved in the conflict and
proportionally to their indiv idual masses, so that the specificity of th e informat ion is entirely
preserved in this fusion process. Let m1 (.) and m2 (.) be two independent bbaâ€™s, then the PCR5 ru le is
defined as follows (see Dezert, et al., 2009, Vo l. 2 for fu ll justification and examp les): mP CR5 (Â‡) = 0
and X Â 24 \ {Â‡}, where Â‡ is the null set and 24 is the power set:
mP CR5 (X) =

Â¦

m1 (X1 ) + m2 (X2 )

4
X1 ; X2 Â 2
X1  X2 = X

+

Â¦

4
X2 Â 2
X2  X = Â‡

Âª m1 (X1 ) m2 (X2 ) + m1 (X1 ) m2 (X2 ) Âº `(11)
Â¬ m1 (X1 ) + m2 (X2 )
m1 (X1 ) + m2 (X2 ) Â¼
2

2

where  is the interesting and all denominators in the equation above are different fro m zero. If a
denominator is zero, that fraction is discarded. Additional properties and extensions of PCR5 for
combin ing qualitative bbaâ€™s can be found in (Dezert, 2009, Vo l. 2 & 3) with examp les and results. All
propositions/sets are in a canonical form.

3.8 Example of DDDAS Cyber Trust Analysis
In this examp le, we assume that policies are accepted and t hat the trust stack must determine
whether the dynamic data is trustworthy. The application system collects raw measurements on the
data intrusion (such as denial o f service attacks) and situation awareness is needed. Conventional
informat ion fusion processing would include Bayesian analysis to determine the state of the attack.
However, here we use the PCR5 rule which distributes the conflicting info rmation over the partial
states. Figure 8 shows the results for a normal system being attacked and the different methods
(Bayes, DS, and PCR5) to access the dynamic attack. Trust is then determined with percent
improvement in analysis. Since the cyber classification of attack versus no attack is not consistent,
there is some conflict in the processing of the measurement data going fro m an measurements of
attack and vice versa. The constant changing of measurements requires acknowledg ment of the
change and data conflict as measured using the PCR5 method.

1310

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

Trust in Decision

Trust in Decision
1

3

0.9

2.5

0.8

Ground truth
Demspters rule
PCR5 rule

2

Perf Improvment

0.7

Trust

0.6
0.5
0.4

1.5
1
0.5

0.3

0
0.2
Demspters rule
PCR5 rule
Bayes Rule

0.1
0

0

20

40

60
Scan number

80

100

-0.5

120

-1

0

20

40

60
Scan number

80

100

120

Figure 8. Results of Bayesian, Dempster-Shafer, and PCR5 Fusion Theories for trust.

The improvement of PCR5 over Bayes is shown in Figure 8 and co mpared with the modest
improvement fro m DS. The average performance improvement of PCR5 is 46% and DS is 2%, which
is data and application dependent. When comparing the results, it can be seen that when a system
goes from a normal to an attack state, PCR5 responds quicker in analy zing the attack, resulting in
maintaining t rust in the decision. Such issues of data reliability, statistical credib ility, an d applicat ion
survivability all contribute to the presentation of information to an application -based user. While the
analysis is based on behavioral situation awareness, it is understood that polices and secure
communicat ions can leverage this information for do main trust analysis and authentication and
authorization that can map measurements to software requirements.

3.9 Policies Enforcement
Policies are an important component of cyber trust (Blasch, 2012) as shown in Figure 9. As an
example, a policy is administered for retrieval of information. Po licy informat ion determines the
attributes for decisions. Determining the decision leads to enforcement. Such a decision is based on
trust processing from which effective enforcement can support secure communica tions.
Policy Administrator
Analyst

System Administrator
Policy
Administration
Point (PAP)

Application
Policy
Enforcement
Point (PEP)

Policies

Policy
Retrieval
Point (PRP)

Policies

Attributes

Policies

Policy
Decision
Point (PDP)

Attributes

Policy
Information
Point (PIP)

Attributes

Figure 9. Policy-Based Fusion of Information requiring Trust (Blasch, 2012)

There are many possible information fusion strategies to enable data access from policies. Here we
demonstrate an analysis of Bayesian versus evidential reasoning for determin ing cyber situation

1311

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

awareness trust. Future work includes threat intent (Shen, et al., 2009), impact assessment (Shen, et
al., 2007), transition behaviors (Du, et al., 2011) and developing advanced forensics analysis (Yu, et
al., 2013).

4 Conclusions
Information fusion (IF) and Dynamic Data-Driven Applicat ion Systems (DDDAS) are emerg ing
techniques to deal with big data, mult iple models, and decision making. One topic of interest to both
fields of study is a measure of trust. In this paper, we exp lored a system for cyber security fusion
which addresses system-level application issues of model building, data analysis, and polices for
application trust. IF and data-driven applications utilize a co mmon framework of probability analysis
and here we explo red a novel technique of PCR5 that builds on Bayesian and Dempster-Shafer theory
to determine trust. Future research would include real wo rld data, co mplete analysis of the trust stack,
and sensitivity of models/measurements in secure cyber situation awareness trust analysis.

Acknowledge ments
This work is partially supported by AFOSR DDDA S award nu mber FA95550-12-1-0241, and
National Science Foundation research projects NSF IIP-0758579, NCS-0855087 and IIP-1127873.

References
Blasch, E., Plano, S. (2002) â€œ JDL Level 5 Fusion model â€˜user refinementâ€™ issues and applications in group Tracking,â€ Proc.
SPIE, Vol. 4729.
Blasch, E., Plano, S. (2003) â€œ Level 5: User Refinement to aid the Fusion Process,â€ Proc. of SPIE, 5099, 2003.
Blasch, E., Pribilski, M., Daughtery, B., Roscoe, B., and Gunsett, J. (2004) â€œ Fusion Metrics for Dynamic Situation Analysis,â€
Proc. of SPIE, Vol. 5429.
Blasch, E., Plano, S. (2005) â€œDFIG Level 5 (User Refinement) issues supporting Situational Assessment Reasoning,â€ Int. Conf.
on Info Fusion.
Blasch, E. (2006) â€œLevel 5 (User Refinement) issues supporting Information Fusion Management,â€ Int. Conf. on Info Fusion.
Blasch, E., Kadar, I., Salerno, J., Kokar, M. M., Das, S., Powell, et al.. (2006) â€œ Issues and Challenges in Situation Assessment
(Level 2 Fusion),â€ J. of Advances in Information Fusion, Vol. 1, No. 2, pp. 122 - 139, Dec.
Blasch, E., Dezert, J., Valin, P. (2011) â€œ DSMT Applied to Seismic and Acoustic Sensor Fusion,â€ Proc. IEEE Nat. Aerospace
Electronics Conf (NAECON).
Blasch, E., Bosse, E., Lambert, D. A. (2012), High-Level Information Fusion Management and Systems Design, Artech House,
Norwood, MA.
Blasch, E., Dezert, J., Pannetier, B. (2013) â€œ Overview of Dempster-Shafer and Belief Function T racking Methods,â€ Proc. SPIE,
Vol. 8745,
Blasch, E., Steinberg, A., Das, S., Llinas, J., Chong, C.-Y., Kessler, O., Waltz, E., White, F., (2013) "Revisiting the JDL model
for information Exploitation," Intâ€™l Conf. on Info Fusion.
Blasch, E. (2013) â€œEnhanced Air Operations Using JView for an Air-Ground Fused Situation Awareness UDOP,â€ AIAA/IEEE
Digital Avionics Systems Conference, Oct..
Chen, G., Shen, D., Kwan, C., Cruz, J., et al., (2007) â€œ Game Theoretic Approach to Threat Prediction and Situation
Awareness,â€ Journal of Advances in Information Fusion, Vol. 2, No. 1, 1-14, June.
Culbertson, J., and Sturtz, K., (2013) â€œ A Categorical Foundation for Bayesian Probability,â€ Applied Categorical Structures.
Daniel, M., (2006) â€œ Generalization of the Classic Combination Rules to DSm Hyper-Power Sets,â€ Information & Security, An
Intâ€™l J., Vol. 20.
Data Encryption Standard (2010), http://blog.fpmurphy.com/2010/04/openssl-des-api.html
Dezert, J. (2002) â€œ Foundations for a new theory of plausible and paradoxical reasoning,â€ Information & Security, An Intâ€™l J.,
ed. by Prof. Tzv. Semerdjiev, Vol. 9.
Dezert, J. Smarandache, F. (2003) â€œOn the generation of hyper-powersets for the DSmT,â€ Int. Conf. on Info Fusion.
Dezert, J. Smarandache, F., (2009) Advances and applications of DSmT for information fusion (Collected works), Vols. 1-3,
American Research Press, http://www.gallup.unm.edu/~smarandache/DSmT.htm
Dezert, J. (2012) â€œ Non-Bayesian Reasoning for Information Fusion â€“ A Tribute to Lofti Zadeh,â€ submitted to J. of Adv. of
Information Fusion.
Djiknavorian, P., Grenier, D., Valin, P. (2010) â€œApproximation in DSm theory for fusing ESM reports,â€ Int. Workshop on
Belief functions 2010, April.
Du, H. Yang, S. J. (2011) â€œCharacterizing Transition Behaviors in Internet Attack Sequences,â€ in IEEE ICCCNâ€™11.

1312

Static versus Dynamic Data Information Fusion analysis using DDDAS...

E. Blasch et al.

Dsouza, G., Rodriguez, G., Al-Nashif, Y., Hariri, S. (2013) â€œ Resilient Dynamic Data Driven Application Systems (rDDDAS),â€
International Conference on Computational Science.
Dsouza, G., Hariri, S., Al-Nashif, Y., Rodriguez, G. (2013) â€œ Building resilient cloud services using DDDAS and moving target
defense,â€ Int. J. Cloud Computing..
Florea, M. C., Dezert, J., Valin, P., Smarandache, F., Jousselme, A-L., (2006) â€œAdaptive combination rule and proportional
conflict redistribution rule for information fusion,â€ COGIS '06 Conf.,
Josang, A., Daniel, M. (2006) â€œ Strategies for Combining Conflict Dogmatic Beliefs,â€ Int. Conf. on Info Fusion.
Kaliski, B. (1993) â€œA Survey of Encryption Standards,â€ IEEE Micro, Issue, 6, December.
Lee, Z. H., Choir, J. S., Elmasri, R. (2010). â€œA Static Evidential Network for Context Reasoning in Home-Based Care,â€ IEEE
Trans. Sys., Man, and Cyber-Part A; Sys & Humans, Vol. 40, No. 6, Nov.
Mahler, R.P. (1996) â€œ Combining ambiguous evidence with respect to ambiguous a priori knowledge, I: Boolean logic,â€ IEEE
Trans. Sys., Man & Cyber., Part A, Vol. 26, pp. 27â€“41.
Mahler, R., (2005) â€œCan the Bayesian and Dempster-Shafer approaches be reconciled? Yes,â€ Intâ€™l Conf. on Information Fusion.
Martin, A., Osswald, C., Dezert, J., Smarandache, F. (2008) â€œ General Combination Rules for Qualitative and Quantitative
Beliefs,â€ J. of Advances in Information Fusion, Vol. 3, No. 2, Dec.
Muir, B. and Moray, N. (1996) â€œTrust in automation: Part II. Experimental studies of trust and human Intervention in a process
control simulation,â€ Ergonomics, 39 (3), 429-460.
Nass, S. J., Levit, L. A., Gostin, L. O. (2009). Beyond the HIPAA Privacy Rule: Enhancing Privacy, Improving Health Through
Research, National Academies Press.
NIST , (revision, 2010) â€œ Recommended Security Controls for Federal Information Systems and Organizations,â€ NIST Special
Publication 800-53, Revision 3.
Rempel, J. K., Holmes, J. G., and Zanna, M. P. (1985) "Trust in Close Relationships," Journal of Personality and Social
Psychology, 49 (1), 95-112.
Shafer, G. (1976) A Mathematical Theory of Evidence, Princeton, NJ: Princeton Univ. Press.
Shen, D., Chen, G. et al., (2007) â€œ Strategies Comparison for Game Theoretic Cyber Situational Awareness and Impact
Assessment,â€œ Int. Conf. on Info Fusion..
Shen, D., Chen, G., et al. (2009) "An Adaptive Markov Game Model for Cyber Threat Intent Inference", invited Ch. 21 in
Theory and Novel Applications of Machine Learning, M. J. Er and Y. Zhou. (Eds.), IN-TECH.
Smaradache, F., Dezert, J., (2005) â€œInformation fusion based on new proportional conflict redistribution rules,â€ Int. Conf. Inf.
Fusion.
Smets, P., (2005) â€œAnalyzing the Combination of Conflicting Belief Functions,â€ Int. Conf. on Info Fusion.
Willens, S., et al, (2000) Remote Authentication Dial-In User Service (RADIUS), accessed at
http://tools.ietf.org/search/rfc2865
Yang, C., Blasch, E. (2009) â€œKalman Filtering with Nonlinear State Constraints,â€ IEEE Trans. Aerospace and Electronic
Systems, Vol. 45, No. 1, 70-84, Jan.
Yen, J. (1986) â€œA reasoning model based on the extended Dempster Shafer theory,â€ Nat Conf. on Artificial Intelligence.
Yu, W., Fu, X., et al. (2013) â€œ On Effectiveness of Hopping-Based Techniques for Network Forensic Traceback,â€ Intâ€™l J. of
Networked and Distributed Computing, Vol. 1, No. 3, 2013.

1313

