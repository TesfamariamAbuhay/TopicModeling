Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 548‚Äì557

International Conference on Computational Science, ICCS 2011

Distinguishing Provenance Equivalence of Earth Science Data
C. Tilmesa,‚àó, Ye. Yeshab , M. Halemb
a NASA

Goddard Space Flight Center
of Maryland, Baltimore County

b University

Abstract
Reproducibility of scientiÔ¨Åc research relies on accurate and precise citation of data and the provenance of that
data. Earth science data are often the result of applying complex data transformation and analysis workÔ¨Çows to vast
quantities of data. Provenance information of data processing is used for a variety of purposes, including understanding the process and auditing as well as reproducibility. Certain provenance information is essential for producing
scientiÔ¨Åcally equivalent data. Capturing and representing that provenance information and assigning identiÔ¨Åers suitable for precisely distinguishing data granules and datasets is needed for accurate comparisons. This paper discusses
scientiÔ¨Åc equivalence and essential provenance for scientiÔ¨Åc reproducibility. We use the example of an operational
earth science data processing system to illustrate the application of the technique of cascading digital signatures or
‚Äúhash chains‚Äù to precisely identify sets of granules and as provenance equivalence identiÔ¨Åers to distinguish data made
in an an equivalent manner.
Keywords: provenance, equivalence, reproducibility, data identiÔ¨Åers, data citations

1. Introduction
Provenance can be used for many purposes. For the Earth Science Data Processing domain, these include understanding of data and analyses, auditing, and anomaly resolution. Various facts can be related to the artifacts,
describing their provenance and other metadata about the data production and analysis. This paper will consider
precise data identiÔ¨Åcation and reproducibility.
1.1. Related Work
Provenance has recently gained prominence and has been garnering more interest and research both in abstract
work, and in numerous application domains. Barkstrom in particular describes provenance tracing for earth science
and how important that is for climate science credibility. [1] Others have applied provenance to numerous data processing systems.
Frew [2] et al. with the ESSW and Holland et al. with PASS [3] address provenance capture slightly diÔ¨Äerently,
augmenting the processing environment for automatic provenance capture. This can be very useful for investigative
research. We are concentrating here on the more industrial approach of large data processing systems.
‚àó Corresponding

author
Email address: Curt.Tilmes@nasa.gov (C. Tilmes)

1877‚Äì0509 ¬© 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.057

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

549

When data processing systems address provenance capture and representation, they usually converge on the same
fundamental workÔ¨Çow paradigm (which we use here as well.) This convergence was recognized by the community
which came together to produce the Open Provenance Model [4]. This provides a common model for expressing basic
workÔ¨Çow provenance and sharing it across systems.
One shortcoming of these approaches is that they generally rely on the permanance of provenance artifacts. They
describe the workÔ¨Çow as it happened in the past, referring to the speciÔ¨Åc artifacts used in the original workÔ¨Çow. In a
Ô¨Åeld such as earth science, with frequent major reprocessings of large amounts of data, prior versions often get deleted
and are lost. When reproducing data, either to replace missing data, or simply to conÔ¨Årm previous results, we get the
problem of expressing data equivalence, to compare newly produced data with the previously produced data. The
typical approach has been to simply compare the provenance graphs of each.
A related problem is maintaining equivalence regardless of data format transformation. This is addressed by
Altman and King [5], through their Universal Numeric Fingerprint. It may be possible to apply a similar mechanism
for earth science, but it is very diÔ¨Écult in general.
Instead of content equivalance, our approach is to use provenance equivalence as a proxy for data equivalence. If
we have a reproducible process and apply it in the same manner (with identical essential creation provenance), the
resulting data will be equivalent to the original. Rather than comparing the provenance graphs directly, we use that
property to create identiÔ¨Åers suitable to representing that equivalence.
1.2. Some DeÔ¨Ånitions
Some of these terms get used diÔ¨Äerently in diÔ¨Äerent contexts, so let us deÔ¨Åne our use of them for this work.
Various people and organizations have attempted to nail down a concrete deÔ¨Ånition for Provenance. For reference,
here is a working deÔ¨Ånition from the W3C Provenance Incubator Group:
Provenance of a resource is a record that describes entities and processes involved in producing and
delivering or otherwise inÔ¨Çuencing that resource. Provenance provides a critical foundation for assessing
authenticity, enabling trust, and allowing reproducibility. Provenance assertions are a form of contextual
metadata and can themselves become important records with their own provenance.1
We include the basic workÔ¨Çow information‚Äîinput Ô¨Åles and processes‚Äîbut also other ancillary aspects of the
process, including the build environment, compilers and libraries. We also include the compute environment, such as
operating system and computer hardware. [6].
DeÔ¨Ånition 1.1. Granularity refers to the diÔ¨Äerentiation between individual portions of a whole dataset. Granule
describes a Ô¨Åle or set of related Ô¨Åles corresponding to an individually identiÔ¨Åable portion of data and a Granule Key
is used to distinguish multiple granules of the same type. [7]
In the earth science domain, the identiÔ¨Åcation of a granule is usually (but not always) related to the geospatial and
temporal coordinates of the data contained in it.
DeÔ¨Ånition 1.2. A Granule IdentiÔ¨Åer is a globally unique identiÔ¨Åer for a speciÔ¨Åc granule.
Every granule produced is assigned that identiÔ¨Åer and it serves as the nexus for organizing information about that
granule. When considering reproducibility, another entity can make the same granule in the same way, but since they
are made at a diÔ¨Äerent time by a diÔ¨Äerent agent, each granule must be assigned a unique identiÔ¨Åer so that provenance
information can be attached to the right granule.
1.3. Equivalence and Reproducibility
Things can get confusing when considering reproducibility when two diÔ¨Äerent and distinct instances of the ‚Äôsame‚Äô
granule are made in precisely the ‚Äôsame‚Äô way such that they can reproduce the same science. We‚Äôll deÔ¨Åne a few terms
to tease out the nuances of the equivalence we are discussing.
1 http://www.w3.org/2005/Incubator/prov/wiki/What_Is_Provenance

550

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

DeÔ¨Ånition 1.3. For two granules of data to be Perfectly Identical, they must not only have identical contents, but also
identical identiÔ¨Åers and identical provenance. If two otherwise identical granules do not share identical provenance,
they are not perfectly identical.
Given the deÔ¨Ånitions above, two granules will have the same Granule IdentiÔ¨Åer if and only if they are Perfectly
Identical.
DeÔ¨Ånition 1.4. ScientiÔ¨Åcally Identical refers to Ô¨Åles (and more generally granules) where the data contents are
bit-for-bit exactly the same.
We use this term even if distinct granules were independently produced in a diÔ¨Äerent time, place, or manner
by diÔ¨Äerent people. Based on our deÔ¨Ånition of provenance, such granules clearly have distinct provenance, but if
their contents are equal, they are considered scientiÔ¨Åcally identical. Each such granule must have a distinct identiÔ¨Åer
that can refer to it so their particular provenance can be represented and referred to, but they can always be used
interchangably in a scientiÔ¨Åc investigation. In practice, we Ô¨Ånd very few scientiÔ¨Åc processes and circumstances are
capable of reliably producing such identical Ô¨Åles. We use this term mainly to show the contrast with what we are
actually capable of.
DeÔ¨Ånition 1.5. ScientiÔ¨Åcally Equivalent refers to granules that are suÔ¨Éciently similar that their use in a scientiÔ¨Åc
investigation would result in the same results or conclusions.
This is a somewhat more loose equivalence class than perfectly identical. For example, the processing could have
been performed on slightly diÔ¨Äerent hardware, or with a diÔ¨Äerent level of compiler optimization. These changes could
lead to very slight diÔ¨Äerences, while maintaining suÔ¨Écient equivalence.
Of course, since it is impossible to foresee every possible future scientiÔ¨Åc investigation it is diÔ¨Écult or impossible
to prove perfect scientiÔ¨Åc equivalence. It is more useful to limit the use of this term to a particular scientiÔ¨Åc domain,
and show that duplicating certain aspects of the provenance of one granule will produce a scientiÔ¨Åcally equivalent
granule for a given purpose.
DeÔ¨Ånition 1.6. ScientiÔ¨Åcally Reproducible refers to a process which is capable of reproducing granules that are
ScientiÔ¨Åcally Equivalent to the original granules and ScientiÔ¨Åc Reproducibility is the extent to which a process is
ScientiÔ¨Åcally Reproducible.
Again, this is diÔ¨Écult to prove deÔ¨Ånitively. For example, if you were to process 1000 granules on computer A,
then attempt to reprocess those same granules on computer B, comparing the results scientiÔ¨Åcally could lead you to
believe that the process was reproducible, but it could fail due to some bug on granule 1001. ScientiÔ¨Åc Reproducibility
is therefore a goal for a system or process, not a guarantee.
Some processes are chaotic in that very slight diÔ¨Äerences in processing are compounded producing drastically
diÔ¨Äerent results. We can apply sensitivity analyses to assess this characteristic and help determine if a process is
suitably reproducible.
We also distinguish the related concepts of Replication‚Äîour own ability to repeat our processing and produce
scientiÔ¨Åcally equivalent data from that of Reproduction‚Äîrepresenting and conveying suÔ¨Écient information about our
process to an independent party so they can produce scientiÔ¨Åcally equivalent data.
This independent reproducibility provides needed credibility to results. Certain results from the earth science
domain have been under Ô¨Åre for lack of transparency. Semantic provenance representation suÔ¨Écient to enable independent reproducibility of scientiÔ¨Åcally equivalent data, and ultimately leading to the same scientiÔ¨Åc conclusions are
critical for addressing that lack of transparency and increasing the credibility of our scientiÔ¨Åc results. [1]
DeÔ¨Ånition 1.7. Essential Provenance are those portions of the provenance information of a granule that must be
equivalent for a given process to reproduce that granule.
This is used to distinguish elements of provenance that are useful for other purposes such as the understanding of
a particular process, or auditing a data processing system from those speciÔ¨Åc elements essential for reproducibility.
For example, we capture the hostname of the computer where data processing was performed and the date/time
the process occured. These don‚Äôt really contribute to understanding of the process, but can increase credibility of

551

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557


	















Figure 1: SimpliÔ¨Åed Ozone Processing Flow

results through auditing and assist in anomaly investigation. It isn‚Äôt, however, essential to replicate these provenance
elements for reproducibility.
Some provenance elements are clearly essential. For example, raw measurements captured by a satellite sensor
that were fed into a process that produced a speciÔ¨Åc granule. It would be impossible to reproduce the resulting granule
without using those precise inputs.
Other provenance elements may fall into a grey area. For example, a program may produce diÔ¨Äerent answers
depending on the hardware it is run on. For that particular process, the hardware (or some aspect of the hardware)
could be essential. A goal of a science software developer should be to develop software where the correctness is
less dependent on such provenance elements. This can increase the reproducibility of the process. Again, sensitivity
analyses and portability testing can determine and help minimize the essential elements.
2. Use Case Scenario: Ozone Data Processing
This section will summarize a greatly simpliÔ¨Åed version of the data processing of ozone from satellite data [8]
shown in Ô¨Ågure 1. These data ultimately result in several Ô¨Ågures related to the ozone hole and overall ozone coverage.
They are provided annually to the Intergovernmental Panel on Climate Change (IPCC) and used to fulÔ¨Åll U.S. treaty
obligations under the Montreal Protocol.
A sensor on a satellite captures measurements of backscattered sunlight from the earth. These raw (‚Äúlevel 0‚Äù or
L0) data are transmitted to a receiving station and delivered to the processing system in 2 hour granules. The data are
only captured on the sunlit side of each orbit of the spacecraft, so the easiest granularity for the scientists to work with
is a single contiguous orbit per granule. The data undergoes a calibration and geolocation process (‚Äúlevel 1B‚Äù or L1B)
that applies various calibration techniques and ultimately produces a level 1B granule for each orbit. The level 1B
data go through various retrieval algorithms to determine speciÔ¨Åc geophysical parameters at level 2 (L2). In this case,
the total amount of ozone in each vertical column of atmosphere. All of the orbits for each day are then summarized
into a daily Ô¨Åle (L3). Finally, considering the daily Ô¨Åles for a year produces various averages, minima, and maxima
for the annual report. These are used to monitor long term trends.
Provenance information is captured and archived throughout this process. This includes simple workÔ¨Çow information (as shown in the diagram), but also auditing information such as the host that performed each process, the time
it started and stopped, etc. In particular the version of the algorithms, look up tables, and calibration Ô¨Åles are critical,
both for understanding and for reproducibility. [9]
Several aspects of this process make it an interesting real world case. One, it is an ongoing process‚Äîevery day
more data come in and get processed. Two, the scientists are still working on the process. This means they periodically
analyze the data and Ô¨Ånd a problem and want to make a change. This could be a change to the calibration if they notice
something happening with the instrument performance, or a change in the algorithms themselves. Another situation
that occasionally arises are operational issues that lead either to a delay of data, or redelivery of level 0 data (e.g. the
original data were corrupted or incomplete).
We have two (major) approaches to incorporating such changes. One, we can simply upgrade the system in place.
This results in past granules remaining as is, and future granules being processed somewhat diÔ¨Äerently. The second

552

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

approach is to start over from the beginning of the mission and reprocess all of the old data in the the new manner.
This is typically used for more major changes, so the data don‚Äôt exhibit discontinuities. We sometimes retain the older
data in a separate ArchiveSets (discussed later).
2.1. IdentiÔ¨Åers
Artifact identiÔ¨Åcation is a very broad topic, and we began to address some of its issues elsewhere [7], assigning
URIs to each artifact in the system. For this example, we will use some simple tuples comprised of key distinguishing
elements.
2.1.1. Granules
Each granule is identiÔ¨Åed by its type (L0, L1B, L2, L3), the GranuleKey (L0: YYYY-MM-DDTHH2 , L1B/L2:
OrbitNumber and L3: YYYY-MM-DD) and an instance identiÔ¨Åer. The instance identiÔ¨Åer is used to distinguish
multiple instances of the same granule, either made in an identical manner, or made from diÔ¨Äerent inputs such as a
later version of an algorithm. Since we really want a globally unique instance identiÔ¨Åer so that diÔ¨Äerent scientists can
independently reproduce granules and distinguish them appropriately, it makes sense for this portion to be a UUID,
but they are awkward for humans to work with, so for this paper, we‚Äôll use small integers to distinguish instances of
the same granule.
2.1.2. Software
We refer to the software encapsulating the integrated algorithms that are used by the system to perform processing
as Algorithm Plugin Packages (APPs).
Software versions are relatively straight forward. When a developer makes a change to the source code for a
software, it gets delivered into a conÔ¨Åguration management system and tagged with a speciÔ¨Åc version. A rigorous CM
process ensures that every change, however minor, gets assigned a distinct version.
The executable software itself is an additional ‚Äúinput‚Äù to the process that performs data processing. That executable has its own ‚ÄúBuild Process‚Äù that produced it from source code, compilers, libraries, and taking place on
a particular host with a particular environment. Each of those components are inputs to the process producing the
executable. Just as certain elements of the provenance of the data processing are essential for reproducibility of
scientiÔ¨Åcally equivalent data, certain elements of the provenance of the software executable (for example, a certain
compiler, or a certain version of a library) are essential for reproducing an executable capable of producing scientifically equivalent data Ô¨Åles. Other provenance elements are interesting and useful for other purposes, but not strictly
essential, like the time it was compiled, or the agent responsible for compiling it.
Again, the dependence on certain aspects of the environment limits reproducibility, while portability and other
good software engineering practices can increase reproducibility.
For now, we are Ô¨Çowing the version of the source software through to the executable and suggesting that the
versions must match to maintain scientiÔ¨Åc equivalence. This is clearly not always true. There are many cosmetic
changes to the source that don‚Äôt aÔ¨Äect the data contents in a way that would cause them not to be equivalent. It is
possible to separate software ‚ÄúVersion‚Äù into two parts, one indicating a change that aÔ¨Äects the data content, and one
that doesn‚Äôt. To date, the utility of such a separation hasn‚Äôt been worth the eÔ¨Äort.
2.1.3. Other IdentiÔ¨Åers
Simplifying the identiÔ¨Åcation of lookup tables and calibration, we‚Äôll identify them with a name and version as
well.
Each of the artifact and process identiÔ¨Åers can be mapped into a URI namespace for constructing RDF triples and
asserting facts about those artifacts. We Ô¨Ånd URIs more useful than literal strings for all artifact identiÔ¨Åers. Each URI
can be resolved by the web browser to provide metadata about the artifact.
2 ISO

8601 date/time http://www.iso.org/iso/catalogue_detail?csnumber=40874

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

553

2.2. Data Aggregation
2.2.1. ArchiveSets
We group granules into ArchiveSets which are processed together. This grouping is arbitrary, but typically corresponds with speciÔ¨Åc experiments, processing campaigns, etc. This is useful for e-Science since each ArchiveSet
can be assigned to an owner who can manage and control processing and data within that ArchiveSet, and grant permissions and sharing of that information. URIs can locate the artifacts associated with each ArchiveSet and allow
that data to be accessed remotely or used for further processing. A key concept to an ArchiveSet is that it can never
hold two Ô¨Åles with the same type and GranuleKey, so {ArchiveSet,GranuleType,GranuleKey } is unique at a
point in time, or more generally {ArchiveSet,GranuleType,GranuleKey,Timestamp } always refers to at most
one physical granule, which itself has a globally unique Granule IdentiÔ¨Åer.
2.2.2. DataSets
Provenance information is tracked down to the granule level during all data processing, but since there are over
5000 orbital granules per year we‚Äôve found it useful to refer to all the Granules of a given type in the same ArchiveSet
as a DataSet. We can then summarize some provenance facts at a higher level.
For example, consider production of the Ô¨Årst 1000 granules of L2TO3 with version 1.7 of the algorithm in
ArchiveSet 1, we can say:
{L2TO3,1,1 } ‚Üí {APP-L2TO3,1.7 }
{L2TO3,2,1 } ‚Üí {APP-L2TO3,1.7 }
{L2TO3,3,1 } ‚Üí {APP-L2TO3,1.7 }, etc.
Those granules are all part of a DataSet {L2TO3,1 } (type = L2TO3 and ArchiveSet = 1).
Those facts can be summarized and expressed for human consumption by simply saying:
{L2TO3,1-1000,1 } ‚Üí {APP-L2TO3,1.7 }, or as a triple asserting the DataSet {L2TO3,1 } ‚Üí {APP-L2TO3,1.7 }.
If the L2TO3 APP was upgraded from version 1.7 to version 1.8 at orbit 500, the GranuleKey ranges can be summarized by coalescing ranges:
{L2TO3,1-500,1 } ‚Üí {APP-L2TO3,1.7 },
{L2TO3,501-1000,1 } ‚Üí {APP-L2TO3,1.8 }
or as triples associating both versions of the APP directly with the DataSet:
DataSet {L2TO3,1 } ‚Üí {APP-L2TO3,1.7 },
DataSet {L2TO3,1 } ‚Üí {APP-L2TO3,1.8 }.

2.2.3. Versions
As discussed above, the software version is relatively straight forward. Data versions, however, are more complicated. Historically, the most common practice was to simply use the version of the software that produced the data
product. Consider the relatively common case of the calibration table, which is an input to the L1B process, changing.
Even though the version of the L2 or L3 software hasn‚Äôt changed, the data Ô¨Åles in the whole process have been aÔ¨Äected
by the change in the calibration.
ArchiveSets allow us to separate, identify, and refer to the DataSets that have been produced in diÔ¨Äerent manners,
not just in terms of the version of the immediate predecessor software, but isolating a whole set of changes from one
another.
As granules are added to an ArchiveSet, they become part of the DataSet for their data type. Within the ArchiveSet,
we also maintain identiÔ¨Åers for the data processes in the workÔ¨Çow. my Grid uses a similar scheme for establishing identities of workÔ¨Çow provenance and data products. [10] In particular, the Taverna IDSet aggregation identity scheme has
similarities to our DataSet concept, though ArchiveSets and GranuleKey geospatial/temporal enumerations simplify
aggregation for the special case of earth science data. We follow the Strong IdentiÔ¨Åcation and via our DataSets, the
Strong IdentiÔ¨Åcation with IDSet identiÔ¨Åcation strategies as described by Chapman and Jagadish. [11]
As noted, this process is operational, so new granules are added every day. In order to precisely refer to a speciÔ¨Åc
set of granules, we timestamp each granule on ingest or removal, and allow a date/time diÔ¨Äerentiator on a DataSet
granule membership query to determine the speciÔ¨Åc list of granules.

554

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

	


















	







	




	


























Figure 2: Ozone Example

3. Provenance Equivalence IdentiÔ¨Åcation
A more speciÔ¨Åc example of the data processing graph is shown in Ô¨Ågure 2. This graph uses the historical provenance convention, where the arrows indicate the used and wasGeneratedFrom relationships, so are backward from the
data Ô¨Çow diagram. The Ô¨Ågure shows the basic input Ô¨Åles, and a link to the software used in each process, but omits
much other information, including the provenance graph of the software, and the compute environment.
3.1. Single Level
The Ô¨Årst case is to reproduce the Ô¨Ånal granule, {L3,2010-02-01,1 }. A query of the identiÔ¨Åer for that granule
will discover that it was produced from {L2,1,1 }, {L2,2,1 } and {L2,3,1 } using the software {APP L3,4.2,1 }.
If they are all available, we can simply re-run the APP and produce the output granule.
3.2. Multi Level
Assume the immediate predecessor Ô¨Åles are not available. The science team has delivered a new version of the
Level 2 lookup table, {LUT,8 }, and all of the L2 data have been reprocessed. Instead of those granules, the system
holds {L2,1..3,2 }.
Querying the provenance of the original Ô¨Åles shows how they were produced, and links to the speciÔ¨Åc input
granules from them. So, for example, {L2,1,1 } was produced from {L1B,1,1 } and {LUT,7 } by {APP L2,8.1,1 }.
The current granule however is {L2,1,2 }, produced from tupleL1B,1,1 and {LUT,8 } by {APP L2,8.1,1 }. Since
the updated LUT causes the resulting granule not to be scientiÔ¨Åcally equivalent, it can‚Äôt be used by our reproducing
process.
We must instead additionally reproduce {L2,1,1 }. Since all of its inputs are available, it can be re-run and will
produce a new granule {L2,1,3 }. This newly produced granule is distinct and has a distinct identiÔ¨Åer from the
original{L2,1,1 }. The associated provenance information about when it was produced, where it was produced, etc.
are all diÔ¨Äerent and are linked individually (represented by semantic tagging) to the distinct identiÔ¨Åers. The important
fact though is that the distinct granules {L2,1,1 } and {L2,1,3 } have the same essential provenance and assuming
the process is scientiÔ¨Åcally reproducible, should be scientiÔ¨Åcally equivalent to on another. Also, each of them are not
scientiÔ¨Åcally equivalent to the other granule, {L2,1,2 }.

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

555

3.3. Provenance Equivalence IdentiÔ¨Åers
Starting from the root of the graph, we can tag each granule with an additional identiÔ¨Åer to represent the provenance equivalence of that granule. We construct it by computing a digital signature of the elements of Essential
Provenance of the process that produced that granule. For the raw, level 0 data, we use a hash of our unique identiÔ¨Åer
for that granule.
{L1B,1,1 } ‚Üí H({L0,2010-02-01T02,1 },
{L0,2010-02-01T04,1 },
{CAL,2 },
{APP L1B,1.7,1 })
{L1B,1,1 } ‚Üí h1

{L2,1,1 } ‚Üí H(h1 ,
{LUT,7 },
{APP L2,8.1,1 })
{L2,1,1 } ‚Üí h2

The newly processed {L2,1,2 } was made with a diÔ¨Äerent lookup table, so it has a diÔ¨Äerent digital signature:
{L2,1,2 } ‚Üí H(h1 ,
{LUT,8 },
{APP L2,8.1,1 })
{L2,1,2 } ‚Üí h3

but since we reproduced {L2,1,3 } in a scientiÔ¨Åcally equivalent manner, it gets the same signature:
{L2,1,3 } ‚Üí H(h1 ,
{LUT,7 },
{APP L2,8.1,1 })
{L2,1,3 } ‚Üí h2

Now to reproduce {L3,2010-02-01,1 }, we look up its immediate predecessors, and Ô¨Ånd that the speciÔ¨Åc input
granule was {L2,1,1 }, which isn‚Äôt available, but we can request other granules with the same Provenance Equivalence
IdentiÔ¨Åer (PEI) that should be scientiÔ¨Åcally equivalent to the one we desire, since they have equivalence hash h2 , and
Ô¨Ånd that granule {L2,1,3 } is an acceptable (scientiÔ¨Åcally equivalent) granule to use.
3.4. ScientiÔ¨Åcally Equivalent Software
This technique can also be applied to the software itself to represent scientically equivalent software. We include
in the essential provenance of the software executable all of the dependencies both on the compiler versions and
the library versions that can aÔ¨Äect scientiÔ¨Åc equivalence. In this way, an executable is tagged not just with a speciÔ¨Åc
version, but also with a Provenance Equivalence IdentiÔ¨Åer summarizing the manner in which it was built. As discussed
above, the versions of some of of those elements could (through analysis or testing validation) determined to be
scientiÔ¨Åcally equivalent and tagged as such. For example, if it was determined (and validated) that libx version 1.8.1
was scientiÔ¨Åcally equivalent to libx version 1.8.2 (even though they both might be diÔ¨Äerent from version 1.7.1), those
two versions could be tagged with the same signature by excluding that minor version.

556

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

4. Semantic Provenance Tagging
4.1. Data Citations
A major purpose for data set identiÔ¨Åers is for data citations. The particular contents of proper data citations is
beyond the scope of this paper [12], but are part of the use case of concern. If a reader of a journal article citing a
dataset wants to reproduce that dataset in order to reproduce the science described by the research, the citation, and the
data identiÔ¨Åer must be suÔ¨Écient to produce a similar data set that is ScientiÔ¨Åcally Equivalent to the cited dataset. This
requires an identiÔ¨Åer that can be resolved to the level of granule membership, software source version, and suÔ¨Écient
identiÔ¨Åcation of the software build environment and compute environment for an independent party to reproduce the
data set.
Consider the problem of Data Citation comparison. Two researchers access similar, but not identical dataset. They
each rigorously cite their data, but those data identiÔ¨Åers each refer to very large sets of data. The question then comes,
what is the diÔ¨Äerence? Each of the dataset identiÔ¨Åers provide entry into potentially extremely large semantic web
graphs of their entire granule membership and provenance graphs for each of those granules. A mechanical process
of comparing those provenance graphs becomes very diÔ¨Écult and time consuming. Categorizing certain provenance
properties as essential for reproducibility, and tagging each granule with a Provenance Equivalence IdentiÔ¨Åer summarizing the provenance can make that comparison process easier.
4.2. Data Model and Ontologies
Our system assigns a unique, persistent URL 3 to each artifact in the system, then relates those artifacts to one
another and represents their relationship and using various ontologies. The basic workÔ¨Çow information maps into
the Open Provenance Model (OPM) [4], and can be exported in the XML or semantic web RDF representations of
that data model. We are using some other standard ontologies for computer inventory information and related context
information and some local experimental ontologies for tagging our application speciÔ¨Åc information, including the
Provenance Equivalence IdentiÔ¨Åer.
5. Conclusions and Future Work
Complete provenance capture can enable complete reproducibility of a complex process by going back to the
raw data. Systematic semantic tagging of provenance equivalence based on cascaded digital signatures of a canonical
serialization of essential provenance elements can enable subsets of the process to be sampled and reproduced reliably
at a higher level. When data sets are diÔ¨Äerent, Provenance Equivalence IdentiÔ¨Åers can also simplify comparison of
data set provenance graphs and help summarize the diÔ¨Äerences.
We plan on implementing more of the increasingly standardized provenance ontologies for the representation
of provenance information from our data processing system. We will document a standard essential provenance
canonicalization representation so the digital signatures can be produced by others reproducing our process. Our
goal is to extend our dataset and granule identiÔ¨Åers and complete provenance artifacts into the linked data cloud and
provide a service for comparing datasets through their provenance graphs.
Acknowledgment
The authors would like to acknowledge contributions from the ACPS software development team and numerous
discussions with the NASA Earth Science Data Systems Working Group (ESDSWG4 ) and the Federation of Earth
Science Information Partners (ESIP FED) Data Preservation Cluster5 .
3 http://purl.org
4 http://esdswg.eosdis.nasa.gov/
5 http://wiki.esipfed.org/index.php/Preservation_and_Stewardship

C. Tilmes et al. / Procedia Computer Science 4 (2011) 548‚Äì557

557

References
[1] B. Barkstrom, A mathematical framework for earth science data provenance tracing, Earth Science Informaticsdoi:10.1007/
s12145-010-0057-0.
URL http://dx.doi.org/10.1007/s12145-010-0057-0
[2] J. Frew, R. Bose, Earth system science workbench: a data management infrastructure for earth science products, in: ScientiÔ¨Åc and Statistical
Database Management, 2001. SSDBM 2001. Proceedings. Thirteenth International Conference on, 2001, pp. 180 ‚Äì189. doi:10.1109/
SSDM.2001.938550.
[3] D. A. Holland, M. I. Seltzer, U. Braun, K.-K. Muniswamy-Reddy, Passing the provenance challenge, Concurr. Comput. : Pract. Exper. 20
(2008) 531‚Äì540. doi:10.1002/cpe.v20:5.
URL http://portal.acm.org/citation.cfm?id=1350745.1350747
[4] L. Moreau, B. CliÔ¨Äord, J. Freire, J. Futrelle, Y. Gil, P. Groth, N. Kwasnikowska, S. Miles, P. Missier, J. Myers, B. Plale, Y. Simmhan,
E. Stephan, J. V. den Bussche, The open provenance model core speciÔ¨Åcation (v1.1), Future Generation Computer Systems.
URL http://eprints.ecs.soton.ac.uk/21449/
[5] M. Altman, G. King, A proposed standard for the scholarly citation of quantitative data, D-Lib Magazine 13 (3/4).
[6] C. Tilmes, A. J. Fleig, Provenance Tracking in an Earth Science Data Processing System, in: Provenance and Annotation of Data
and Processes, Vol. 5272 of Lecture Notes in Computer Science, Springer Berlin / Heidelberg, 2008, pp. 221‚Äì228. doi:10.1007/
978-3-540-89965-5_23.
URL http://www.springerlink.com/content/3433g6633h91781k/
[7] C. Tilmes, Y. Yesha, M. Halem, Provenance Artifact IdentiÔ¨Åcation in the Atmospheric Composition Processing System (ACPS), Proceedings
of the 2nd Workshop on the Theory and Practice of Provenance.
URL http://www.usenix.org/events/tapp10/tech/full_papers/tilmes.pdf
[8] P. Bhartia, Total ozone from backscattered ultraviolet measurements, in: G. Visconti, P. Carlo, W. Brune, A. Wahner, M. Schoeberl (Eds.),
Observing Systems for Atmospheric Composition, Springer New York, 2007, pp. 48‚Äì63, 10.1007/978-0-387-35848-2 3.
URL http://dx.doi.org/10.1007/978-0-387-35848-2_3
[9] C. Tilmes, Y. Yesha, M. Halem, Tracking provenance of earth science data, Earth Science Informatics 3 (2010) 59‚Äì65, 10.1007/s12145-0100046-3.
URL http://dx.doi.org/10.1007/s12145-010-0046-3
[10] C. G. Jun Zhao, R. Stevens, in: Provenance and Annotation of Data, Vol. 4145 of Lecture Notes in Computer Science, Springer Berlin /
Heidelberg, 2006, pp. 254‚Äì269. doi:10.1007/11890850, [link].
URL http://www.springerlink.com/content/ml4113ln11r538u0/
[11] A. Chapman, H. V. Jagadish, Provenance and the Price of Identity, Springer-Verlag, Berlin, Heidelberg, 2008, pp. 106‚Äì119. doi:10.1007/
978-3-540-89965-5_12.
URL http://portal.acm.org/citation.cfm?id=1484346.1484360
[12] M. Parsons, R. Duerr, J.-B. Minster, Data citation and peer review, EOS Vol. 91 (Num. 34).

