Available online at www.sciencedirect.com

ScienceDirect
Procedia Computer Science 108C (2017) 2443â€“2447

International Conference on Computational Science, ICCS 2017, 12-14 June 2017,
Zurich, Switzerland

Cognitive Agents Success in Learning to Cross a CA
Cognitive Agents Success in Learning to Cross a CA
Based Highway
Comparison
for Two
Cognitive
Agents Success
in Learning
to Decision
Cross a CA
Based Highway
Comparison
for Two
Decision
Formulas for Two Decision
Based Highway Comparison
Formulas
Formulas
Anna T. Lawniczak1* and Fei Yu2
1*

2

Anna T.ofLawniczak
Fei Yu
University
Guelph, Guelph,and
Ontario,
Canada
2
2 1*
University
Anna T.ofLawniczak
Guelph, Guelph,
and
Ontario,
Fei Yu
Canada
alawnicz@uoguelph.ca,
fyu03@uoguelph.ca
2
1,21
alawnicz@uoguelph.ca,
fyu03@uoguelph.ca
University
of Guelph, Guelph,
Ontario, Canada
1
alawnicz@uoguelph.ca, 2fyu03@uoguelph.ca
1,2

1,21

Abstract
Abstract
We study cognitive agentsâ€™ success in learning to cross a Cellular Automaton (CA) based highway, for
We
cognitive
agentsâ€™
success
learning in
to cross
Cellular Automaton
(CA)The
basedagents
highway,
Abstract
two study
decision
formulas
used
by thein agentsâ€™
their adecision-making
process.
use for
an
two
decision
formulas
used
bystrategy
thein agentsâ€™
their
process.
use for
an
We study
cognitive
agentsâ€™
success
learning
toon
cross
Cellular Automaton
(CA)The
based
highway,
â€œobservational
social
learningâ€
basedin
the adecision-making
observation
of performance
ofagents
other
agents,
â€œobservational
social
learningâ€
basedinwhat
ontheir
the
observation
of performance
other agents,
two decision
formulas
used
bystrategy
the
process.
Theof
agents
use an
mimicking
what
worked
for them
and agentsâ€™
avoiding
diddecision-making
not. We investigate
how the
incorporation
of
mimicking
whatof
worked
for of
them
and waiting
avoiding
what
didinto
not.their
We investigate
how the
incorporation
of
â€œobservational
social
learningâ€
strategy
baseddecisions
on the
observation
of performance
of
other
agents,
the assessment
outcomes
agents
decision-making
process
based
only
the
assessment
outcomes
agents
waiting
decisions
their
decision-making
process
based only
mimicking
whatofworked
for of
them
avoiding
what
didinto
not.affects
We investigate
how
the
incorporation
of
on the
assessment
of outcomes
ofand
their
crossing
decisions
the agentsâ€™
success
in learning
to
on
the
assessment
of
outcomes
of their
decisions
affects
the
success
in and
learning
to
the
assessment
of outcomes
of agents
waiting
decisions
their decision-making
process
based
only
cross
the
highway.
The
agentsâ€™
success
iscrossing
measured
by into
the numbers
of agentsâ€™
successful,
killed
queued
cross
highway. of
The
agentsâ€™ success
measured
by the numbers
of agentsâ€™
successful,
killed
queued
on
thethe
assessment
outcomes
of their iscrossing
decisions
affects the
success
in and
learning
to
agents
at
simulation
end.
agents
at simulation
end.agentsâ€™ success is measured by the numbers of successful, killed and queued
cross the
highway. The
Â© 2017 The Authors. Published by Elsevier B.V.
Keywords:
Agents, cognitive
agents, learning, decision-making, knowledge base, autonomous robots,
agents
at simulation
end.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
computational
intelligence,
cellular
automaton
Keywords:
Agents,
cognitive
agents,
learning, decision-making, knowledge base, autonomous robots,
computational
intelligence,
cellular
automaton
Keywords:
Agents,
cognitive
agents,
learning, decision-making, knowledge base, autonomous robots,
computational intelligence, cellular automaton

1 Introduction
1 Introduction
the rapid development
1 With
Introduction

of autonomous robots operating in dynamically changing
With the itrapid
development
of autonomous
robots operating
in is
dynamically
environments
is important
to study
how robots learning
performance
affected bychanging
various
environments
itrapid
isofimportant
to study
howcarried
robotsoutlearning
performance
affected bychanging
With theSome
development
of autonomous
robots
dynamically
parameters.
these
studies
may
be
throughoperating
modelinginandis
simulations
invarious
which
parameters.
these
studies
may cognitive
be
outlearning
through
modeling
andisthe
simulations
which
environmentsSome
it isofare
important
to study
howcarried
robots
performance
affected
byinvarious
autonomous
robots
identified
with
agents
[1]. We
investigate
performance
of a
autonomous
robots
identified
cognitive
[1].
Wemodeling
investigate
performance
ofbya
parameters.
Some
ofare
these
studies
may
be carriedagents
out
through
simulations
which
simple
learning
algorithm
based
on with
an
observational
social
learning
strategyand
in the
which
agentsinlearn
simple
learning
algorithm
based
on with
an
observational
social
learning
strategy
which
agentswhat
learnofdid
bya
autonomous
are identified
cognitive
agents
[1].
We investigate
the
performance
observing
therobots
performance
of other
agents,
mimicking
what
worked
for theminand
avoiding
observing
the performance
offocuses
other
agents,
mimicking
what
worked
for themin
and
what
simple
learning
algorithm
based
on an
learning
strategy
which
agents
learndid
by
not
in the
past
[2].
Our work
onobservational
simplicity
ofsocial
the
learning
algorithms
and
itavoiding
is an
extension
of
not
in
the past
[2]. Our[3]-[5].
workoffocuses
on simplicity
of the
learning
algorithms
and
itavoiding
is
an extension
of
the
previous
These
works
show
that
each
population
agents
simulation
enddid
is
observing
theresearch
performance
other agents,
mimicking
what
worked
forofthem
andat
what
the
previous
research
These
show ones,
that
each
population
of agents
at
simulation
end of
is
divided
into
three
of agents:
theworks
successful
thelearning
killed
ones,
and
theand
agents
stillextension
queuing
to
not in
the
past
[2].types
Our[3]-[5].
work
focuses
on
simplicity
of the
algorithms
it is
an
divided
three
types
of
agents:
theworks
successful
ones,
thesignificantly
killed
ones, and
the
agents
still
to
the previous
research
[3]-[5].
These
show
that each
population
of
at simulation
is
cross
theinto
highway.
The
queuing
agents
may
outnumber
theagents
successful
onesqueuing
for end
some
cross
theinto
highway.
The of
queuing
may outnumber
the the
successful
onesqueuing
for some
divided
three types
agents:agents
the successful
ones, thesignificantly
killed ones, and
agents still
to
cross
the highway. The queuing agents may outnumber significantly the successful ones for some
*

Corresponding author. The authors acknowledge useful discussions with B. Di Stefano, L. Ly and H. Wu. A.T. Lawniczak
acknowledges
partial
financial
support
from the NSERC
Canada. with B. Di Stefano, L. Ly and H. Wu. A.T. Lawniczak
Corresponding
author.
The authors
acknowledge
useful of
discussions
*acknowledges partial financial support from the NSERC of Canada.
Corresponding author. The authors acknowledge useful discussions with B. Di Stefano, L. Ly and H. Wu. A.T. Lawniczak
*

acknowledges partial financial support from the NSERC of Canada.

1877-0509 Â© 2017 The Authors. Published by Elsevier B.V.
Peer-review under responsibility of the scientific committee of the International Conference on Computational Science
10.1016/j.procs.2017.05.056

2444	

Anna T. Lawniczak et al. / Procedia Computer Science 108C (2017) 2443â€“2447

values of the model parameters. We investigate, if incorporation of the assessment of the agentsâ€™
waiting decisions into their decision-making process used in [3]-[5], which was based only on the
assessment of their crossing decisions, improves the agentsâ€™ success in crossing.
The paper is organized as follows: Section 2 briefly describes the model focusing on agentsâ€™
decision-making algorithms; Section 3 describes how agentsâ€™ decision formulas affect the relative
frequency of numbers of successful, killed and queued agents at simulation end, and Section 4 reports
our conclusions and outlines future work.

2 Model of Agents Learning to Cross a CA Based Highway
For the full description of the model the reader is referred to [3]-[5]. Here, we focus on the agentsâ€™
decision-making formulas used by them in their decision-making process of crossing a highway. We
assume that the agents (1) want to learn how to cross a single lane unidirectional highway without
being hit/killed by the oncoming vehicles; (2) are capable of approximating distances and velocities of
moving vehicles; (3) witness what had happened to the agents that previously crossed the highway at
their crossing point (CP); (4) can imitate the agents which crossed successfully; (5) can decide not to
cross and wait for better conditions, or look for a different CP when unsuccessful crossings outnumber
the successful ones. These allow each CP to build one knowledge base (KB) during the experiment
that is available to all agents at that CP.
We model the highway traffic by adopting the Nagel-Schreckenberg cellular automaton (CA)
model, for details see [3]-[7]. An agent is generated only at a CP set at the initialization step and is
placed into the queue at this CP. Each generated agent falls with equal probability (0.25) into one of
the four categories: (1) no Fear nor Desire; (2) only Fear; (3) only Desire; (4) both Fear and Desire.
These attributes of agents play a role in their decision-making process of crossing the highway through
the values of Fear (aversion to risk taking) and Desire (propensity to risk taking) that an agent may
experience. The agents, within their limited horizon of vision, can perceive only fuzzy levels of speed
(e.g., slow, medium, fast, very fast) and of distance (e.g., close, medium, far). At a CP, the agents
build up in the queue until the one at the top of the queue, called an active agent, decides to cross, or if
a simulation setup permits, moves with probability 1/3 right or left to a different location to attempt to
cross from there.
Each active agent must make one of the following two decisions: Crossing Decision (CD) or
Waiting Decision (WD). If an active agent decides to cross it may either succeed, we call such
crossing decision Correct Crossing Decision (CCD), or it may be hit/killed, and we call such crossing
decision Incorrect Crossing Decision (ICD). Similarly, each WD of an active agent can be assessed as:
Correct Waiting Decision (CWD), this is the case when, if the agent did not wait and chose to cross, it
would be hit; or Incorrect Waiting Decision (IWD), this is the case when, the agent chose to wait but it
would cross the highway successfully. The assessment of each decision of an active agent, i.e. if the
decision was CCD, ICD, CWD, or IWD, is recorded, respectively, as a count in the Knowledge-Based
(KB) table of all agents waiting at CP of the active agent. Thus, the KB table is associated with each
CP.
Each KB table is organized as a matrix with an extra row entry, corresponding to agentsâ€™ out of
range vision, i.e. the situation in which an active agent cannot perceive if outside its horizon of vision
there is a car and if it is, what is its velocity. The columns names are slow, medium, fast and very fast
and the rows names are close, medium and far. At each time t, each entry (including the extra row
entry) of the KB table contains four numbers; each of them corresponds to a type of decision made by
the active agents up to time t-1. These numbers are: number of CCDs, ICDs, CWDs and IWDs. The
KB table is initialized in the same way as in [3]-[5]. After the initialization of a simulation, each active
agent consults the KB table to decide if it is safe or not to cross. Its decision is based on the
implemented intelligence/decision-making algorithm, which for a given (distance, velocity) pair or out

	

Anna T. Lawniczak et al. / Procedia Computer Science 108C (2017) 2443â€“2447

of range vision combines the success ratio of crossing the highway for the observed situation with the
agentsâ€™ Fear and/or Desire parametersâ€™ values. The main simulation loop of the model is described in
[3]-[5].
The decision-making process of described in [3]-[5] considers only the outcomes of CDs. Since the
number of successful agents equals the number of CCDs, and the number of killed agents equals the
number of ICDs, we call the decision formula (DF) of [3]-[5] as Crossing Based Decision Formula
(cDF) and for each ğ‘–ğ‘–ğ‘–ğ‘– #$ entry of the KB table at time ğ‘¡ğ‘¡ (out of range entry is denoted by (0,0)) the
ğ·ğ·ğ·ğ·() ğ‘¡ğ‘¡ of DF is calculated as follows:
																																												ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ = ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ + ğ‘£ğ‘£ ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ· âˆ’ ğ‘£ğ‘£ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ ,																																		(1)

where ğ‘£ğ‘£(ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·) and ğ‘£ğ‘£(ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹) are the values of the active agent Fear and Desire parameters, and
ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() (ğ‘¡ğ‘¡) is the Crossing Based Success Ratio (cSR) corresponding to the ğ‘–ğ‘–ğ‘–ğ‘– #$ entry of the KB table,
which is defined as follows:
																														ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ = 	 {ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶() ğ‘¡ğ‘¡ âˆ’ 1 âˆ’ ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() ğ‘¡ğ‘¡ âˆ’ 1 } ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶#>#?@ ğ‘¡ğ‘¡ âˆ’ 1 .																					 2

The terms ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶() (ğ‘¡ğ‘¡ âˆ’ 1) and ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() (ğ‘¡ğ‘¡ âˆ’ 1) are, respectively, the numbers of CCDs and ICDs recorded
in the ğ‘–ğ‘–ğ‘–ğ‘– #$ entry of the KB table at time ğ‘¡ğ‘¡. The term ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶#>#?@ (ğ‘¡ğ‘¡ âˆ’ 1) is the sum of numbers of all the
CCDs over all the entries of the KB table. After the initialization, if ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ â‰¥ 0, then an active agent
will cross. If ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ < 0, then the active agent will wait and additionally it may move to another
crossing point, if the simulation setup permits.
The Crossing-and-Waiting Based Decision Formula (cwDF) incorporates the assessment of both
CDs and WDs of the active agents. The formula cwDF is obtained from cDF formula by replacing the
term ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ 	by the term ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ 	in the cDF formula (1). The term ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ ,	 called Crossingand-Waiting Based Success Ratio (cwSR), is defined for each ğ‘–ğ‘–ğ‘–ğ‘– entry of the KB table at time ğ‘¡ğ‘¡ as
follows:
ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ = {ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶() ğ‘¡ğ‘¡ âˆ’ 1 âˆ’ ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() ğ‘¡ğ‘¡ âˆ’ 1 âˆ’ ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶() ğ‘¡ğ‘¡ âˆ’ 1 	 + 	 ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() (ğ‘¡ğ‘¡ âˆ’ 1)}/ğ‘†ğ‘† ğ‘¡ğ‘¡ âˆ’ 1 ,						(3)	
															
where ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶() ğ‘¡ğ‘¡ âˆ’ 1 , ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() (ğ‘¡ğ‘¡ âˆ’ 1), ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶() ğ‘¡ğ‘¡ âˆ’ 1 and ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() (ğ‘¡ğ‘¡ âˆ’ 1) are, respectively the numbers of
CCDs, ICDs, CWDS and IWDs in the KB table entry ğ‘–ğ‘–ğ‘–ğ‘–, recorded up to time ğ‘¡ğ‘¡ âˆ’ 1. The term
ğ‘†ğ‘† ğ‘¡ğ‘¡ âˆ’ 1 is the sum of the numbers of all the decision types recorded in all the entries of the KB table
up to time ğ‘¡ğ‘¡ âˆ’ 1,	i.e.
											ğ‘†ğ‘† ğ‘¡ğ‘¡ âˆ’ 1 =

() {ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶()

ğ‘¡ğ‘¡ âˆ’ 1 + ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() ğ‘¡ğ‘¡ âˆ’ 1 + ğ¶ğ¶ğ¶ğ¶ğ¶ğ¶() ğ‘¡ğ‘¡ âˆ’ 1 + ğ¼ğ¼ğ¼ğ¼ğ¼ğ¼() ğ‘¡ğ‘¡ âˆ’ 1 }.											(4)

Thus, the formula cwDF can be written as

																																															ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ = ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() ğ‘¡ğ‘¡ + ğ‘£ğ‘£ ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ·ğ· âˆ’ 	ğ‘£ğ‘£ ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ğ¹ .																																						(5)		

An active agent decides to cross the highway only when ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘() â‰¥ 0. Otherwise, the active agent will
wait and additionally it may move to another crossing point, if the simulation setup allows this.

2445

2446	

Anna T. Lawniczak et al. / Procedia Computer Science 108C (2017) 2443â€“2447

3 Simulation Results
For each DF type, i.e. cDF and cwDF, two data sets were generated with the same values of the
other parameters. The constant values of the parameters in the simulations were: (1) the single lane
highway of the length of 120 cells; (2) the CP set at the cell 60 at the initialization step; (3) duration of
1511 time steps of each simulation run; (4) 30 repetitions of each simulation set up. A car was
perceived as: close if it was 0 to 5 cells away, medium far if it was 6 to 10 cells away, far if it was 11
to 15 cells away and out of range if it was 16 or more cells away, regardless of the true velocity of the
car. If the velocity of a car was 0 to 3 cells, 4 or 5 cells, 6 or 7 cells, or 8 to 11 cells per time step, then
the car was perceived, respectively, as slow, medium speed, fast, or very fast. A carâ€™s max speed was
set as 11 cells per time step.

Figure 1: Relative frequency of numbers of queued agents (called creatures) at simulation end calculated,
respectively, for four types of simulations with HM=0. These frequencies are defined by the following
parametersâ€™ setups: (cDF, KBT=0), (cDF, KBT=1), (cwDF, KBT=0), (cwDF, KBT=1). The legend box describes
the correspondence between the bar plots and the frequencies â€œfâ€ depending on the setup of these parameters. The
â€œnKBtâ€ stands for (KBT=0) and â€œKBtâ€ stands for (KBT=1) in the legend box.

There are 6 parameters values of which vary through the main simulation loop. These parameters
are: (1) car creation probability, i.e. CCP, taking values: 0.1, 0.3, 0.5, 0.7, and 0.9; (2) Fear and
Desire parameters, each taking values: 0.00, 0.25, 0.5, 0.75, and 1.00; (3) the KB transfer direction
parameter KBT, which can be set as: â€œnoneâ€ (KBT=0), or â€œforwardâ€ (KBT=1). This parameter
determines if the KB table of the initial CP can be transferred (KBT=1) or not (KBT=0) at the end of a
simulation run with lower CCP value to the beginning of a simulation run with immediately higher
value of CCP. For details see, [3]-[5]; (4) random deceleration RD, when RD=1, the speed of each car
is decreased randomly with probability 0.5, when RD=0 this is not allowed; (5) an active agent (called
also a creature) horizontal movement HM, which can take value 0 or 1. If HM=1, then an active
agents can move to a different CP, but not further away than 5 cells, if HM=0 this is not allowed.
When HM=0, the maximum number of the successful agents can be only 50% of all the generated
agents (i.e., 755 in our case). This is due to the model design, as it takes 2 time steps for an active
agent to cross the highway. Setting HM=1 removes this 50% bound on the maximum number of
successful agents. Therefore, for the analysis the simulation data is split further by the parameter HM.

	

Anna T. Lawniczak et al. / Procedia Computer Science 108C (2017) 2443â€“2447

For both DFs, the numbers of killed agents (creatures), at simulation ends are always very small
(i.e., less than 50) in comparison with 1511 generated creatures. Because of this, when the number of
successful creatures is small the number of queued creatures is big and vice versa. Here, we analyse
how cDF and cwDF effects creaturesâ€™ performance by looking only at the relative frequencies of
numbers of queued creatures at simulation end, when HM=0. These frequencies are calculated as
follow: we divide the interval from 0 to 1511 into the following subintervals: [0, 250], (250, 500],
(500, 750], (750, 1000], (1000, 1250], and (1250, 1511]. Then, at simulation end in each data subset of
queued creatures we count how many times the number of queued creatures falls into each subinterval.
For the display, we normalize the obtained numbers by dividing them by the total number of the
individual simulation runs in the entire data subset and display the obtained relative frequencies as
percentages. Given that for HM=0, the maximum number of successful creature at simulation end
cannot be bigger than 755, this implies that for HM=0, most of the numbers of queued creatures at
simulation end are bigger than 750, as Figure 1 shows. Additionally, this figure shows that when
cwDF is used most numbers of queued creatures at simulation end (i.e., 61.2% when KBT=0 and
87.9% when KBT=1) are between 750 and 1000, while when cDF is used most of these numbers (i.e.,
71.2% when KBT=0 and 67% when KBT=1) are between 1250 and 1511. Thus, the use of cwDF
improves the creaturesâ€™ performance by decreasing the numbers of queued creatures. We notice that
the KB transfer has stronger effect on creaturesâ€™ performance for cDF than cwDF. In general, the use
of cwDF leads to smaller (bigger) numbers of queued (successful) creatures at simulation ends,
regardless if the KB transfer takes place or not. This confirms that the inclusion of the assessment of
creatures WDs into their DF improves their performance, which is further enhanced by transfer of KB.

4 Conclusions and Future Work
The presented work shows that the incorporation of the assessment of agents waiting decisions into
their decision-making formula, improves the agentsâ€™ performance, i.e. it increases the numbers of
agents crossing the highway successfully by decreasing the numbers of queuing agents attempting to
cross without affecting the numbers of killed agents. The coupling of the decision formula based on
crossing and waiting decisions outcomes with agentsâ€™ knowledge base transfer further improves
agentsâ€™ performance. We plan to explore other types of decision-making algorithms and study the
agentsâ€™ performance for them.

References
[1]
[2]
[3]
[4]
[5]
[6]
[7]

S. Russell, P. Norvig, â€œArtificial Intelligence, A Modern Approachâ€, Pearson Education Limited, 2014.
Ch.L. Nehavin, K. Dautenhahn, â€œImitation and Social Learning in Robots, Humans and Animalsâ€, Cambridge University
Press, Cambridge, UK, 2007.
A.T. Lawniczak, B.N Di Stefano, J.B. Ernst, NaÃ¯ve Creature Learns to Cross a Highway in a Simulated CA-Like
Environmentâ€, 2014 IEEE Symposium on Intelligent Agents (IA), Orlando, FL, 09-12 Dec. 2014, pp. 30-37.
A.T. Lawniczak, B.N. Di Stefano, L. Ly, S. Xie, â€œPerformance of Population of NaÃ¯ve Creatures with Fear and Desire
Capable of Observational Social Learningâ€, Acta Physica Polonica Series B, Proceedings Supplement, Vol. 9 (1), 2016,
pp. 95-107.
A.T. Lawniczak, L. Ly, F. Yu, S. Xie, â€œEffects of Model Parameter Interactions on NaÃ¯ve Creaturesâ€™ Success of Learning
to Cross a Highwayâ€, The 2016 IEEE Congress on Evolutionary Computation (IEEE CEC 2016) at IEEE WCCI 2016, 10
pages.
K. Nagel, M. Schreckenberg, â€œA cellular automaton model for freeway trafficâ€, J. Physique I, 2, 1992, pp. 2221 â€“ 2229.
A.T. Lawniczak, B.N. Di Stefano,â€œDigital Laboratory of Agent-Based Highway Traffic Modelâ€, Acta Physica Polonica B
Proc. Supplement, Vol. 3, No. 2, February 2010, pp. 479-493.

2447

