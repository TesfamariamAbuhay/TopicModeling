Available online at www.sciencedirect.com

Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

International Conference on Computational Science, ICCS 2013

Performance Evaluation of Levenberg-Marquardt Technique in
Error Reduction for Diabetes Condition ClassiÔ¨Åcation
Nawaz Khana,‚àó, Dhara Gaurava , Thomas Kandlb
a School

of Science and Technology, Middlesex University, Hendon, London and NW4 4BT, UK
b F. HoÔ¨Ämann-La Roche, 4070 Basel, Switzerland

Abstract
This paper aims to provide a case study to classify diabetes medical condition amongst patients. The study examines the
performance of the Levenberg-Marquardt (LM) algorithm on a single dataset, the Pima Indian Diabetes dataset, attempting to
minimize error in classifying the patients as diabetes positive or negative. The learning algorithm is applied on dynamically
constructed neural network to minimize the error by continuously training the network until the optimum eÔ¨Éciency level is
obtained. The performance of the approach is veriÔ¨Åed by performing a comparison study. The comparison study involves
testing of the dynamically constructed network and presents a critical analysis of the classiÔ¨Åcation output. The performance
of the network is measured in terms of sensitivity and speciÔ¨Åcity for diÔ¨Äerent learning algorithms. The study reveals that the
LM algorithm outperforms other techniques in these tests and consequently concludes it to be the best ANN learning rule in
providing optimum output results when applied to a dynamically constructed neural network.
Keywords: ArtiÔ¨Åcial Neural Networks; Levenberg-Marquardt Algorithm;Diabetes ClassiÔ¨Åcation

1. Introduction
The Ô¨Åeld of medical informatics is devoted to the structuring, processing, storage and dissemination of information for many purposes [1]. The central goal though behind these eÔ¨Äorts is to develop a decision support system
which improves the human ability to diagnose, treat and propose preventive measures for pathological conditions.
Despite the great advances in the eÔ¨Écacy of mainstream medical science in the diagnosis of diseases and ailments,
the presence of human variation and the resulting heterogeneity in symptoms exhibited present a signiÔ¨Åcant challenge to making accurate diagnoses in every single case. One solution to this problem lies in performing studies of
aggregate data which often yields useful statistical rationales which can greatly contribute in decision making for
medical conditions. ArtiÔ¨Åcial Neural Networks (ANN) learning algorithms discussed in this paper, present potent
approach to accomplish such tasks. The use of artiÔ¨Åcial neural techniques in medical condition detection reported
in medical literatures not only adds value to diagnostic predictions but also act as a prediction guide. Algorithms
following analytical methods which are proposed in diÔ¨Äerent researches replaced statistical descriptive analysis
to get approximate solutions for real world disease prediction problems [2, 31, 32]. However, the application of
neural network and learning algorithms has been increased in recent days and reduced too much reliance on the
statistical description for disease classiÔ¨Åcation.
‚àó Corresponding

author. Tel.: +44-208-411-4273
E-mail address: n.x.khan@mdx.ac.uk.

1877-0509 ¬© 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and peer review under responsibility of the organizers of the 2013 International Conference on Computational Science
doi:10.1016/j.procs.2013.05.455

2630

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

The use of ANN for analytic purposes in Biology and Chemistry has been gaining attention and it has been
heralded as one of the good ways to prevent and diagnose disease [3]. Neural networks are able to imitate the
human learning process and human intuitions and can therefore solve non-linearity matters. As such it has been
widely used in the calculation and prediction of complex systems, achieving a non-linearity mapped eÔ¨Äect which
even conventional calculating methods could not accomplish [4]. Results obtained through the use of Neural
Networks are frequently comparable to those of standard statistical models. The use of the classiÔ¨Åer system for
medical diagnosis is increasing gradually [17, 28].
Studies conducted on the eÔ¨Écacy of ANN in medical diagnosis to date have been generally very promising.
For example, ANNs have been shown to correctly classify diverse conditions such as acute nephritic disease and
heart disease with a success rate of up to 99% and 95% respectively [12]. Another notable study conducted on
the broad applications of artiÔ¨Åcial intelligence in medical diagnostics by Monadjemi and Moallem showed that
fuzzy neural networks could eÔ¨Äectively approximate the real world diagnostic methods of physicians, correctly
discerning abnormalities in ETM disease samples at rates of around 97.5% [13]. Applications of neural nets have
also yielded success in aiding the diagnosis of urinary conditions [14]. Back propagation method was used in
detection of peripheral artery occlusive disease [16].
The use of neural nets in the diagnosis of diabetes has also been previously investigated by many researches
which concluded that a Bayesian regulation algorithm was most eÔ¨Äective in predicting Diabetes [15]. Venkatesan
and Anitha conducted a similar study comparing Radial Basis Function (RBF) neural nets with common MLP
algorithms and classical logistic regression in their eÔ¨Écacy of predicating Diabetes, concluding that the RBF
algorithm performed the best [16]. Recently, advances in Support Vector Machine methods have also resulted in
promising results. An Adaptive SVM method is proposed in [17] in which they report to have a classiÔ¨Åcation rate
of 100% when applied to a Diabetes dataset from the University of California [17]. Functional model for ANN is
proposed in [17] and demonstrated nearly 89% of accuracy for detecting Thrombo-embolic stroke disease.
The examples above ascertain the fact that neural network is capable of diagnosis and classify medical conditions [33][34], however, all these approaches involve a series of modiÔ¨Åcations on the combinations of diÔ¨Äerent
learning algorithms and pre-processing of data set to get an optimum result [35][36][37] whereas, our research
focuses on single optimized algorithms to identify optimum ability to gain best possible accuracy for the classiÔ¨Åcation purpose. This research also has conducted experiments to identify the causes of error rate. This study then
provide with a comparative study to demonstrate the level of accuracy for diÔ¨Äerent algorithms applied for diabetes
prediction.
This research attempts to apply optimised Levenberg Marquardt (LM) algorithms for minimizing errors in
classifying diabetes condition. LM is widely used in manufacturing and for engineering optimisation purpose [22],
however, have these algorithms never been investigated on a neural network for medical condition classiÔ¨Åcation
[38][39][40]. The algorithm is then compared with others to determine its accuracy. In this study the Pima Indian
Diabetes Database is subjected to the ANN technique using Levenberg-Marquardt Algorithm training method to
ascertain and classify the presence of diabetes in subjects and experiments are further conducted to determine the
sensitivity and speciÔ¨Åcity of the optimised LM technique.The algorithms and methods used in diabetes condition
classiÔ¨Åcation are presented below.
2. Algorithm and Network Structure
The algorithms which this research focuses upon is a MLP (Multi-layer Perceptron) training algorithm. These
algorithms belong to the supervised learning methods. The MLP training algorithms are divided into several types
which are inclusive of gradient based ones which compute the derivative of the error function with respect to
each and every weight, and then alter the weights in order to minimize the error. Some of them used for classiÔ¨Åcation purposes are backpropagation, RPROP, Quick prop (QP), Scaled Conjugate Gradient, Quasi-Newton and
Levenberg-Marquardt Algorithm (LM), RLS [18, 19, 20 and 21]. Other category of algorithms are global optimization methods that dont change weights based on the gradient direction but attempt to hunt for the minimum
in much wider areas, e.g. simulated annealing, Alopex, Novel, Genetic Algorithms. This research implements the
gradient based algorithms to investigate their performance in diabetes classiÔ¨Åcation.
The Levenberg-Marquardt (LM) algorithm is a higher-order adaptive algorithm and minimise the Mean Square
Error of a neural network [5]. The algorithm is a member of a class of learning algorithms called pseudo second

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

2631

order methods. In determining the best direction to move the weights in order to bring down the error, the second
order methods use the Hessian or the matrix of second derivatives of the performance surface to determine the
weight update, whereas, pseudo-second order methods estimate the Hessian. Therefore to discard the second
order derivatives of the error the LM method makes use of the Gauss-Newton approximation that accepts the
Jacobian Matrix. In the case of Linear systems which have a quadratic performance surface the second order
method can Ô¨Ånd the minimum in one step but in Non-linear systems like neural networks, where the issue arises
as the performance surface tends to be convex, this leads to the quadratic approximations to diverge and requires
several steps for convergence [5][6][7].
The approach of optimising the LM algorithm and its implementation are described below.
2.1. LM Approach and Network architecture
Let us take a nonlinear model of the general form
yi = g(xi , Œ≤) + Œµi

(i = 1, 2, 3...m)

(1)

where Œ≤ is a vector containing n parameters and m > n. Assume further that f is nonlinear in Œ≤T =
[Œ≤1 , Œ≤2 , ..., Œ≤n ]. The method of least squares is used for estimating the unknown parameters in a non-linear regression function. According to this method, the estimates of Œ≤1 , Œ≤2 , ..., Œ≤( n) are obtained by minimizing the
quantity
fi (Œ≤)2

(2)

The sum of the squares of the errors of the predictions, where:
fi (Œ≤) = yi ‚àí g(xi , Œ≤)

(3)

As given by nonlinear regression, the method of nonlinear least-squares data Ô¨Åtting has a special form for the
gradient and Hessian. Let us express the problem as:
min f (Œ≤) =

1
2

fi (Œ≤)2 =

1
F(Œ≤)T F(Œ≤)
2

(4)

Where F is the vector-valued function.
F(Œ≤) = ( f1 (Œ≤), f2 (Œ≤), .... fm (Œ≤))T
Note that the scaling by
follows:

1
2

(5)

is to make the derivatives less jumbled. The components of

f (Œ≤) = J(Œ≤)T F(Œ≤)

f (Œ≤) can be derived as
(6)

Where J is the Jacobian matrix with i jth element
Ji j =
2

Œ¥g(xi , Œ≤)
,
Œ¥Œ≤i

i = 1, 2, 3...m

and

j = 1, 2, 3, ...n

(7)

f (Œ≤) can be derived by diÔ¨Äerentiating this formula with respect to the Œ≤ j
2

f (Œ≤) = J(Œ≤)T J(Œ≤) +

fi (Œ≤)

2

fi (Œ≤)

(8)

Since it is anticipated that fi (Œ≤) is approximately zero, the summing up term can be ignored. Therefore, we
can approximate 2 f (Œ≤) as
2

f (Œ≤) = J(Œ≤)T J(Œ≤)

(9)

2632

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

For the Gauss-Newton method this approximation can be used for the Hessian and then to solve
J(Œ≤)T J(Œ≤k )pk = ‚àíJ(Œ≤k )T F(Œ≤k )

(10)

to calculate pk and then let Œ≤k + 1 = Œ≤k + pk .
Rather than approximating the Hessian as in (9), the outline term in (8) can be approximated by ŒªI where
Œª ‚â• 0. Following this the Hessian is approximated as
2

f (Œ≤k ) ‚âà J(Œ≤k )T J(Œ≤k ) + ŒªI

(11)

Now to Ô¨Ånd search direction, p, the following equation is solved:
[J(Œ≤)T J(Œ≤) + ŒªI]p = ‚àíJ(Œ≤)T F(Œ≤)

(12)

After Ô¨Ånding p, f (Œ≤ + p) has been evaluated. If there has been an improvement in the function value then let
Œ≤ = Œ≤ + p and Œª = Œª2 .
The termination criterion is then checked. If the termination criteria are not met, then proceed with other
iteration. If, however, the evaluation of f (Œ≤ + p) does not give us an improvement in the function value, then let
Œª = 2Œª but Œ≤ has not been changed.
The LM algorithm is implemented on dynamically constructed feed forward neural network. the network
is designed based on feed forward construction algorithm proposed in [5]. In our network structure, nodes are
dynamically added until a benchmark eÔ¨Éciency is achieved. New node is inserted dynamically when learning
rule update weights until it reaches the eÔ¨Éciency level. Thus, the learning rule is still can be applied on network
layer even if it is not fully eÔ¨Écient and enables the network to generate a benchmark eÔ¨Éciency. As the new node
is added dynamicallly the search direction of LM algorithm is set to as steepest descent method when achieved
eÔ¨Éciency is far from benchmark eÔ¨Éciency. However, as eÔ¨Éciency gets closer to benchmark eÔ¨Éciency, it takes on
a search direction similar to Newtons method[6][7][8].
2.2. Diabetes Dataset and Dataset Preparation
The database used in this study is the Pima Indian Diabetes Database from The John Hopkins University and
is owned by National Institute of Diabetes and Digestive and Kidney Diseases. The dataset is retrieved from
ftp://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes.
The diagnostic, binary valued variable investigated here is for ascertaining whether the patient exhibits signs
of diabetes as laid out by the The World Health Organization criteria (i.e., if the 2 hour post-load plasma glucose
was at least 200 mg/dl at any survey examination or if found during routine Medical care). All patients in the
database are females of at least 21 years of age and of Pima Indian heritage. The total number of instances is 768.
There are 8 attributes listed which are Number of times pregnant, Plasma glucose concentration, Diastolic blood
pressure, Triceps skin fold thickness, 2-Hour serum insulin ,Body mass index, Diabetes pedigree function, Age
in addition to two more output classes: Diabetes Yes and Diabetes No. The class was divided into two output
attributes section without any due change to the original dataset. There are no missing values in the dataset. Class
distribution is done in the way which shows class value 1 as tested positive for diabetes and 0 as tested negative
for diabetes.
3. Experimentation and Results
In this paper the Diabetes diagnosis with the LM algorithm is classiÔ¨Åed through training and testing of the Pima
Indian Dataset. The two classes are diabetes yes, which indicates the patient has diabetes, and diabetes no which
indicates the patient does not have diabetes. These experiments show some very interesting neurodynamics. The
following graph (Figure 1) obtained shows the learning curve that the network rapidly reaches to the Minimum
Squared Error(MSE) of 0.094 at the epoch no 245.
The dynamic networks estimate for the training set is acceptable as our desired error target. We determine the
acceptable error should be less than 0.1 and network nodes are added dynamically to reach the target.So it is vital
to train the Neural Network several times to determine whether they reproducibly converge.

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

2633


	










 


 




 





	


	

Fig. 1. Training learning curve for LM

In the research work performed here, the standard procedure of evaluation is done on the basis of the results
obtained by splitting the data into one training set, one cross-validation set, which is used to determine the stopping
point for the purpose of over Ô¨Åtting avoidance, and Ô¨Ånally a testing set which is used to determine whether the
network has really learned the training patterns and obtained the Ô¨Ånal distribution of performance. The comparison
of the LM algorithm with other techniques like Quickprop algorithm [10] and those obtained by alterations to
the standard Back Propagation algorithm, like Momentum learning [11] and Delta-Bar-Delta, [12] will itself
be helpful for the performance evaluation of the method. For comparison purpose, to reveal the capability of
LM algorithm amongst all these algorithm there is a value set for mean squared error (MSE), normalized MSE
(NMSE), mean absolute error (MAE) and Min Abs Error and these are shown in Table 1. All these learning
algorithms are applied on the same neural network which is obtained by applying LM initially.
Table 1. Summary of main results.
Parameters
MSE
NMSE
MAE
Min Abs Error

Threshold value
‚â§ 0.5 for both diabetes yes and diabetes no
‚â§ 2.0 for both diabetes yes and diabetes no
‚â§ 0.5 for both diabetes yes and diabetes no
‚â§ 0.005 for both diabetes yes and diabetes no

Table 2 demonstrates clearly that the LM algorithm shows 58% accuracy for diabetes yes when compared to
Delta-bar-Delta, QuickProp and Momentum approach. However, it shows 90% correct classiÔ¨Åcation result for
the diabetes no when compared with other algorithms. The table also demonstrates that the LM algorithm shows
minimum absolute error 0.0010 for diabetes yes and 0.0018 for diabetes no, respectively which is less than the
other approaches, i.e. Delta-bar-delta, QuickProp and Momentum approaches.
The confusion matrix (Table 2) for LM shows that while testing 41 cases, 32 shows correct prediction whilst
9 incorrect prediction is evident, whereas 113 cases are detected as diabetes no out of which 90 shows correct
classiÔ¨Åcation. To ensure that a natural result is obtained a process of cross validation is applied in order to
eliminate attributes which has no eÔ¨Äect on the decision making. The cross validated dataset shows 100% accuracy
for the diabetes yes and 94% accuracy for diabetes no, respectively. The cross validation process on dataset
increases the performance of the LM algorithm signiÔ¨Åcantly. Table 3 presents the performance comparison of all
selected algorithms when training is performed on the cross validated dataset.
In the case of cross validated dataset (Table 3) it is surprising that the LM outperformed the other algorithms
by obtaining the best minimum MSE of 0.067 and 0.07 respectively for diabetes yes and diabetes no. The other
three algorithms have performed well for the diabetes yes classiÔ¨Åcation which is under the threshold value (see
table 1) but in the case of diabetes no they exceeded the threshold value. The NMSE, in the case of cross validating
dataset, LM exceeded the threshold value in diabetes no and Delta-by-Delta demonstrated the best result, 1.72.

2634

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

Table 2. Comparison of LM algorithm with others.
Algorithms
Performance
LM
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no
Delta-bar-Delta
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no
Quickprop
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no
Momentum
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no

diabetes ‚Äôyes‚Äô
0.15
0.7
0.3
0.001
0.55
58.18
32
23
0.39
1.7
0.41
0.007
1.05
0.0
0
55
0.35
1.5
0.38
0.001
1.05
0.0
0
55
0.30
1.3
0.49
0.004
1.04
20
11
44

diabetes ‚Äôno‚Äô
0.15
0.68
0.3
0.001
0.56
90.1
9
90
0.36
1.6
0.39
0.002
1.05
100
0
99
0.22
0.96
0.36
0.005
1.048
100
0
99
0.25
1.1
0.46
0.012
0.97
82
17
82

LM performs better on cross validated data when MAE is taken as evaluation parameter. It shows 0.19289 and
0.20 for diabetes yes and diabetes no respectively. Min Abs Error value obtained for LM is 0.001048 and 0.001 for
diabetes yes and diabetes no and these results are promising in comparison to other algorithms. On cross validated
dataset LM shows accuracy of 100% for diabetes yes and 94.4% accuracy for diabetes no classes, on the contrary,
the QP shows 67% for diabetes yes and 23% for diabetes no and MOM and DBD show the similar results.
The performance of the algorithms are further analysed by sensitivity and speciÔ¨Åcity [21] study. For checking
the sensitivity and speciÔ¨Åcity the following expressions are used:
Sensitivity (%) = TP/TP+FN
SpeciÔ¨Åcity (%) = TN/TN+FN
Where, TP = True positive in the confusion matrix, TN= True negative in the confusion matrix and FN= False
negative in the confusion matrix
The Table 4 shows the comparison study of all the algorithms presented here based on their sensitivity and
speciÔ¨Åcity. The robustness of all the algorithms are measured on both test and cross validated dataset.
4. Discussion and Conclusion
The study attempts to investigate the performance of the Levenberg Marquardt method in diabetes disease
classiÔ¨Åcation in comparison with other algorithms available. It is found that the Levenberg Marquardt method
is successful in reducing errors in providing a meaningful classiÔ¨Åcation on the Pima Indian Diabetes Dataset for
diagnosing the patients with and without diabetes. One of the objectives of this research has been to make use of
the LM method in improving the classiÔ¨Åcation accuracy of the neural network on the dataset applied. The next

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637
Table 3. algorithm performance on cross validated dataset.
Algorithms
Performance
LM
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no
Delta-bar-Delta
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no
Quickprop
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no
Momentum
MSE
NMSE
MAE
Min Abs Error
Max Abs Error
percent correct
diabetes yes
diabetes no

2635

diabetes ‚Äôyes‚Äô
0.06
0.27
0.19
0.001
0.68
100
12
0
0.4
1.7
0.41
0.0
1.05
58.3.0
7
5
0.33
1.39
0.37
0.0
1.0
66.6
8
4
0.4
1.7
0.43
0.0
1.04
58.3
7
5

diabetes ‚Äôno‚Äô
0.07
0.29
0.20
0.004
0.64
94.4
1
17
0.5
2.4
0.59
0.0
1.05
27.7
13
5
0.55
2.31
0.60
0.0
1.01
22.2
14
4
0.5
2.2
0.58
0.0
1
22.2
14
4

objective of this study is to critically compare and evaluate the performance of the LM algorithm in comparison
with other algorithms available. This task is carried out successfully by undertaking a performance evaluation of
the LM algorithm compared to the Quickprop, Momentum and Delta-Bar-Delta techniques which are also used
for classiÔ¨Åcation. The other reason for selecting the LM method as our learning algorithm is to overcome the
problem of convergence which has been observed in the BP algorithm, this is proven successfully when it is
compared and evaluated according to the lowest MSE found and seen to be better than all the other techniques
considered. Therefore, from the results obtained by implementation, experimentation and performance evaluation
and comparison, it can be concluded that the Levenberg Marquardt is the best method (out of all those studied
here) for the diagnosis of Diabetes in terms of convenience and optimum accuracy.
Table 4. Robustness study of the algorithms.
Dataset
Evaluation matrix
Test Data
Sensititivity
SpeciÔ¨Åcity
Cross validated data
Sensitivity
SpeciÔ¨Åcity

LM
58.18%
90.90%
100%
94.44%

Delta-by-Delta
0%
100%
58.33%
27.77%

QuickPro
0%
100%
66.66%
22.22%

Momentum
20%
82.82%
58.33%
22.22%

All algorithms demonstrate their capabilities and this study shows none of the selected algorithms demonstrate
100% accuracy on the test dataset. LM demonstrates 58% accuracy which is then followed by MOM with 20%.
However, LM shows 100% sensitivity in classifying diabetes yes and no. The speciÔ¨Åcity analysis is carried out on
the testing data to check the percentage of correct records classiÔ¨Åed as true negative that means the percentage of

2636

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

diabetes no record classiÔ¨Åed correctly. It is demonstrated in Table 4 that DBD and QP outperformed here giving
100% result and LM followed them with 90%. However, when speciÔ¨Åcity analysis is carried out on cross validated
dataset LM performs the best amongst all other algorithms with 94.44% in Ô¨Ånding diabetes no.
It can be concluded that LM algorithm provided a meaningful classiÔ¨Åcation on diabetes patients when compared to other techniques. LM provides with more accurate results in terms of convergence speed. It shows
excellent performance in the confusion matrix assessment on both test and cross validating dataset. However, the
future work which are recommended for further studies on this research would be in two major areas:
‚Ä¢ As the research was performed on a single dataset, it is recommended that the LM algorithm be applied to
additional real world datasets to determine its proÔ¨Åciency in dealing with diÔ¨Äerent conditions and phenomena.
‚Ä¢ Detailed study on adjusting inner statistics like hidden layers and input output nodes to Ô¨Ånd the optimum
solution.
References
[1] ShortliÔ¨Äe EH et al (1990). Medical Informatics: Computer Applications in Medicine. Addison-Wesley, Reading.
[2] Maron MJ (1987) Numerical Analysis: A Practical Approach. MacMillan, New York,
[3] Hasan Temurtas, Nejat Yumusak, Feyzullah Temurtas (2009) A comparative study on diabetes disease diagnosis using neural networks,
Expert Systems with Applications, Volume 36, Issue 4, May 2009, Pp 86108615
[4] Zuo P, Li Y, Ma J(2005) Analysis of Noninvasive Measurement of Human Blood Glucose with ANN-NIR Spectroscopy, 0-7803-94224/05/2005 IEEE.
[5] Principe J, Lefebvre C, Lynn G , n.d, The manual for the NeuroSolutions 6.0.
[6] P. Mondragon (2003), A Comparison of Nonlinear Regression Codes, New Mexico Institute of Mining and Technology Socorro, New
Mexico.pp 4-12.
[7] Nash, S.G., Sofer, A., Linear and Nonlinear Programming McGraw Hill New York (1996), pgs 409-423.
[8] Engineering
Statistics
Handbook,
4.1.4.2
Nonlinear
Least
Squares
Regression,[online],Available
at
http://www.itl.nist.gov/div898/handbook/pmd/section1/pmd142.htm,1-3.
[9] Fahlman, S. E. (1988) Faster-Learning Variations on Back-Propagation: An Empirical Study in Proceedings of the 1988 Connectionist
Models Summer School, Morgan Kaufmann.
[10] Rumelhart DE; Hinton GE; Williams RJ.(1986) Learning internal representation by error propagation. In Rumelhart, D.E., and McClelland, J.L. (eds) Parallel Distributed Processing. MIT Press, Cambridge.
[11] Robert A. Jacobs. Increased Rates of Convergence Through Learning Rate Adaptation.Neural Networks,1:295-307,1988.
[12] Rumelhart, D. E., Hinton, G. E. and Williams, R. J., Learning rep-resentation by back-propagating errors. Nature, 1986, 323, 533536.
[13] A. Monadjemi, P. Moallem, Automatic Diagnosis of Particular Diseases using a Fuzzy-Neural Approach, International Review on
Computers and Software (IRECOS) [COMPENDEX], Praise Worthy Prize (Publishing House), Italy, Vol. 3, July 2008.
[14] D. Gil, M. Johnsson, J. M. Garicia Chemizo, A. S. Paya and D. R. Fernandez, ‚ÄùApplication of ArtiÔ¨Åcial Neural Networks in the
Diagnosis of Urological Dysfunctions‚Äù, Expert Systems with Applications, Vol.36, No.3, 2009, pp. 5754-5760.
[15] Muhammad Akmal Sapon , Khadijah Ismail and Suehazlyn Zainudin , Prediction of Diabetes by using ArtiÔ¨Åcial Neural Network, 2011
International Conference on Circuits, System and Simulation IPCSIT vol.7 (2011) (2011) IACSIT Press, Singapore
[16] P. Venkatesan* and S. Anitha, Application of a radial basis function neural network for diagnosis of diabetes mellitus, Current Science,
Vol. 91, No. 9, 10 November 2006
[17] Gurbuz, E.; Kilic, E., Diagnosis of diabetes by using Adaptive SVM, Signal Processing and Communications Applications (SIU), 2011
IEEE 19th Conference (20-22 April 2011 ), p46 49, Print ISBN: 978-1-4577-0462-8
[18] Karamchandani, S.; Desai, U.B.; Merchant, S.N.; Jindal, G.D.;, Principal Component Analysis Based Backpropagation Algorithm for
Diagnosis of Peripheral Arterial Occlusive Diseases, Canadian Conference on Electrical and Computer Engineering, 2009, pp.482-485
[19] Shanthi, D.; Sahoo, G.; Saravanan, N.; (2009) Designing an ArtiÔ¨Åcial Neural Network for the Prediction of Thromboembolic Stroke,
International Journals of Biometric and Bioinformatic, vol. 3, no. 1,pp.10-18, 2009.
[20] Neilsen, H.R. Theory of Backpropagation Neural Networks, (1989). IJCNN., International Joint Conference on In Neural Networks,
1989. IJCNN., International Joint Conference on (22 June 1989), pp. 593-605.
[21] Reidmiller, M. and Braun, H. A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm, In IEEE
International Conference on Neural Networks, Vol. 16 (1993), pp. 586-591.
[22] Shahin, M.A., Jaksa, M.B., and Maier, H.R. (2001), ArtiÔ¨Åcial Neural Network applications in geotechnical engineering. Australian
Geomechanics, 36(1), 49-62.
[23] Al-Daoud (2009), A comparison between three neural network models for classiÔ¨Åcation problems. J.Artif. Intel., 2(2): 56-64.
[24] Arimura H., Mgome T., Ymashita Y., Yamamoto D (2009), Computer Aided Diagnosis Systems for Brain Diseases in Magnetic
Resonance Images, Algorithms 2009, 925-952.
[25] Baradaran, M.N., Shogain S. and ZariÔ¨Å M. (2008) Cancer Diagnosis using aritiÔ¨Åcal neural networkds. Int. J. Comput. Sci. Network
security, 8:233-236.
[26] Dogantekin, D. Dogantekin a., Avci, D., Avci L, (2009), An intelligent diagnosis system for diabetes on linear discriminant analysis
and adaptive network based fuzzy inference system, LDA-ANFIS, 1051-2004.

Nawaz Khan et al. / Procedia Computer Science 18 (2013) 2629 ‚Äì 2637

[27] Jayalakshi T., Santhakumaran A. (2010), A novel classiÔ¨Åcation method for diagnosis of diabetes mellitus using artiÔ¨Åcial neural network,
978-0-7695-3958-4/10 IEEE.
[28] Kayaer, K., Yildirum, T (2003), Medical diagnosis of Pima Indian Diabetes using general regression neural networks. In proceedings
of the international conference on artiÔ¨Åcial neural networds and neural information processing (ICANN/ICONIP) pp 181-184.
[29] Palaniappan S. and Awang R. (2008) Intelligent Heart Disease Prediction System Using Data Mining Technique, IJCSNS vol. 8, no. 8.
[30] Purnami W., Zaim, M. and Embong A. (2010) A new expert system for diabetes disease diagnosis using modiÔ¨Åed spline smooth support
vector machine. D. Taniar et al. (Ed.), ICCSA, Part IV, LNCS 6019, pp 83-92.
[31] Temurtas H., Yumusak, N. Temurtas, F. (2009), A comparative study on diabetes disease diagnosis using neural network, Expert Sys.
And Applications, 36, 8610-8615.
[32] Zitar R., Al0Jabali A., (2005) Towards Neural Network Model for Insulin/Glucose in Diabetics II, Informatica 29, 227-232.
[33] Siristatidis C, Chrelias C, Pouliakis A, Katsimanis E, Kassanos D. (2010) ArtiÔ¨Åcial neural networks in gyneacological diseases: Current
and potential future applications. Med Sci Monit. 16: 231-236
[34] Szolovits P, Patil RS, Schwartz W. ArtiÔ¨Åcial Intelligence in Medical Diagnosis. Ann Intern Med. 108: 80-87, 1988.
[35] Shankaracharya, Odedra D, Samanta S, Vidyarthi A. (2010) Computational intelligence in early diabetes diagnosis: a review. Rev
Diabet Stud. 7: 252-262, 2010.
[36] Atkov O, Gorokhova S, Sboev A, Generozov E, Muraseyeva E, Moroshkina S and Cherniy N. (2012) Coronary heart disease diagnosis
by artiÔ¨Åcial neural networks including genetic polymorphisms and clinical parameters. J Cardiol. 59: 190-194, 2012.
[37] Bartosch-Hrlid A, Andersson B, Aho U, Nilsson J, Andersson R. (2008) ArtiÔ¨Åcial neural networks in pancreatic disease. Br J Surg. 95:
817-826, 2008.
[38] Mazurowski M, Habas P, Zurada J, Lo J, Baker J, Tourassi G. (2008) Training neural network classiÔ¨Åers for medical decision making:
the eÔ¨Äects of imbalanced datasets on classiÔ¨Åcation performance. Neural networks. 21: 427-436, 2008.
[39] Er O, Temurtas F, Tanrkulu A. (2008) Tuberculosis Disease Diagnosis Using ArtiÔ¨Åcial Neural Networks. J Med Syst. 34: 299-302,
2008.
[40] Amato, Fillipo, Alberto Lopez, Eladia Maria, Petr Vanhara, Ales, Hampl, Josef Havel. (2013) ArtiÔ¨Åcial Neural Network in Medical
Diagnosis, J Appl Biomed 11: 47-58.

2637

