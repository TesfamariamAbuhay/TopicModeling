Available online at www.sciencedirect.com

Procedia Computer Science 4 (2011) 76‚Äì85

International Conference on Computational Science, ICCS 2011

High performance distributed cluster-based individual-oriented Ô¨Åsh
school simulation
Roberto Solar, Remo Suppi, Emilio Luque
Department of Computer Architecture & Operating Systems
Universitat Autnoma de Barcelona
Bellaterra, 08193, Barcelona, Spain

Abstract
Individual-oriented simulation allows us to represent the global behavior of a system through local interaction
in discrete time steps. As we face up close-to-reality models and large-scale workloads, we focus on turning from
traditional approaches towards distributed simulation in order to obtain more accurate results in less time. One of the
main problems in distributed simulation is how to distribute individuals eÔ¨Éciently through distributed architecture.
Individual-oriented systems can be implemented in a distributed fashion by using either a grid-based or cluster-based
approach. On one hand, grid-based approaches consist of assigning to each node a simulation space portion, together
with the set of individuals currently residing in that area. On the other hand, cluster-based approaches consist of
assigning to each node a Ô¨Åxed set of individuals. In this work we present a cluster-based method based on Voronoi
diagrams and covering radius criterion in order to avoid unnecessary interaction between individuals. We can show
experimentally that our proposal reduces the communication and computing times signiÔ¨Åcantly increasing simulation
eÔ¨Éciency.
Keywords: High performance simulation, individual-oriented models, distributed simulation, data clustering,
nearest-neighbor.

1. Introduction
Collective behavior in groups of autonomous individuals is a common phenomenon observed in diÔ¨Äerent scales
and levels of complexity. Individual members act on the basis of some limited local information coming from interaction with other individuals and/or the environment. This local information Ô¨Çows through the system producing
collective patterns. Collective behaviors can be seen in many research areas such as: ecology and biology [1, 2, 3, 4, 5],
military strategies [6], sociology [7, 8, 9], physics [10, 11], health care [12], vehicular traÔ¨Éc [13], Ô¨Åre suppression
strategies [14], etc.
Individual-oriented models have been created to solve limitations imposed by population-oriented models, in
‚ú© This

research has been supported by the MEC-MICINN Spain under contract TIN2007-64974
Email addresses: roberto.solar@caos.uab.es (Roberto Solar), remo.suppi@uab.es (Remo Suppi), emilio.luque@uab.es (Emilio
Luque)

1877‚Äì0509 ¬© 2011 Published by Elsevier Ltd. Open access under CC BY-NC-ND license.
Selection and/or peer-review under responsibility of Prof. Mitsuhisa Sato and Prof. Satoshi Matsuoka
doi:10.1016/j.procs.2011.04.009

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

77

which the system variables evolve according continuous functions in time (eg Lotka-Volterra equations, also known
as prey-predator equations). An individual-oriented approach allows us obtaining a global vision of how system variables evolve from interaction between individuals and their environment. Nevertheless, it is very diÔ¨Écult to solve
an individual-oriented model analytically whereby it is necessary using simulation tools in order to observe system
variables through time. During the last few years, the great disadvantages of individual-oriented simulation have
been: on one hand, the workload assigned to a single computing element and, on the other hand, the high complexity
level of the models. But due the advent of distributed/parallel architectures and high performance computing these
disadvantages have become a challenge for parallel/distributed simulation.
One of important problem in distributed simulation is how to distribute individuals through the architecture in order
to get the best performance of applications (scalability, eÔ¨Éciency, minimum communication times, etc). Individualoriented systems can be implemented in a distributed fashion by making each node responsible for a Ô¨Åxed portion of
the problem domain. This Ô¨Åxed portion can be assigned using either a grid-based or a cluster based approach.
The grid-based approach consist of assigning to each node a simulation space portion together with the set of
individuals currently residing in that area. Grid-based partitioning methods can be classiÔ¨Åed into two groups: static
decomposition - eg: strip, rectangular, recursive and scatter, and dynamic decomposition - strip, rectangular, recursive
and quadrilateral [15]. The cluster-based approach consist of assigning to each node a Ô¨Åxed set of individuals. Each
set is determined from individuals grouping into clusters of similar/near members. Similarity is determined according
to a distance measure.
In this work we present a distributed Ô¨Åsh school simulator which implements a cluster-based approach based on
an hybrid voronoi diagrams/covering radius construction criterion. Furthermore, a high-level metric data structure
called list of clusters is used in order to store and manipulate individuals as the simulation progresses. In subsection
1.1 we present an overview of some previous works about partitioning algorithms in distributed individual-oriented
simulations. In section 2 we show the biological behavior model that describes the motion of a Ô¨Åsh school. In section
3 we present our partitioning algorithm, the data structure to store and manipulate individuals, its construction and
the sequential cluster-based simulation algorithm. In section 4 we present out model distribution and the distributed
simulation. The experimental results, comparing a grid-based partitioning method (dynamic strip decomposition) and
our cluster-based implementation are presented in section 5. Finally, in section 6 the conclusions and future work are
proposed.
1.1. Related Work
In this section we focus at previous works about partitioning approaches in distributed individual-oriented simulation. Partitioning methods can be classiÔ¨Åed into two approaches: grid-based and cluster-based (also can be hybrid).
Next, we will take a look at the most important works in this area.
Grid-based methods
In [10] is proposed two partitioning methods based on Voronoi cells (body-centered-cubic and face-centered-cubic
lattices), used in simulations of the sillium model for amorphous silicon. In [16] a micro-cells based method is used.
In this method, the problem domain is decomposed to small cubes, called micro-cells, and they are grouped into subdomains (groups of adjacent micro-cells), and each sub-domain is assigned to a distinct processing element. In [5]
is presented a column wise block-striped decomposition to partition the simulated space in bird Ô¨Çocking simulation.
In [4, 3] is used a grid-based approach, named strip decomposition. The simulation space is divided evenly into
n strips, each strip is assigned to a processing node together with the individuals residing currently in that area.
Every processing node executes the simulation with local data, making data exchange using two types of messages:
neighbors exchange [17] and migration. In this work a simulation study of large-scale of Ô¨Åsh schools is carried out.
Cluster-based methods
In [11] is proposed a new approach for parallel domain decomposition of vortex particles, based on k-means
clustering of the particle coordinates. The paper investigates hierarchical evaluation of vortical velocities in a vortex
simulation of a transverse jet at high Reynolds number. In [8] is presented a method of partitioning individuals through
the distributed architecture using an adapted k-means clustering algorithm. The paper shows the application of cluster
partitioning algorithms for large-scale agent-based crowd simulation. In [7] is proposed a partitioning method based

78

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

on convex hulls to simulate large crowds of autonomous agents. This approach consist of handling partitions as the
convex hull of the points that represent the individuals positions in a particular area.
2. Individual-oriented Models
An individual-oriented approach can provide techniques and tools for analyzing complex organizations and social
phenomena. These models allow us to understand global consequences from local interactions of members of a
population. These individuals might represent: Ô¨Åsh in schools [1, 4, 3], people in crowds [7, 8], birds in Ô¨Çocks [2], etc.
These type of models typically consist of: an environment in which interactions occur and a Ô¨Åxed set of individuals
deÔ¨Åned in terms of their behavioral rules and characteristic attributes.
Some individual-oriented models are also spatially-explicit which means individuals are associated with a location
in geometrical space. Furthermore, some spatially-explicit individual-oriented models can exhibit motion patterns
which means individuals can change their position in geometrical space as the simulation progresses.
Individual-oriented models also allows us: to include diÔ¨Äerent types of individuals within the same model, to
deÔ¨Åne individuals with two levels of heterogeneity (behavioral rules and attributes values), to model interactions
between individuals and its environment, and to represent learning mechanisms.
2.1. Fish school model
Fish schools are one of the most frequent social groups in the animal world [18]. This type of social aggregation
shows complex emergent properties such as: high level of synchronization, strong group cohesion, leaderless group
navigation and non-hierarchical structure.
The biological model [18, 1] used in this work describes the change of position and orientation of a single individual depending on the position and orientation of a Ô¨Åxed number of neighbors. To select appropriately the neighbor‚Äôs
inÔ¨Çuence we identify three vision areas: attraction, repulsion and parallel orientation (Figure 1).

	



	

		
	





Figure 1: Neighbor inÔ¨Çuences areas.

Depending on the neighbor‚Äôs spatial-temporal position the individual chooses between three behavior patterns:
Repulsion: In order to avoid collision between Ô¨Åsh of the same group. Consists of rotating the Ô¨Åsh‚Äôs orientation a
minimum-angle so the Ô¨Åsh and its neighbor are perpendicular (Figure 2(c)).
Parallel orientation: In order to keep the group moving towards the same direction. Consists of matching the Ô¨Åsh‚Äôs
orientation with its neighbor. (Figure 2(b)).
Attraction: In order to keep the group cohesiveness. Consists of steering the Ô¨Åsh‚Äôs orientation towards its neighbor‚Äôs
position (Figure 2(a)).
The new Ô¨Åsh‚Äôs orientation will be the average of neighbors‚Äô inÔ¨Çuence. If there are no neighbors within the Ô¨Åsh vision
range, the Ô¨Åsh starts searching for neighbors by means of swimming in random directions.

79

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

(a) Attraction.

(b) Parallel orientation.

(c) Repulsion.

3. Partitioning method
In this section we explain the partitioning method used in this work. In our case, we use an hybrid partitioning
method based on voronoi diagrams and covering radius criterion.
Voronoi diagram is one of the most fundamental data structures in computational geometry. Given some number
of objects in the space, their Voronoi diagram divides the space according to the nearest-neighbor rule: each object
is associated with the area closest to it [19]. Covering radius criterion consist of trying to bound the area [ci ] by
considering a sphere centered at ci that contains all the objects of the problem domain that lie in the area [20].
A metric space is a particular type of vectorial space where a distance between objects is deÔ¨Åned. Given a set of
objects X subset of the universe of valid objects U and a distance function d : X2 ‚Üí R, so ‚àÄx, y, z ‚àà X, must be met
the following conditions:
Positiveness: d(x, y) ‚â• 0, d(x, y) = 0 ‚áí x = y
Symmetry: d(x, y) = d(y, x)
Triangular inequality: d(x, y) + d(y, z) ‚â• d(x, z)
Since individuals are associated with a position in three-dimensional euclidean space, we assume that these individuals together with the euclidean distance (which determines the visibility of individuals or objects in environment),
generating a metric space. This allow us introducing concepts of similarity or proximity within the distributed simulation.
The partitioning method proposed here consist of two stages: First, the centroids selection by means of covering
radius criterion, which ensures us a set of centroids far away enough the others. Second, the space decomposition by
means of voronoi diagrams, which allow us deÔ¨Åne similar size areas with similar number of individuals (as long as
individuals are uniformly distributed in space). Both criteria are applied to construct the data structure described in
the next section.
3.1. Data Structure
The metric data structure used to store individuals is called Ô¨Åxed-radius list of clusters [20], speciÔ¨Åcally, we use an
hybrid voronoi diagram/covering radius building criterion for a Ô¨Åxed-radius list of clusters [21]. The radius is Ô¨Åxed
in function of the maximum Ô¨Åsh vision area (r ‚â• RAT T RACT ION ). This allow us deÔ¨Åning areas in which individuals can
interact only with individuals belonging to adjacent areas, reducing computing involved in the neighbors selection
process.
The structure is formed by a linked list of clusters. Each cluster consists of several data such as: a centroid - which
is the most representative element of the cluster, the processor identiÔ¨Åer (PID) - indicating in which node each cluster
is stored, a bucket - in which individuals belonging to the cluster are stored, the cluster identiÔ¨Åer (CID) - indicating
the cluster position in the list, and some information about distances to other clusters (Fig. 2).

80

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85




	





	










	










	












Figure 2: List of clusters.

3.2. Construction
The construction consists of iterative insertion of individuals within the data structure. First, if the list is empty,
the Ô¨Årst individual is selected as a centroid. Next, for each individual, the distance to each centroid in order to Ô¨Ånd the
minimum distance is calculated. If the minimum distance is greater than the covering radius, the individual is selected
as a centroid, otherwise, the individual within the closest cluster is inserted. The construction algorithm complexity is
O (nk), where n is the number of individuals and k the number of clusters (k < n).


























	



Figure 3: Covering radius/Voronoi diagram partitioning.

In Figure 3 a two-dimensional example of our cluster-based partitioning method is shown. One of the main improvements of our proposal is reducing the execution time of sequential algorithm. Sequential algorithm performs
exhaustive computing (n √ó n) in order to Ô¨Ånd the most inÔ¨Çuential neighbors. In our case, individuals only perform
computing of their nearest-neighbors individuals belonging to adjacent clusters, reducing computing involved in obtaining the spatial-temporal position of their neighbors.
3.3. Simulation step
One simulation step consists of several simple stages:
First stage: consists of updating individuals selected as centroids. For this, we seek the intersection of each cluster
in order to Ô¨Ånd all adjacent clusters (this intersection will be used in update bucket process also). Next, for each
centroid, we perform neighbors selection process in order to obtain the most inÔ¨Çuential individuals. Finally, we
update the centroids position and orientation.

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

81

Second stage: For each individual belonging to bucket we perform: neighbors selection and, update individual position and orientation.
Third stage: Consists of reinserting all individuals belonging to buckets within the header structure (centroids). For
each bucket individual, we calculate the distance to each centroid in order to Ô¨Ånd the closest to it and insert into
its bucket.
Finally: If some individual is outside of all clusters, we proceed to create a new cluster.
The sequential algorithm in Alg. 1 is shown.
3.4. Simulation algorithm complexity
Given U a set of individuals uniformly distributed in space, R ‚â• RAT T RACT ION the Ô¨Åxed covering radius, R MIN =
RREPULS ION the minimum distance between individuals, C = {c1 , c2 , ..., ck } ‚äÇ U the set of centroids uniformly distributed, V = {[c1 ], [c2 ], ..., [ck ]} the set of partitions [ci ] centered on ci deÔ¨Åned from Voronoi diagram criterion.
Algorithm 1 Cluster-based simulation step
for i = 1 to k do
I ‚Üê [ci ] ‚à© V
for all j ‚àà [ci ] do
N ‚Üê j‚Üíchoose neighbors(I ‚àí { j})
j‚Üísimulate(N)
end for
end for
R 3
R MIN

Let n = |U| the total number of individuals, m = |[ci ]| =
the area [ci ], we can demonstrate that:
k

n=

the maximum number of individuals belonging to

k

|[ci ]| =

m = km ‚áí k =

i=1

i=1

n
m

(1)

Considering the Algorithm 1, where k is the number of partitions, I the intersection between [ci ] and V, N the set
of more inÔ¨Çuential individuals, we can demonstrate that:
T (n) = k ‚àó (k + |[ci ]| ‚àó (|I| ‚àí 1 + |N|))

(2)

Replacing m = |[ci ]| and b = |N| (Ô¨Åxed number of neighbors):
T (n) = k ‚àó (k + m ‚àó (|I| ‚àí 1 + b))

(3)

Extending the covering radius to R ‚Üí 2R, we obtain:
|I| =
Replacing |I|, we obtain:

n 2
m

3

3

(4)

T (n) = k ‚àó (k + m ‚àó (8m ‚àí 1 + b))
T (n) = mn ‚àó mn + m ‚àó (8m ‚àí 1 + b)

(5)

n 2
m

=8

R

= 8m

T (n) =
Intersecting

2R
R MIN

+ 8nm ‚àí n + bn ‚áí

and nm, we obtain:
2

T (n) =

R MIN

O( mn 2 )
O(nm)

n 2
m

‚àö
if m ‚â§ 3 n
otherwise

+ nm

(6)

Where m is the minimum
‚àö3 number of individuals per cluster. Also using m we can obtain the minimum number of
clusters k = mn = ‚àö3nn = n2 .

82

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

4. Distributed time-driven simulation
An important issue in discrete simulation is the mechanism in which the state variables changes as simulation time
advance. We can distinguish two time-advance approaches: time-driven and event-driven. In a time-driven approach,
the simulation time is subdivided into a sequence of equal-sized steps, and the simulation advances from one time step
to the next [22]. In the event-driven mechanism the simulation time is computed when a event is processed adding the
event time to the execution time. Furthermore, is necessary to consider the time management protocol because this will
ensuring that the execution of the distributed simulation is properly synchronized. Time management algorithms can
be classiÔ¨Åed as conservative or optimistic [22]. In conservative algorithms, the process is blocked until all execution
conditions are satisÔ¨Åed. In optimistic algorithms, the process will continues even if some execution condition is not
fulÔ¨Ålled but this algorithm includes mechanisms in order recover from causality issues.
We implement a time-driven time-advance mechanism because the individual-oriented model used in this work
describes the motion of a Ô¨Åsh school in discrete time steps, i.e. each Ô¨Åsh moves at the same time. Furthermore, we
implement a conservative time-management protocol because each logical process requires exchanging information
(migration or neighboring request) from adjacent logical processes before starting the next simulation step [22].
4.1. Model distribution
After building our list of clusters, we proceed to distribute it through the distributed architecture. The model distribution used in this work is based on proximity concept. We distribute the list header together a Ô¨Åxed set of diÔ¨Äerent
clusters to each node. This Ô¨Åxed set of clusters is determined from the maximum number of individuals that each node
can have ( NNindividuals
), and how close are to each other. The main issue our model distribution is assigning of contiguous
processors
groups of clusters to each node in order to decrease communication and computing involved selecting data to transfer.
Every node independently executes the simulation with local data making data exchange through three type of
messages: neighbors exchange, centroids exchange and migration. The neighbors exchange process consists intersecting local clusters with non-local clusters in order to Ô¨Ånd adjacency. In this computation we use the cluster‚Äôs
distance data and the covering radius in order to intersect them, obtaining the data set to transfer Next, centroids‚Äô
neighbors selection is made, and its position and orientation is updated. After this operation, we execute the centroids
exchange process. This process consists of send local centroids to each node. Once updated the list header, we proceed to neighbors selection and updating the position and orientation of each individual belonging to each bucket.
Finally, we reinsert each bucket element within the list header. After this step some individuals can be stored within a
non-local cluster, and in this case, these individuals are reassigned to the correct node.
5. Experimental results
The simulator was developed using C++ (gcc 4.3.2), STL (c++ standard template library) and MPI namespace
(openmpi 1.4.1). The simulation experiments was carried out using 1, 2, 4, 8, 16, 32 and 64 processors. The data input
are formed by two Ô¨Åles containing 524.288 and 1.048.576 individuals uniformly distributed. Typical Ô¨Åsh parameters
used in our experiments in Table 1 are shown. Furthermore, we have varied the covering radius factor between three
values 5.0, 7.5 and 10.0 RAT T RACT ION . The execution environment used for testing has the following characteristics:
Cluster IBM - 32 nodes 2 x dual-core intel(R) xeon(R) CPU 5160 @ 3.00GHz, 12GB fully buÔ¨Äered DIMM, Integrated
dual Gigabit Ethernet and hot-swap SAS controller Disk. Experimental results have obtained from the average of 100
simulation steps.
RAT T RACT ION
RPORIENT AT ION
RREPULS ION
œâ

5.5BL
3.3BL
0.6BL
œÄ
3

Attraction radius
Parallel orientation radius
Repulsion radius
Dead angle

Table 1: Typical Ô¨Åsh parameter.

83

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

Cluster-based fish school simulation speedup
(individuals = 524.288, covering radius = Œ± * Rattraction)
64

64

Linear
Œ± = 5.00
Œ± = 7.50
Œ± = 10.0

Linear
Œ± = 5.00
Œ± = 7.50
Œ± = 10.0

32
Speedup (logscale)

32
Speedup (logscale)

Cluster-based fish school simulation speedup
(individuals = 1.048.576, covering radius = Œ± * Rattraction)

16
8
4
2

16
8
4
2

1

1
1

2

4
8
16
32
Number of Processors (logscale)

64

1

2

(a) Speedup 524.288 individuals.

4
8
16
32
Number of Processors (logscale)

64

(b) Speedup 1.048.576 individuals.

Figure 4: Cluster-based simulation speedups.

In Figure 4, the cluster-based simulation speedups is shown. Experiments has been executed using two set of
inputs and three covering radius factors conÔ¨Åguration. We see in Figures 4(a) and 4(b) the cluster-based simulation
scaling very well in comparison with linear speedup. Furthermore, there are a tightly coupled between the number
of processors and the largest covering radius factor in terms of scalability. This tightly coupled is because large
covering radius factors are capable of covering more space, mainly decreasing the data structure variability as the
simulation progresses. One of the main improvements of our cluster-based simulation is obtaining linear speedup
instead of previous works [3] given by superlinear speedup obtained. Using our cluster-based partitioning method we
can achieve a reduction of the sequential algorithm execution from O(n2 ) to O(nm).
Cluster-based fish school simulation execution times
(individuals = 524.288, covering radius = Œ± * Rattraction)
1600

Comunication times
Computing time Œ± = 5.00
Computing time Œ± = 7.50
Computing time Œ± = 10.0

300
250

Execution Times (seconds)

Execution Times (seconds)

350

Cluster-based fish school simulation execution times
(individuals = 1.048.576, covering radius = Œ± * Rattraction)

200
150
100
50
0

Comunication times
Computing time Œ± = 5.00
Computing time Œ± = 7.50
Computing time Œ± = 10.0

1400
1200
1000
800
600
400
200
0

1

2

4

8

16

32

64

1

Number of Processors

(a) Computation and communication times 524.288 individuals.

2

4

8

16

32

64

Number of Processors

(b) Computation and communication times 1.048.576 individuals.

Figure 5: Cluster-based simulation times.

In Figure 5 the cluster-based simulation computation and communication times are shown. We see in Figure
5(a) that small covering radius factor conÔ¨Åguration have shown an execution times reduction, but as the number of
processors is increased the execution times diÔ¨Äerence between other factors conÔ¨Åguration is negligible. We see in
Figure 5(b) the opposite behavior, but unlike Figure 5(a) results obtained, the simulation performance results are
maintained as the number of processors is increased.

84

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

106
10

Communication times
Computing time dsd
Computing time Œ± = 5.00
Computing time Œ± = 7.50
Computing time Œ± = 10.0

5

104
103
10

2

101
100

1

2

4
8
16
Number of Processors

32

(a) Execution Time 524.288 individuals.

Cluster-based and grid-based execution times comparison
(individuals = 1.048.576)
Execution Times (seconds/logscale)

Execution Times (seconds/logscale)

Cluster-based and grid based execution times comparison
(individuals = 524.288)

64

107

Communication times
Computing time dsd
Computing time Œ± = 5.00
Computing time Œ± = 7.50
Computing time Œ± = 10.0

6

10

5

10

4

10

3

10

102
1

10

100

1

2

4
8
16
Number of Processors

32

64

(b) Execution Time 1.048.576 individuals.

Figure 6: Execution Times Comparison (Cluster-based vs Grid-based).

In Figure 6 we compare our cluster-based partitioning method against a grid-based partitioning method existing
called dynamic strip decomposition (DSD). The great DSD advantage is that communication is produced only with the
left and right neighbors logical processes, reducing communication times. Furthermore, DSD approach implements
a dynamic load balancing strategy. We see in Figures 6(a) and 6(b) our cluster-based partitioning method execution
times are much lower than dynamic strip decomposition results. Results are much more signiÔ¨Åcantly because we have
used a logarithmic Y axis scale. In Figure 6(a) we see the cluster-based partitioning method always having a better
performance than the grid-based method. Figure 6(b) we see a similar behavior to the previous case.
6. Conclusions and Future Work
In this work we have presented our cluster-based partitioning method which has experimentally shown to be much
more eÔ¨Écient than a grid-based partitioning method (dynamic strip decomposition). We have executed experimental
testing using large-scale workload (524.288 and 1.048.576 individuals) in order to ensure the application scalability.
One of the main advantages of our partitioning method is the reduction of the sequential algorithm complexity from
O(n2 ) to O(nm). Data clustering techniques allow us partitioning an individuals group in small-size areas called
clusters, restricting interaction between individuals that are far away each others.
The main conclusions that can be extracted are:
‚Ä¢ Our partitioning method is adapted to the Ô¨Åsh school form because the centroids belong to the group. This
ensures to each cluster contain at least one individual avoiding empty partitions.
‚Ä¢ We have proved that employing a robust partitioning method we can obtain either a sequential and distributed
execution times reduction.
‚Ä¢ Our partitioning method allows to reduce the interaction between individuals that are too far away. We deÔ¨Åne
the cluster radius in function of the maximum Ô¨Åsh vision area so individuals belonging to a cluster only interact
with individuals from nearest-neighbors clusters.
‚Ä¢ Our partitioning method and model distribution scaling close to linear (see Fig. 4(a) and 4(b)). This shows the
feasibility of our implementation, opening areas for future work.
‚Ä¢ Our cluster-based partitioning method in comparison with a grid-based partitioning method has shown better
results (see Fig. 6).We see that we have considerably reducing computation and communication times for
large-scale distributed Ô¨Åsh school simulation.

Roberto Solar et al. / Procedia Computer Science 4 (2011) 76‚Äì85

85

6.1. Future work
The main objective for future work are:
‚Ä¢ Establish dynamic load balancing strategies in order to obtain the best performance of our cluster-based partitioning method.
‚Ä¢ Establish dynamic centroids reallocation strategies in order to obtain a set of centroids far enough away each
other as the simulation progresses. Actually, one of the main shortcomings of our proposal is as the simulation
progresses the number of centroids is increased.
References
[1] A. Huth, C. Wissel, The simulation of Ô¨Åsh schools in comparison with experimental data, Ecological Modelling 75-76 (1994) 135 ‚Äì 146,
state-of-the-Art in Ecological Modelling proceedings of ISEM‚Äôs 8th International Conference.
[2] C. W. Reynolds, Flocks, herds and schools: A distributed behavioral model, SIGGRAPH Comput. Graph. 21 (1987) 25‚Äì34.
[3] R. Solar, R. Suppi, E. Luque, High performance individual-oriented simulation using complex models, Procedia Computer Science 1 (1)
(2010) 447 ‚Äì 456, iCCS 2010.
[4] R. Suppi, P. Munt, E. Luque, Using pdes to simulate individual-oriented models in ecology: A case study, in: Proceedings of the International
Conference on Computational Science-Part I, ICCS ‚Äô02, Springer-Verlag, London, UK, 2002, pp. 107‚Äì116.
[5] B. Zhou, S. Zhou, Parallel simulation of group behaviors, in: Proceedings of the 36th conference on Winter simulation, WSC ‚Äô04, Winter
Simulation Conference, 2004, pp. 364‚Äì370.
[6] J. J. Corner, G. B. Lamont, Parallel simulation of uav swarm scenarios, in: Proceedings of the 36th conference on Winter simulation, WSC
‚Äô04, Winter Simulation Conference, 2004, pp. 355‚Äì363.
[7] G. Vigueras, M. Lozano, J. Ordua, Workload balancing in distributed crowd simulations: the partitioning method, The Journal of Supercomputing (2009) 1‚Äì9.
[8] Y. Wang, M. Lees, W. Cai, S. Zhou, M. Low, Cluster based partitioning for agent-based crowd simulations, in: Winter Simulation Conference
(WSC), Proceedings of the 2009, 2009, pp. 1047 ‚Äì1058.
[9] M. J. Quinn, R. A. Metoyer, K. Hunter-zaworski, Parallel implementation of the social forces model, in: Proceedings of the Second International Conference in Pedestrian and Evacuation Dynamics, 2003, pp. 63‚Äì74.
[10] M. A. Stijnman, R. H. Bisseling, G. T. Barkema, Partitioning 3d space for parallel many-particle simulations, Computer Physics Comm 149
(2003) 121‚Äì134.
[11] Y. M. Marzouk, A. F. Ghoniem, K-means clustering for optimal partitioning and dynamic load balancing of parallel hierarchical n-body
simulations, J. Comput. Phys. 207 (2005) 493‚Äì528.
[12] D. M. Rao, A. Chernyakhovsky, Parallel simulation of the global epidemiology of avian inÔ¨Çuenza, in: Proceedings of the 40th Conference on
Winter Simulation, WSC ‚Äô08, Winter Simulation Conference, 2008, pp. 1583‚Äì1591.
[13] S. B. Yoginath, K. S. Perumalla, Parallel vehicular traÔ¨Éc simulation using reverse computation-based optimistic execution, in: Proceedings
of the 22nd Workshop on Principles of Advanced and Distributed Simulation, PADS ‚Äô08, IEEE Computer Society, Washington, DC, USA,
2008, pp. 33‚Äì42.
[14] X. Hu, Y. Sun, Agent-based modeling and simulation of wildland Ô¨Åre suppression, in: Proceedings of the 39th conference on Winter simulation: 40 years! The best is yet to come, WSC ‚Äô07, IEEE Press, Piscataway, NJ, USA, 2007, pp. 1275‚Äì1283.
[15] F. Merchant, Load balancing in spatial individual-based systems using autonomous objects, Ph.D. thesis (1998).
[16] D. Zhang, C. Jiang, S. Li, A fast adaptive load balancing method for parallel particle-based simulations, Simulation Modelling Practice and
Theory 17 (6) (2009) 1032 ‚Äì 1042.
[17] C. Ding, Y. He, A ghost cell expansion method for reducing communications in solving pde problems, in: Proceedings of the 2001 ACM/IEEE
conference on Supercomputing (CDROM), Supercomputing ‚Äô01, ACM, New York, NY, USA, 2001, pp. 50‚Äì50.
[18] A. Huth, C. Wissel, The simulation of the movement of Ô¨Åsh schools, Journal of Theoretical Biology 156 (3) (1992) 365 ‚Äì 385.
[19] F. Aurenhammer, Voronoi diagrams - a survey of a fundamental geometric data structure, ACM Comput. Surv. 23 (1991) 345‚Äì405.
[20] E. Chavez, G. Navarro, An eÔ¨Äective clustering algorithm to index high dimensional metric spaces, in: Proceedings of the Seventh International
Symposium on String Processing Information Retrieval (SPIRE‚Äô00), IEEE Computer Society, Washington, DC, USA, 2000, pp. 75‚Äì.
[21] R. U. Paredes, C. Marquez, R. Solar, Construction strategies on metric structures for similarity search, CLEI Electron. J. 12 (3).
[22] R. M. Fujimoto, Parallel and Distribution Simulation Systems, 1st Edition, John Wiley & Sons, Inc., New York, NY, USA, 1999.

